[{"content":"其实年中时做过一个涵盖人生方方面面的规划，每个模块都有具体的OKR和事项，像是给我在《地球Online》布置了主线任务。目前运行得还算顺畅，本来想着按它展开年终总结的，但那样就会把年终总结写成年终汇报，违背了年终总结记录成长的初衷。于是决定先谈谈今年发生的事和想法上的变化。\n心态 观念 翻了翻以前的随笔和日记，发现这一年下来心态变了不少，变得平静了，但是也麻木了。了解我的人应该知道，我本来性格急躁，不乐意受挫，因而时常在焦虑下过度努力。记得去年的三四月份，我还会因为社会的、自己找实习的各种琐碎事情深陷负面情绪。但这一年下来，我好像只是在慢慢地完成着一件件事情。从上海去到波士顿生活，从英语转到计算机学习，对我来说本该是生活急剧变化的一年，我却表现得过于麻木了，没有什么惊和喜，好像只是从一个片场到了另一个片场，友情出演一段段人生。\n我想，问题可能出在这里：这一年结束的几件事，付出得不算少，但结局都不是Happy Ending。四五月，似乎把时间都花在了研究开源项目上，本来计划着暑期做一段相关实习，最后因实力不够没能获得机会。六月初，结束了论文答辩，只参加了个学院的毕业典礼，学校毕业典礼时我甚至在大阪环球影城。似乎都没有体验过多久校园生活，就被迫“滚旦”了，最后留下的只有形式上的证明，正如拿不拿那句形だけ何か述べて通り過ぎ行く。九月，本来说可能有希望发表的文章，最后了无音信草草收场。后面来美几个月，隔三差五收到秋招intern岗位的拒信，跟很多全职前辈确认了不是cv和经历的问题，最后只能感叹一句时运不济。\n大概出于无意识的自我保护，在过去的几个月里我并没有仔细分析这种变化的根因和意义。但现在想来，根本原因是，持续的负反馈会使人内化曾经不断抵抗的无知和无力感。现在更多是理解了把一颗石头扔下深渊而听不见任何坠地的声音，是一件再正常不过的事，这和石头多大没太大关系。比如个人是石头，社会是深渊，或者时间是石头，知识是深渊，或者追求是石头，欲望是深渊。\n说回我的心态变化，接近年末时我想通了引起问题的关键——人的落点在客体上，不幸就迟早会发生。即使不得不，也不该成为海面上的浮标，要成为海底的锚。\n但这种（社会的、个人的）转变也不全是坏事，在微观意义上可以说它让我活得松弛了不少。比如对任何机会，我现在的反应大多是“反正不成功很正常，先试试再说呗”，自我设限的事很少有了。毕竟在不太好的环境和无限低的预期下，试错也没什么物质成本和精神负担。\n意义 未来 今年的一个晚上，跟xixi在本部校园里边逛边聊了好几个小时。我发现我们有相似的人生观，都透着虚无主义的底色，但是选择了截然不同的方法论。我过去时常为自己生活的渺小感和重复性到非常失落：对于无限的空间或是时间的尺度来说，大部分人事物都显得太无意义了些；而且历史的车轮滚滚，无法累积的个体经验只是在不断重蹈覆辙。xixi也这么觉得，但她选择用最快乐的生活方式消解虚无，因为每个当下的愉悦体验是绝对真实的，这是价值的基石。那晚我好像不是特别赞同，知道没必要说服，但也辩不出道理，只是固执地认为对抗虚无的方法是创造出至少自己认可的有价值的东西，艺术作品也好，产品也好，至少避免成为一个量产复制品，所以要为此不断努力。\n大半年过去，我觉得我逐渐走上了“质疑，理解，成为”的路。\n今年和一些同学朋友聊天时发现，很多思考推断、目标理想，都经不起一个“然后呢”的追问。太多人，包括抱有“创造价值”的想法的我自己，都是在用一个定义模糊的里程碑遮蔽着在那之后的迷茫——用”到了那里再说吧“搪塞着自己。其实多想一步就该知道的，后面还是一样的模式，主打一个螺旋上升版的西西弗斯，越摆周期越长的叔本华钟摆，这样做的结局就是把一生花在低头追逐虚头巴脑的东西上。\n这么看，可能的确只有主体的体验是切实的，真正值得托付时间的。让我想起了野炊和王泪无限回档的、无法真正抵达的结局，好像也诉说了相同的道理。塞尔达的两部开放世界最终让我回忆起来而感到美好的，从来不是打败盖侬救下塞尔达的团圆结尾，而是在那路上，林克在海拉鲁跋涉过的火山、沙漠、雪地、草原，站在神兽顶上看到的落日，举着咕咕鸡飞行降落到的卡卡利科村，哈特诺村小溪旁等我回去的家，帮助过的笨蛋npc，路过迫害过的呀哈哈，拼了几小时的高达，洗劫过的一窝窝猪猪，回忆杀才磨过的人马。\n所以明年在主线之余，我打算试试更认真地生活，先从琐碎一些的开始。\n天空树上看到的许愿彩带，众多考试通过、身体健康之中格外显眼的一条： 「彩りある人生を送りたい」\n","permalink":"http://eimy.ink/zh/posts/2023/year-in-retrospect/","summary":"先が長い\u0026hellip;","title":"2023年终总结：开放世界的主线之余"},{"content":"Lab 11 networking 实验记录 lab link: https://pdos.csail.mit.edu/6.828/2020/labs/net.html\n11.1 E100 1 要求 补全网卡驱动里的e1000_transmit()和e1000_recv()函数，使之能够接受发送数据packets。\n这个task的自由度不高，细节主要跟着prompts和hints就可以实现。需要了解大致步骤\u0026amp;原理可以参考manual里的ch3。\n2 实现 实现e1000_transmit() 首先获取当前的ring index以及对应的desc：\n1 2 3 4 5 6 7 8 9 10 11 12 13 int e1000_transmit(struct mbuf *m) { // // Your code here. uint32 end; struct tx_desc *desc; acquire(\u0026amp;e1000_lock); end = regs[E1000_TDT]; // cur desc id desc = \u0026amp;tx_ring[end]; // index into ring to get cur desc // ... } 然后检查desc overflow。如果desc上设置好了E1000_TXD_STAT_DD，说明上一轮已经完成，可以释放buf里上一轮的内存。\n1 2 3 4 5 6 7 8 9 10 // check overflow if (!desc-\u0026gt;status \u0026amp; E1000_TXD_STAT_DD) { release(\u0026amp;e1000_lock); return -1; } // use mbuffree() to free the last mbuf if (tx_mbufs[end]) { mbuffree(tx_mbufs[end]); } 最后更新当前desc中的信息，更新ring index\n1 2 3 4 5 6 7 8 9 10 desc-\u0026gt;addr = (uint64) m-\u0026gt;head; tx_mbufs[end] = m; desc-\u0026gt;length = m-\u0026gt;len; desc-\u0026gt;cmd = E1000_TXD_CMD_EOP | E1000_TXD_CMD_RS; // update the ring position regs[E1000_TDT] = (end + 1) % TX_RING_SIZE; release(\u0026amp;e1000_lock); return 0; 实现e1000_recv() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 static void e1000_recv(void) { // ask the E1000 for the ring index int end = (regs[E1000_RDT] + 1) % RX_RING_SIZE; // get the next waiting received packet struct rx_desc *desc = \u0026amp;rx_ring[end]; // check if a new packet is available while ((desc-\u0026gt;status \u0026amp; E1000_RXD_STAT_DD)) { if(desc-\u0026gt;length \u0026gt; MBUF_SIZE) { panic(\u0026#34;e1000_resv\u0026#34;); } // update the length reported in the descriptor rx_mbufs[end]-\u0026gt;len = desc-\u0026gt;length; // deliver the mbuf to the network stack net_rx(rx_mbufs[end]); // allocate a new mbuf replace the one given to net_rx() rx_mbufs[end] = mbufalloc(0); if (!rx_mbufs[end]) { panic(\u0026#34;e1000_resv\u0026#34;); } // update descriptor and status desc-\u0026gt;addr = (uint64) rx_mbufs[end]-\u0026gt;head; desc-\u0026gt;status = 0; end = (end + 1) % RX_RING_SIZE; // mod if exceeding ring size desc = \u0026amp;rx_ring[end]; } regs[E1000_RDT] = (end - 1) % RX_RING_SIZE; // // Check for packets that have arrived from the e1000 // Create and deliver an mbuf for each packet (using net_rx()). // } Grade ","permalink":"http://eimy.ink/zh/posts/2023/xv6/lab-net/","summary":"MIT 6.S081 lab 11 networking 实验记录","title":"xv6 Lab 11 networking 实验记录"},{"content":"Lab 9 file system 实验记录 lab link: https://pdos.csail.mit.edu/6.828/2020/labs/fs.html\n9.1 Large files 1 要求 要求修改file system的block结构，使其支持doubly-indirect block，同时block上限从当前的$268 = 256 + 12$升高到 $65803 = 256*256 + 256 + 11$ 个blocks。\n主要修改的函数是bmap(), itrunc()\n2 实现 修改fs.h中定义的参数 1 2 3 4 5 // fs.h #define NDIRECT 11 // 原12 现在把其中一个block作为doubly #define NINDIRECT (BSIZE / sizeof(uint)) #define NDOUBLE (NINDIRECT * NINDIRECT) // 定义doubly的容量 #define MAXFILE (NDIRECT + NINDIRECT + NDOUBLE) // 相应增加 相应修改inode和dinode的addrs数组大小 1 2 3 4 5 6 7 8 9 10 11 12 // fs.h struct dinode { // ... uint addrs[NDIRECT+2]; // 一共有11 + 1 + 1个block }; // file.h struct inode { // ... uint addrs[NDIRECT+2]; // 11 + 1 + 1 }; 修改bmap函数 doubly indirect block相当于一个block指向了一个size=256的块，而每一块又指向一个size=256的block，所以最后一共增加了256*256 可用blocks。\n只要在原有代码基础上增加分配中间层block内存的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 // fs.c 附部分解释comment static uint bmap(struct inode *ip, uint bn) { uint addr, *a, *a1; struct buf *bp; if(bn \u0026lt; NDIRECT){ if((addr = ip-\u0026gt;addrs[bn]) == 0) ip-\u0026gt;addrs[bn] = addr = balloc(ip-\u0026gt;dev); return addr; } bn -= NDIRECT; // if (bn \u0026gt;= 250) printf(\u0026#34;bn: %d\\n\u0026#34;, bn); // 至此 bn=blocknumber=singly block中的计数 [0, 255] if(bn \u0026lt; NINDIRECT){ // Load indirect block, allocating if necessary. // 给singly indirect block分配内存 if((addr = ip-\u0026gt;addrs[NDIRECT]) == 0) ip-\u0026gt;addrs[NDIRECT] = addr = balloc(ip-\u0026gt;dev); bp = bread(ip-\u0026gt;dev, addr); a = (uint*)bp-\u0026gt;data; if((addr = a[bn]) == 0){ a[bn] = addr = balloc(ip-\u0026gt;dev); log_write(bp); } brelse(bp); return addr; } // ++++++++++++++++++++++++以下新增++++++++++++++++++++ bn -= NINDIRECT; // 至此 bn = doubly block中的计数 [0,65535] if(bn \u0026lt; NDOUBLE){ // n1 = bn / NINDIRECT 中间层的block number/索引号 // n2 = bn % NINDIRECT 实际的（最后一层）的block number // Load 1st layer of doubly indirect block, allocating if necessary. if((addr = ip-\u0026gt;addrs[NDIRECT + 1]) == 0) ip-\u0026gt;addrs[NDIRECT + 1] = addr = balloc(ip-\u0026gt;dev); // Load 2nd layer of doubly indirect block. allocate if necessary bp = bread(ip-\u0026gt;dev, addr); a = (uint*)bp-\u0026gt;data; if((addr = a[bn / NINDIRECT]) == 0){ a[bn / NINDIRECT] = addr = balloc(ip-\u0026gt;dev); log_write(bp); } brelse(bp); // use block bp = bread(ip-\u0026gt;dev, addr); a1 = (uint*)bp-\u0026gt;data; if((addr = a1[bn % NINDIRECT]) == 0){ a1[bn % NINDIRECT] = addr = balloc(ip-\u0026gt;dev); log_write(bp); } brelse(bp); return addr; } panic(\u0026#34;bmap: out of range\u0026#34;); } 相应地修改itrunc函数 用来释放内存 遍历中间层，释放其中每个block对应的第三层的内存blocks（增加一个嵌套循环），具体见下。\n这里需要注意的是，因为要分别release不同层的buffer lock，所以各层不能像之前一样共用locked buffer pointer变量名（bp）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 void itrunc(struct inode *ip) { int i, j, k; struct buf *bp, *bp2; uint *a, *a1; for(i = 0; i \u0026lt; NDIRECT; i++){ if(ip-\u0026gt;addrs[i]){ bfree(ip-\u0026gt;dev, ip-\u0026gt;addrs[i]); ip-\u0026gt;addrs[i] = 0; } } if(ip-\u0026gt;addrs[NDIRECT]){ // the bp of 256 blocks bp = bread(ip-\u0026gt;dev, ip-\u0026gt;addrs[NDIRECT]); // blocks addr arr a = (uint*)bp-\u0026gt;data; // free every block in a for(j = 0; j \u0026lt; NINDIRECT; j++){ if(a[j]) bfree(ip-\u0026gt;dev, a[j]); } brelse(bp); bfree(ip-\u0026gt;dev, ip-\u0026gt;addrs[NDIRECT]); ip-\u0026gt;addrs[NDIRECT] = 0; } // ++++++++++++++++++++++++以下新增++++++++++++++++++++ if(ip-\u0026gt;addrs[NDIRECT + 1]){ // the bp of 256 blocks bp = bread(ip-\u0026gt;dev, ip-\u0026gt;addrs[NDIRECT + 1]); // 1st addr arr a = (uint*)bp-\u0026gt;data; // rls every blocks in every arr in a for(j = 0; j \u0026lt; NINDIRECT; j++){ if(a[j]) { // 注意 bp2必须和bp区分开 否则会造成提前释放lock的问题 bp2 = bread(ip-\u0026gt;dev, a[j]); a1 = (uint*)bp2-\u0026gt;data; for (k = 0; k \u0026lt; NINDIRECT; k++){ if (a1[k]) bfree(ip-\u0026gt;dev, a1[k]); } brelse(bp2); bfree(ip-\u0026gt;dev, a[j]); a[j] = 0; } } brelse(bp); bfree(ip-\u0026gt;dev, ip-\u0026gt;addrs[NDIRECT + 1]); ip-\u0026gt;addrs[NDIRECT + 1] = 0; } ip-\u0026gt;size = 0; iupdate(ip); } 9.2 Symbolic links 1 要求 实现symlink(char *target, char *path) system call\nYou will implement the symlink(char *target, char *path) system call, which creates a new symbolic link at path that refers to file named by target. For further information, see the man page symlink. To test, add symlinktest to the Makefile and run it. Your solution is complete when the tests produce the following output (including usertests succeeding).\n2 实现 设置syscall num、声明syscall函数等 按照hints里一个个来，涉及到文件：user/usys.pl, user/user.h, kernel/syscall.h, kernel/syscall.c, 以及在kernel/sysfile.c里声明这个syscall函数（暂时为空）。\nkernel/stat.h 中增加T_SYMLINK，作为一个新的inode type\nkernel/fcntl.h中增加一个O_NOFOLLOW flag，和其他区分开，用来作为后续判断是否追踪symlink path的flag\n实现symlink()\n每个步骤都在注释里说明了，可以参考sys_link的实现。主要涉及到：1）创建一个特殊类型的inode（type=sym），它的路径和传入的path（下面命名为source以防搞混）相同；2）然后在inode里存放target path。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // sysfile.c uint64 sys_symlink(void) { // symlink(\u0026#34;/testsymlink/b\u0026#34;, \u0026#34;/testsymlink/a\u0026#34;); // arg0 target pathname // arg1 path pathname char source[MAXPATH], target[MAXPATH]; struct inode *sip; int len; // load args if((len = argstr(0, target, MAXPATH)) \u0026lt; 0 || argstr(1, source, MAXPATH) \u0026lt; 0) return -1; begin_op(); // create a symnode to store target sip = create(source, T_SYMLINK, 0, 0); if(sip == 0){ end_op(); return -1; } // ilock(sip); deadlock create里已经lock了 // write the target path to symnode if (writei(sip, 0, (uint64)target, 0, len) != len) { iunlockput(sip); end_op(); return -1; } iunlockput(sip); end_op(); return 0; } 修改sys_open()。 需要实现：如果当前path指向一个symlink inode，根据O_NOFOLLOW决定是否要跟踪symlink中的target path。\n如果跟踪，用link depth进行环检测+及时终止跟踪；\n如果不跟踪，直接读取该symnode（即不用额外操作）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // sysfile.c // 主要步骤见comment 具体略 struct inode* getirec(struct inode *ip) { uint inums[10]; // prompt建议设置最大深度为10 超过10默认err int i, j; char target[MAXPATH]; for(i = 0; i \u0026lt; 10; i++) { inums[i] = ip-\u0026gt;inum; // read the target path from symlink file // 用readi 略 // get the inode of target path if((ip = namei(target)) == 0) { return 0; } // ... // 判断是否为symnode 不是则直接返回ip 是则继续跟踪path if(ip-\u0026gt;type != T_SYMLINK) { return ip; } } iunlockput(ip); return 0; } uint64 sys_open(void) { char path[MAXPATH]; int fd, omode; struct file *f; struct inode *ip; int n; // ... if(ip-\u0026gt;type == T_DEVICE \u0026amp;\u0026amp; (ip-\u0026gt;major \u0026lt; 0 || ip-\u0026gt;major \u0026gt;= NDEV)){ iunlockput(ip); end_op(); return -1; } // ++++++++++++ 以下新增 ++++++++++++++++ // if inode is a symnode if (ip-\u0026gt;type == T_SYMLINK \u0026amp;\u0026amp; (omode \u0026amp; O_NOFOLLOW) == 0) { // if symnode not marked NOFOLLOW, read recursively // getirec需要额外写一下（略） 根据promt 不建议写成递归 if ((ip = getirec(ip)) == 0) { end_op(); return -1; } // ... } Grade ","permalink":"http://eimy.ink/zh/posts/2023/xv6/lab-fs/","summary":"MIT 6.S081 lab 9 file system 实验记录","title":"xv6 Lab 9 file system 实验记录"},{"content":"Lab 5 lazy 实验记录 Lab lazy page allocation要求：https://pdos.csail.mit.edu/6.828/2020/labs/lazy.html\n5.1 Eliminate allocation from sbrk() 1 要求 在syscall sbrk中删除即时分配内存的部分。\n2 实现 把原函数中调用growproc的部分注掉，再增加proc sz即可，diff如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 diff --git a/kernel/sysproc.c b/kernel/sysproc.c index e8bcda9..a410cd5 100644 --- a/kernel/sysproc.c +++ b/kernel/sysproc.c @@ -47,8 +47,9 @@ sys_sbrk(void) if(argint(0, \u0026amp;n) \u0026lt; 0) return -1; addr = myproc()-\u0026gt;sz; - if(growproc(n) \u0026lt; 0) - return -1; + myproc()-\u0026gt;sz += n; + // if(growproc(n) \u0026lt; 0) + // return -1; return addr; } 如果最后报错为page fault（unexpected scause 0x000000000000000f）就对了。\n3 reflection 这是实现lazy allocation的第一步。增加size相当于给proc开空头支票，所有内存面额增长，但实际还没有映射到物理内存。下一部分才处理proc真的需要使用内存的情况。\n5.2 Lazy Allocation 1 要求 要求修改trap.c以处理上一部分引起的page fault，需要给报错的虚拟地址分配对应的物理内存页。\n2 实现 首先在usertrap()中增加应对page fault的代码，总的来说是判断page fault -\u0026gt; 分配内存 -\u0026gt; 映射地址三步。\n根据hints，r_scause()可以用来判断是否pagefault。 需要分配内存的虚拟地址就是报错的地址，可以用r_stval()找到。此处的虚拟地址需要再rounddown对齐到page boundary。 然后参考vm.c中的uvmalloc()，用kalloc分配物理内存，mappages把处理过的虚拟地址映射到物理内存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // kernel/trap.c - usertrap() // ... } else if((which_dev = devintr()) != 0){ // ok } else if(r_scause() == 13 || r_scause() == 15) { // +++++ // if pagefault // get the page boundary uint64 addr = PGROUNDDOWN(r_stval()); // alloc memory char *mem = kalloc(); if(mem == 0){ printf(\u0026#34;usertrap: failed to alloc mem\\n\u0026#34;); } memset(mem, 0, PGSIZE); if(mappages(p-\u0026gt;pagetable, addr, PGSIZE, (uint64)mem, PTE_W|PTE_X|PTE_R|PTE_U) != 0){ kfree(mem); printf(\u0026#34;usertrap: failed to mappages\\n\u0026#34;); } } else { printf(\u0026#34;usertrap(): unexpected scause %p pid=%d\\n\u0026#34;, r_scause(), p-\u0026gt;pid); // ... } 到这里再次echo hi，不出意外会出现panic:uvmunmap not mapped的报错。看一下uvmunmap的代码就会发现，这个报错说明我们在取消虚拟地址和物理内存之间的映射时发现va对应了无效的pte。在实现lazy allocation前不可能有这种情况，所以被认为是错误。但现在lazy alloc的模式里遇到空头支票pte是正常的，所以可以放心地把报错删掉。\n1 2 3 4 5 6 7 8 9 10 // kernal/vm.c void uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free) { // ... if((*pte \u0026amp; PTE_V) == 0) continue; // ++++ normal for lazy alloc if(PTE_FLAGS(*pte) == PTE_V) // ... } 最后echo hi不报错就算通过。\n3 小结 现在lazy alloc的核心部分完成了（甚至就只需要这么几行）。下一部分还需要处理这个改动波及到的其他原有功能。\n5.3 Lazytests and Usertests 1 要求 修改代码以通过提供的压力测试\u0026amp;原功能测试。hints如下：\nHandle negative sbrk() arguments. Kill a process if it page-faults on a virtual memory address higher than any allocated with sbrk(). Handle the parent-to-child memory copy in fork() correctly. Handle the case in which a process passes a valid address from sbrk() to a system call such as read or write, but the memory for that address has not yet been allocated. Handle out-of-memory correctly: if kalloc() fails in the page fault handler, kill the current process. Handle faults on the invalid page below the user stack. 2 实现 其他几个都比较简单，只需要简单加条件/加一行kill（具体看后面的diff）。有一个比较隐秘的：\nHandle the case in which a process passes a valid address from sbrk() to a system call such as read or write, but the memory for that address has not yet been allocated. 还没处理这个问题时，有个usertest会失败：test sbrkarg: sbrkarg: write sbrk failed FAILED\n为此看了下test里报错位置的函数调用链，似乎是这样write -\u0026gt; sys_write -\u0026gt; filewrite -\u0026gt; pipewrite -\u0026gt; copyin -\u0026gt; walkaddr/memmove。于是初步判断问题出在最后几个函数（主要是没找到usertests的正确对单debug方法，不然还是gdb判断更快）。又因为问题必然是出在va没有对应的pa上，所以锁定在了walkaddr函数，而不会是memmove。\n再看walkaddr，显然是还需要处理下pte invalid的情况，报错似乎是在pte2pa这一步发生的（因为lazy alloc下会出现空头pte）。在保证这个pte在有效范围内的前提下，再次分配物理内存即可。以下的lazyalloc是把上一部分usertrap中的片段单独抽成一个函数，方便调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 uint64 walkaddr(pagetable_t pagetable, uint64 va) { pte_t *pte; uint64 pa; if(va \u0026gt;= MAXVA) return 0; pte = walk(pagetable, va, 0); // 这里以下修改了+++++ if(pte == 0 || (*pte \u0026amp; PTE_V) == 0) { // make sure the va is ACTUALLY valid if (va \u0026gt;= PGROUNDUP(myproc()-\u0026gt;trapframe-\u0026gt;sp) \u0026amp;\u0026amp; va \u0026lt; myproc()-\u0026gt;sz) { // lazy alloc lazyalloc(va); } else { return 0; } } if((*pte \u0026amp; PTE_U) == 0) return 0; pa = PTE2PA(*pte); return pa; } 其他部分：\n1 2 3 4 5 6 7 8 9 10 // 加了一个lazyalloc函数 diff --git a/kernel/defs.h b/kernel/defs.h index 4b9bbc0..5dd45a6 100644 --- a/kernel/defs.h +++ b/kernel/defs.h @@ -171,6 +171,7 @@ uint64 walkaddr(pagetable_t, uint64); int copyout(pagetable_t, uint64, char *, uint64); int copyin(pagetable_t, char *, uint64, uint64); int copyinstr(pagetable_t, char *, uint64, uint64); +uint64 lazyalloc(uint64); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // sbrk里处理负数情况 diff --git a/kernel/sysproc.c b/kernel/sysproc.c index a410cd5..ee9cf46 100644 --- a/kernel/sysproc.c +++ b/kernel/sysproc.c @@ -47,7 +47,12 @@ sys_sbrk(void) if(argint(0, \u0026amp;n) \u0026lt; 0) return -1; addr = myproc()-\u0026gt;sz; - myproc()-\u0026gt;sz += n; + if (n \u0026gt; 0) { + myproc()-\u0026gt;sz += n; + } else if (n \u0026lt; 0) { + int sz = myproc()-\u0026gt;sz; + myproc()-\u0026gt;sz = uvmdealloc(myproc()-\u0026gt;pagetable, sz, sz + n); + } // if(growproc(n) \u0026lt; 0) // return -1; return addr; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // usertrap()中简化代码 + 增加几处err handling diff --git a/kernel/trap.c b/kernel/trap.c index 4f41264..191f717 100644 --- a/kernel/trap.c +++ b/kernel/trap.c @@ -70,16 +70,15 @@ usertrap(void) } else if(r_scause() == 13 || r_scause() == 15) { // if pagefault // get the page boundary - uint64 addr = PGROUNDDOWN(r_stval()); - // alloc memory - char *mem = kalloc(); - if(mem == 0){ - printf(\u0026#34;usertrap: failed to alloc mem\\n\u0026#34;); + uint64 addr = r_stval(); + if (addr \u0026gt;= p-\u0026gt;sz || addr \u0026lt; p-\u0026gt;trapframe-\u0026gt;sp){ + p-\u0026gt;killed = 1; + // printf(\u0026#34;usertrap: invalid address\\n\u0026#34;); + exit(-1); } - memset(mem, 0, PGSIZE); - if(mappages(p-\u0026gt;pagetable, addr, PGSIZE, (uint64)mem, PTE_W|PTE_X|PTE_R|PTE_U) != 0){ - kfree(mem); - printf(\u0026#34;usertrap: failed to mappages\\n\u0026#34;); + if (lazyalloc(addr) != 0) { + p-\u0026gt;killed = 1; + exit(-1); } } else { 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // uvmunmap、uvmcopy中允许pte == 0的情况 // 改uvmcopy是为了解决fork中拷贝内存时的bug diff --git a/kernel/vm.c b/kernel/vm.c index caddaa7..4e258b1 100644 --- a/kernel/vm.c +++ b/kernel/vm.c @@ -5,6 +5,8 @@ #include \u0026#34;riscv.h\u0026#34; #include \u0026#34;defs.h\u0026#34; #include \u0026#34;fs.h\u0026#34; +#include \u0026#34;spinlock.h\u0026#34; +#include \u0026#34;proc.h\u0026#34; @@ -181,7 +188,8 @@ uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free) for(a = va; a \u0026lt; va + npages*PGSIZE; a += PGSIZE){ if((pte = walk(pagetable, a, 0)) == 0) - panic(\u0026#34;uvmunmap: walk\u0026#34;); + continue; + // panic(\u0026#34;uvmunmap: walk\u0026#34;); if((*pte \u0026amp; PTE_V) == 0) continue; // normal for pagefault if(PTE_FLAGS(*pte) == PTE_V) @@ -223,6 +231,27 @@ uvminit(pagetable_t pagetable, uchar *src, uint sz) memmove(mem, src, sz); } // Allocate PTEs and physical memory to grow process from oldsz to // newsz, which need not be page aligned. Returns new size or 0 on error. uint64 @@ -315,9 +344,11 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz) for(i = 0; i \u0026lt; sz; i += PGSIZE){ if((pte = walk(old, i, 0)) == 0) - panic(\u0026#34;uvmcopy: pte should exist\u0026#34;); + continue; + // panic(\u0026#34;uvmcopy: pte should exist\u0026#34;); if((*pte \u0026amp; PTE_V) == 0) - panic(\u0026#34;uvmcopy: page not present\u0026#34;); + // panic(\u0026#34;uvmcopy: page not present\u0026#34;); + continue; pa = PTE2PA(*pte); flags = PTE_FLAGS(*pte); if((mem = kalloc()) == 0) Grade 相比pagetable来说真是非常仁慈的lab了。\n","permalink":"http://eimy.ink/zh/posts/2023/xv6/lab-lazy/","summary":"MIT 6.S081 lab 5 lazy allocation 实验记录","title":"xv6 Lab 5 lazy 实验记录"},{"content":"Lab 4 Traps 实验记录 课上的截图，对理解trap很有帮助：high-level picture of the procedure of switching from user mode to supervisor mode\n4.2 Backtrace 1 要求 实现backtrace()函数，打印当前stack中的函数调用位置\n2 实现 跟着hints一步步实现:\n主要函数如下，除此以外还需要声明函数、在指定位置调用etc.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // kernel/printf.c void backtrace() { // // read the current frame pointer uint64 curfp = r_fp(); uint64 begin = PGROUNDDOWN(curfp); uint64 end = PGROUNDUP(curfp); // while curfp still in range of stack while(curfp \u0026gt;= begin \u0026amp;\u0026amp; curfp \u0026lt; end) { // print frame printf(\u0026#34;%p\\n\u0026#34;, *(uint64 *)(curfp - 8)); // get prev fp // be careful with pointers! curfp = *((uint64 *) (curfp - 16)); } } // also modified kernel/defs.h, kernel/riscv.h, // kernel/sysproc.c 3 reflection 循环里的逻辑是打印frame pointer - 8位置的return addr -\u0026gt; 更新frame pointer为其指向的prev frame pointer -\u0026gt; 循环直到超出范围。\n唯一一个卡手点在pointer casting那里（可见我写C真的不熟练、）。\n4.3 Alarm 1 要求 通过实现两个syscall\u0026ndash;sigalarm(interval, handler)和sigreturn()，实现对进程的定时警报。sigalarm(interval, handler)使得每隔intervel数量的硬件ticks，会触发一次handler函数来进行警报。\n2 实现 instruction里分了两部分。\n第一部分先实现（sigalarm中初始化警报相关参数 -\u0026gt; 在tick数量达到interval的要求时，触发第一次警报）。实现方法是在usertrap()（kernel/trap.c）中，在当前进程累计tick数达interval时，把handler装进trapframe的epc中。这样在返回user program时就会首先执行epc里的函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 先写sigalarm函数 初始化警报参数 uint64 sys_sigalarm(void) { int interval; uint64 handler; // get interval a0 if(argint(0, \u0026amp;interval) \u0026lt; 0) return -1; // get pointer to the handler function if(argaddr(1, \u0026amp;handler) \u0026lt; 0) return -1; // put it into the struc of myproc() myproc()-\u0026gt;alarm_handler = handler; myproc()-\u0026gt;interval = interval; // myproc()-\u0026gt;numticks = 0; return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 void usertrap(void) { int which_dev = 0; // ... // give up the CPU if this is a timer interrupt. if(which_dev == 2) { p-\u0026gt;numticks++; if( p-\u0026gt;interval \u0026gt; 0 \u0026amp;\u0026amp; p-\u0026gt;numticks == p-\u0026gt;interval){ // save the current trapframe bf overwriting p-\u0026gt;tpcopy = *(p-\u0026gt;trapframe); // put the handler func into the program counter // user will exec this func after returning p-\u0026gt;trapframe-\u0026gt;epc = p-\u0026gt;alarm_handler; } yield(); } usertrapret(); } 但这样直接写进epc会导致原epc被覆盖，同时许多原进程保存在寄存器的内容也会在执行handler函数时被覆盖，所以第二部分中要用sigreturn()来解决这个问题。instr里已经指定了sigreturn()的作用，它会在traphandler结束时被调用，专门用来恢复原进程内容。\n关于怎么恢复原进程，lab instr里的推荐做法（似乎）是在覆盖epc前，保存相关的寄存器。根据riscv convention我猜测至少需要保存所有的argument/pointer/save reg以及几个特殊寄存器。\n但这样好像有点麻烦，更加直接（？）的解决方式是覆盖前直接拷贝一份进程的trapframe放一边，再在需要恢复时拷回来。\n第三部分（第三个test）要求handler在没有返回前，不可以再次被调用。这里稍微卡了下，后来发现只要用tick计数就可以控制：目前累计ticks在只有在达到interval时会触发handler，也就是说只要累计ticks没有被重置，handler就只会被触发一次。利用这点，我们只在sigreturn中重置累计ticks，这样就等同于“在调用sigreturn（即handler结束）之前，不会有再次调用发生“。\n主要代码是这些：\n1 2 3 4 5 6 7 8 9 // usertrap()中加一句 if( p-\u0026gt;interval \u0026gt; 0 \u0026amp;\u0026amp; p-\u0026gt;numticks == p-\u0026gt;interval){ // save the current trapframe bf overwriting p-\u0026gt;tpcopy = *(p-\u0026gt;trapframe); // +++++++tpcopy是在proc.h中声明的新参数 // put the handler func into the program counter // user will exec this func after returning p-\u0026gt;trapframe-\u0026gt;epc = p-\u0026gt;alarm_handler; } 1 2 3 4 5 6 7 8 9 uint64 sys_sigreturn(void) { // 把trapframe恢复成进入handler前的样子 *(myproc()-\u0026gt;trapframe) = myproc()-\u0026gt;tpcopy; // 重置计数器 由此只有当一次handler call结束后才可能有下一次alarm myproc()-\u0026gt;numticks = 0; return 0; } 其他还有一堆syscall声明相关的修改，跟之前的syscall lab差不多。\n3 思考 这个task中最关键的是理解trap的流程和riscv中相关寄存器的作用。\nGrade ","permalink":"http://eimy.ink/zh/posts/2023/xv6/lab-traps/","summary":"MIT 6.S081 lab 4 traps 实验记录","title":"xv6 Lab 4 traps 实验记录"},{"content":"Lab网址：https://pdos.csail.mit.edu/6.828/2020/labs/pgtbl.html\n课程主页：https://pdos.csail.mit.edu/6.828/2020/schedule.html\ngdb用法：https://pdos.csail.mit.edu/6.1810/2022/labs/gdb.html\n排雷提示：第一次学操作系统，且没有参考中文教材，以下内容可能会出现中英混杂、中文术语不准确等问题。\n3.1 Print a page table 1 具体要求 要求实现一个vmprint()函数，接受一个pagetable参数，按照要求的格式打印出这个pagetable。\n1 2 3 4 5 6 7 # Print Format: # page table [argument] page table 0x0000000087f6e000 # [depth] [pte index]: [pagetable entry] pa [physical address] ..0: pte 0x0000000021fda801 pa 0x0000000087f6a000 .. ..0: pte 0x0000000021fda401 pa 0x0000000087f69000 .. .. ..0: pte 0x0000000021fdac1f pa 0x0000000087f6b000 2 实现方法 这个task相关的知识点：\nVA, PA, PPN, PTE的构成、作用和它们之间的关系，比如 虚拟地址（VA）中包括27bits，其中每9bits对应一个page table entry（PTE） VA包含几个部分，其中27位（3*9）用于在各层页表中索引PTE，另有12位offset用来在PA中索引定位 页表PTE中的PPN用来寻找下一层页表 xv6页表的three-level tree结构 (xv6book, p.30-1)： VA-PA转换的逻辑是：最上层页表的地址是由satp寄存器记录的；通过va中27bits里最左的9bits索引，查找到最上层的页表中对应的PTE；然后通过这个PTE中的PPN找到第二个页表，由VA中第二个9bits索引到对应的PTE，以此类推\u0026hellip;最后再结合VA中的offset定位PA VA-PA translation是由硬件memory management unit（MMU）实现的（如果没听错，lec里说软件也可以，但是硬件更快） 如何判断PPN映射到了下一层页表还是物理内存？ 参考freewalk()，如果(pte \u0026amp; (PTE_R|PTE_W|PTE_X)) == 0，即不可读/写/执行，就说明PPN没有映射到物理内存，而是映射到了更低层的页表 有三层pagetable，我选择了递归打印。这个task标了easy难度，跟着hints就能实现。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // helper function for vmprint void printhelper(pagetable_t pagetable, int depth) { // there are 2^9 = 512 PTEs in a page table. for(int i = 0; i \u0026lt; 512; i++){ pte_t pte = pagetable[i]; // skip invalid pages if (!(pte \u0026amp; PTE_V)) { continue; } // print indentation for (int i = 0; i \u0026lt;= depth; i++) { printf(\u0026#34;..\u0026#34;); if(i != depth) { printf(\u0026#34; \u0026#34;); } } printf(\u0026#34;%d: pte %p pa %p\\n\u0026#34;, i, pte, PTE2PA(pte)); // has lower-level pt -\u0026gt; recursive call on child if((pte \u0026amp; (PTE_R|PTE_W|PTE_X)) == 0){ uint64 child = PTE2PA(pte); printhelper((pagetable_t)child, depth + 1); } } } // print the content of a page table void vmprint(pagetable_t pagetable) { // refer to freewalk() printf(\u0026#34;page table %p\\n\u0026#34;, pagetable); printhelper(pagetable, 0); } 3 结果 和要求print内容一致，test ok。\n4 问题\u0026amp;思考 最后有个challenge question问打印出来的page0、page1、page2里是什么。\n因为vmprint是在kernel/exec.c中调用的，所以回去看kernel/exec.c里有分配页表的地方，源码上面有注释：\n1 2 3 4 5 6 7 8 9 10 11 ... // 分配了1 page // Load program into memory. 那这个页表应该是data+text if((sz1 = uvmalloc(pagetable, sz, ph.vaddr + ph.memsz)) == 0) goto bad; ... // 分配了2 pages // Allocate two pages at the next page boundary. // Use the second as the user stack. if((sz1 = uvmalloc(pagetable, sz, sz + 2*PGSIZE)) == 0) goto bad; 所以根据Figure3.4，这些应该是init user stack时分配的，page0是data+text，page1是guard page（PTE_V not set, 不可read/write），page2是顶上的stack。\n3.2 A kernel page table per process 1 要求 让每个进程都有一个自己的kernel pagetable，它们的页表和global kernel page保持一致。在切换进程时，也要切换到该进程对应的kernel pagetable（无进程运行时用global kernel pagetable。\n和当前task相关的知识点：\n每个进程维护一个页表的用户地址空间和一个页表的内核地址空间：\u0026ldquo;Xv6 maintains one page table per process, describing each process’s user address space, plus a single page table that describes the kernel’s address space.\u0026rdquo; (xv6book, p.31) Figure 3.3 内核地址空间里的映射关系（明白这点才知道之后如何构建kernel pagetable的mapping），里面哪些是直接映射、哪些不是（和后面的kstack有关）。 以及上面的页表结构，还会再次用到 2 实现方法 和hints给的顺序基本一致：\n声明kernel pagetable变量：在 struct proc 中增加变量pagetable_t kpagetable，由此每个process都有了自己的kpt 1 2 3 4 5 6 // kernel/proc.h 结构体里增加一个变量 struct proc { // ... private pagetable_t kpagetable; // (+) Kernel page table } 仿照kvminit 写一个函数，用来创建kpagetable页表并构建映射： 理解：要在分配进程（即allocproc()里）时，增加「给kpagetable分配内存」 -\u0026gt; 「直接映射到和global kernel pagetable相同物理地址」这些构建操作 思路：这些功能在kvminit中已有类似实现，但是不能直接调用kvminit，因为它调用了kvmmap()，后者是用mappages direct map了global kernel page和对应的pa。这里是要map各个进程的kernel page和pa，所以需要另写一个和kvmmap类似、但是允许传入指定pagetable的函数，然后在构建kpagetable时调用。 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // kernel/vm.c 实现一个类似kvmmap的函数 // +++++++以下都是新增的 // add a mapping to a given page table void uvmmap(pagetable_t pt, uint64 va, uint64 pa, uint64 sz, int perm) { if(mappages(pt, va, sz, pa, perm) != 0) panic(\u0026#34;uvmmap\u0026#34;); } // 参考了kvminit, // 把kvmmap换成了上面的uvm以自定义需要map的pagetable // Create a kernel page table for a given process pagetable_t proc_kpagetable(struct proc *p) { pagetable_t kpagetable = (pagetable_t) kalloc(); memset(kpagetable, 0, PGSIZE); // uart registers uvmmap(kpagetable, UART0, UART0, PGSIZE, PTE_R | PTE_W); // virtio mmio disk interface uvmmap(kpagetable, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W); // CLINT uvmmap(kpagetable, CLINT, CLINT, 0x10000, PTE_R | PTE_W); // PLIC uvmmap(kpagetable, PLIC, PLIC, 0x400000, PTE_R | PTE_W); // map kernel text executable and read-only. uvmmap(kpagetable, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X); // map kernel data and the physical RAM we\u0026#39;ll make use of. uvmmap(kpagetable, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W); // map the trampoline for trap entry/exit to // the highest virtual address in the kernel. uvmmap(kpagetable, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X); return kpagetable; } // +++++++ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // kernel/proc.c 新增代码片段 // Look in the process table for an UNUSED proc. // If found, initialize state required to run in the kernel, // and return with p-\u0026gt;lock held. // If there are no free procs, or a memory allocation fails, return 0. static struct proc* allocproc(void) { // .... // An empty user page table. p-\u0026gt;pagetable = proc_pagetable(p); if(p-\u0026gt;pagetable == 0){ freeproc(p); release(\u0026amp;p-\u0026gt;lock); return 0; } // +++++++++++ // Create a kernel page table. p-\u0026gt;kpagetable = proc_kpagetable(p); // 在这里调用 if(p-\u0026gt;kpagetable == 0){ freeproc(p); release(\u0026amp;p-\u0026gt;lock); return 0; } // +++++++++++ // .... } 在kpagetable的页表中添加kernel stack的映射： 理解+思路：原本kernel stack的初始化是在启动时的procinit()里完成的。现在为了把它加进kpagetable的映射中，需要把整个初始化过程移动到创建kpagetable的地方——也就是allocproc()中。 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // kernel/proc.c 移动代码 // initialize the proc table at boot time. void procinit(void) { struct proc *p; initlock(\u0026amp;pid_lock, \u0026#34;nextpid\u0026#34;); for(p = proc; p \u0026lt; \u0026amp;proc[NPROC]; p++) { initlock(\u0026amp;p-\u0026gt;lock, \u0026#34;proc\u0026#34;); // ----- 这里注释/删除掉原本的kstack初始化 } kvminithart(); } static struct proc* allocproc(void) { // ++++++++上面删掉的代码移动到这里 // Allocate a page for the process\u0026#39;s kernel stack. // Map it high in memory, followed by an invalid // guard page. char *pa = kalloc(); if(pa == 0) panic(\u0026#34;kalloc\u0026#34;); // get kstack va uint64 va = KSTACK((int)(p - proc)); // map kernal pagetable with kernal stack \u0026lt;- 这里构建映射 uvmmap(p-\u0026gt;kpagetable, va, (uint64)pa, PGSIZE, PTE_R | PTE_W); // 把va存在proc结构里 p-\u0026gt;kstack = va; // ++++++++++ // Set up new context to start executing at forkret, // which returns to user space. memset(\u0026amp;p-\u0026gt;context, 0, sizeof(p-\u0026gt;context)); p-\u0026gt;context.ra = (uint64)forkret; p-\u0026gt;context.sp = p-\u0026gt;kstack + PGSIZE; return p; } 修改进程调度函数 scheduler() ： 理解：（1）在切换进程时，把对应的kpagetable加载到satp寄存器，并清除缓存[*否则会导致错误的mapping被留着继续用]（2）没有进程运行时用global kernel_pagetable 思路：参考kvminithart()函数，它实现了把global kernel pagetable加载到satp以及清除缓存。只要页表改成proc-\u0026gt;kpagetable即可 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // kernel/proc.c 修改调度函数 void scheduler(void) { // ... for(;;){ // Avoid deadlock by ensuring that devices can interrupt. intr_on(); int found = 0; // use kernel_pagetable when no process is running if(found==0){ kvminithart(); // ++++ 无进程时使用global kernel pt } for(p = proc; p \u0026lt; \u0026amp;proc[NPROC]; p++) { acquire(\u0026amp;p-\u0026gt;lock); if(p-\u0026gt;state == RUNNABLE) { // Switch to chosen process. It is the process\u0026#39;s job // to release its lock and then reacquire it // before jumping back to us. p-\u0026gt;state = RUNNING; c-\u0026gt;proc = p; w_satp(MAKE_SATP(p-\u0026gt;kpagetable)); // ++++++ sfence_vma(); // ++++++ // 在跳进进程之前，就要完成satp的切换 swtch(\u0026amp;c-\u0026gt;context, \u0026amp;p-\u0026gt;context); // ... } // ... } } 在freeproc()中增加释放kstack和kpagetable内存的操作 理解：要求清除kpagetable中的所有映射，但是不能动物理内存，否则会影响global kernel pagetable（毕竟它们的va直接映射到了同一物理内存上）；kstack是process-specific的，可以全部清除 思路：关于kpagetable，参考freewalk() 写一个函数，遍历三层pagetable，对有效pte进行递归释放；如果pagetable直接映射到了物理内存就不递归。至于kstack，直接调用已有方法uvmumap()就可以清除映射。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // kernel/proc.c 增加函数 //++++++ // Free a process\u0026#39;s page table without // freeing the physical memory it refers to void proc_freepagetable_vonly(pagetable_t kpagetable) { // there are 2^9 = 512 PTEs in a page table. for(int i = 0; i \u0026lt; 512; i++){ pte_t pte = kpagetable[i]; if(pte \u0026amp; PTE_V) kpagetable[i] = 0; // 只有当映射到了下一层页表时，才会继续递归 if((pte \u0026amp; PTE_V) \u0026amp;\u0026amp; (pte \u0026amp; (PTE_R|PTE_W|PTE_X)) == 0){ // this PTE points to a lower-level page table. uint64 child = PTE2PA(pte); proc_freepagetable_vonly((pagetable_t)child); } } kfree((void*)kpagetable); } //++++++ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // kernel/proc.c 对freeproc的改动如下 // free a proc structure and the data hanging from it, // including user pages. // p-\u0026gt;lock must be held. static void freeproc(struct proc *p) { // ... p-\u0026gt;killed = 0; p-\u0026gt;xstate = 0; // ++++ 以下新增 if(p-\u0026gt;kstack){ // 第四个参数do_free设置为1 即为同时释放物理内存 uvmunmap(p-\u0026gt;kpagetable, p-\u0026gt;kstack, 1, 1); } p-\u0026gt;kstack = 0; if(p-\u0026gt;kpagetable) proc_freepagetable_vonly(p-\u0026gt;kpagetable); p-\u0026gt;kpagetable = 0; // +++++ 以上新增 p-\u0026gt;state = UNUSED; } 彩蛋：修改kvmpa()函数 理解：似乎是初始化disk时需要调用kvmpa，但是这个函数中目前walk的是global kernel pagetable，需要改成proc的kpagetable。 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // kernel/vm.c // translate a kernel virtual address to // a physical address. only needed for // addresses on the stack. // assumes va is page aligned. uint64 kvmpa(pagetable_t kpagetable, uint64 va) // 签名加了页表的参数 { uint64 off = va % PGSIZE; pte_t *pte; uint64 pa; pte = walk(kpagetable, va, 0); // 这里修改成kpagetable if(pte == 0) panic(\u0026#34;kvmpa\u0026#34;); if((*pte \u0026amp; PTE_V) == 0) panic(\u0026#34;kvmpa\u0026#34;); pa = PTE2PA(*pte); return pa+off; } 1 2 3 4 5 // 然后再跟着报错， // 把调用这个kvmpa的地方传入 myproc()-\u0026gt;kpagetable // kernel/virtio_disk.c disk.desc[idx[0]].addr = (uint64) kvmpa(myproc()-\u0026gt;kpagetable, (uint64) \u0026amp;buf0); 其他注意：\n添加函数后注意在def.h中更新声明 可以修改kernel/vm.c and kernel/proc.c，但不要动测试相关的代码 debug比较累 3 结果 tesk全部ok\n4 问题 有两个我觉得比较tricky的地方 freeproc的实现，主要是要理解释放内存的范围，然后找/写对应的函数 hints里没有提到的kvmpa()函数。在完成所有hints后make qemu会出现panic：kvmpa的报错，这个函数的调用链不是特别清楚。 3.3 Simplify copyin/copyinstr 1 要求 用vmcopy.c中给出的新函数copyin_new和copyinstr_new简化原有的copyin和copyinstr。\n2 分析 涉及到的知识点：\nuser address space和kernel address space（xv6book, p.32-36） kernel data和user data的起始虚拟地址不同 它们和物理地址的映射关系（kernel space中部分是direct-mapped的） address space和pagetable的关系 地址空间是一个抽象概念，它表示了一个进程的虚拟地址的范围 页表是实际用于将这些虚拟地址映射到物理地址的数据结构 然后简单分析一下task：\n原先由于global kernel pt里没有记录每个进程的用户地址空间的mapping，所以copyin在接受user的虚拟地址后，需要在软件中walk页表把虚拟地址转换成物理，然后才能从物理地址拷贝指定大小的内存到目标位置。\n现在我们每个进程都有自己的kpagetable，所以只要把用户地址空间的mapping也记录进来就能一定程度上简化步骤。为此需要把进程用户地址空间里的pte拷贝到kpagetable里。\n为什么可以记录进来？这和user space和kernel space的分布有关。kernel启动后的最低地址在PLIC（0xC000000），而user是从0开始的，它们的虚拟地址范围不重合，所以可以直接把user space的mapping直接加到（kernel自己不用的）kernel space里。\n3 实现 主要新写一个函数，用来把user pagetable拷贝到kpagetable里。\n简化copyin 1 2 3 4 5 6 7 8 9 10 // kernel/vm.c 修改函数 // Copy from user to kernel. // Copy len bytes to dst from virtual address srcva in a given page table. // Return 0 on success, -1 on error. int copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len) { return copyin_new(pagetable, dst, srcva, len); // ++ } 写一个从uvm拷到kvm里的函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // kernel/vm.c 新增函数uvm2kvm // copy uvm to kvm from START to END, // return 0 if successfull and -1 otherwise int uvm2kvm(pagetable_t upgtbl, pagetable_t kpgtbl, uint64 start, uint64 end) { // pointers to user pte and kernel pte // as walk() returns pointers pte_t *upte, *kpte; // exception: exceed plic limit if(end \u0026lt; start || PGROUNDUP(end) \u0026gt;= PLIC) return -1; // walk through every pte for(uint64 va = PGROUNDUP(start); va \u0026lt; end; va += PGSIZE){ // look up user pte if ((upte = walk(upgtbl, va, 0)) == 0) { panic(\u0026#34;uvm2kvm: failed to find user pte\u0026#34;); } // look up kernel pte if ((kpte = walk(kpgtbl, va, 1)) == 0) { panic(\u0026#34;uvm2kvm: failed to create kernel pte\u0026#34;); } // add mapping // and cancelling user accessibility meanwhile *kpte = *upte \u0026amp; (~PTE_U); // set the user flag to 0 (forbid user access) } return 0; } 修改所有可能会改动/初始化user mapping的函数，包括fork(), exec(), growproc(), userinit() 在改动后需重新把user pagetable拷贝进kpagetable\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // kernel/proc.c 修改fork \u0026amp; growproc \u0026amp; userinit int fork(void) { // ... np-\u0026gt;sz = p-\u0026gt;sz; // copy user addr space into kernel space // 注意是从newprocess的pagetable拷 if ((uvm2kvm(np-\u0026gt;pagetable, np-\u0026gt;kpagetable, 0, np-\u0026gt;sz)) \u0026lt; 0){ freeproc(np); release(\u0026amp;np-\u0026gt;lock); return -1; } np-\u0026gt;parent = p; // ... } // Grow or shrink user memory by n bytes. // Return 0 on success, -1 on failure. int growproc(int n) { uint sz; struct proc *p = myproc(); sz = p-\u0026gt;sz; if(n \u0026gt; 0){ if((sz = uvmalloc(p-\u0026gt;pagetable, sz, sz + n)) == 0) { return -1; } // ++++ mem grow了，重新map一次 if(uvm2kvm(p-\u0026gt;pagetable, p-\u0026gt;kpagetable, p-\u0026gt;sz, sz) \u0026lt; 0) { return -1; } } else if(n \u0026lt; 0){ sz = uvmdealloc(p-\u0026gt;pagetable, sz, sz + n); // ++++ mem shrink了，只清除映射 不动物理内存 if (n \u0026gt;= PGSIZE) { uvmunmap(p-\u0026gt;kpagetable, PGROUNDUP(sz), n/PGSIZE, 0); } } p-\u0026gt;sz = sz; return 0; } void userinit(void) { // ... // allocate one user page and copy init\u0026#39;s instructions // and data into it. uvminit(p-\u0026gt;pagetable, initcode, sizeof(initcode)); p-\u0026gt;sz = PGSIZE; // 在pagetable init完成之后 uvm2kvm(p-\u0026gt;pagetable, p-\u0026gt;kpagetable, 0, p-\u0026gt;sz); // +++ // ... } 1 2 3 4 5 6 7 8 9 10 11 12 // kernel/exec.c 修改exec int exec(char *path, char **argv) { // ... // （位置在进程页表初始化完之后） // copy user pagetable to kernel if(uvm2kvm(pagetable, p-\u0026gt;kpagetable, 0, sz) \u0026lt; 0) goto bad; // ... } 确认copyin没问题了，相似方法修改copyinstr 1 2 3 4 5 6 7 // kernel/vm.c 修改函数copyinstr int copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max) { return copyinstr_new(pagetable, dst, srcva, max); // +++ } 4 结果 tests ok\nFINAL：tests\u0026amp;grade 参考 https://clownote.github.io/2021/03/11/xv6/Xv6-Lab-page-tables/\nhttps://blog.csdn.net/LostUnravel/article/details/121340933\n","permalink":"http://eimy.ink/zh/posts/2023/xv6/lab-pgtbl/","summary":"MIT 6.S081 lab3 页表 实验记录","title":"xv6 Lab 3 pgtbl 实验记录"},{"content":" 1\n离开PVG。第一次见到人这么少的浦东机场。\n2\n抵达日本。在渋谷SKY的神楽茶寮吃着抹茶芭菲，听着身边的本地人在讨论乐队和新番，俯瞰着渋谷的十字路口，从午后等到日落。\n数数好像是第五次来日本了，街景和生活气息都很熟悉。\n3\n曾经在我最无能为力的年纪想上的第一所大学。\n虽然这句话是玩梗，但事情是真的，可能也是唯一一所。我一直说高中考N1是为了看懂动画片，但其实另一半的原因在这里，那时候连语言学校、timeline都暗地里规划好了。\n4\n东京晴空塔350m。站得足够高以后，地面上车人都显得迟缓不少，看来速度也由尺度决定。\n5\n路过的许愿丝带：彩りある人生を送りたい。\n这次路过各种神社时看到了各种各样的愿文，许抽象愿望的其实不太常见，所以记录下来。也不难理解，让人想要借助超自然的力量完成的事情，一般都是很具体的，\n6\n美国留学地狱开局。抵达波屯以后没几天就生病，开学第一周是硬撑过的。\n没有图片\n","permalink":"http://eimy.ink/zh/posts/2023/commencement/","summary":"去上学的路上：上海-东京","title":"去上学的路上，日本旅游5.0"},{"content":" 【发布时的说明】\n曾经想过去游戏行业，这是一篇当时学习手游活动设计时撰写的报告。后来有幸去字节发行线一个特别喜欢的海外游戏项目组实习了一阵，终究觉得不合适，于是告别了这个念想。\n最近整理文件时偶然看到这篇文章，觉得那时的思路、语言各种意义上挺抽象的，带着还没从象牙塔里出来的迂腐之气，总试图提炼出概念性的东西和方法论。\n想着反正也不会有用了，不如发出来留念。\n《原神》游戏内限时活动设计思路分析——以2.0-2.5版本活动为例 前言\n一、2.0～2.5各版本活动简述\n二、初探原神游戏内活动——版本活动规划\n表层规律总结 底层原则分析 架空案例尝试 三、再谈单个游戏活动——拓宽活动设计思路的一种方式\n从「属性空间」看游戏活动 应用活动属性空间的案例尝试 小结与反思\n附录：原神风花节活动设计草案\n前言 从因跑腿任务而被诟病的2021年初海灯节，到后来不少玩家给予好评的风花节和羽球节、有着“剧情巅峰”之名的逐月节，到春节期间的第二次海灯节和近期备受瞩目的三界路飨祭，原神在游戏活动方面的进步——活动数量的增加，真空期的缩短，活动质量（剧情、玩法、美术以及彩蛋等多方面的综合）的提升——是有目共睹的。\n作为一位一般路过旅行者，应接不暇地体验了这么多个版本的活动，（断断续续地）见证了游戏活动体系的大致稳定，想着也是时候尝试换个角度，从游戏运营方的视角出发来看待它们，探究这个目前较为稳定成熟的活动体系是怎样构建的，以及单个活动又是如何设计出来的。于是，在这篇文章里，以个人学习/备忘为宗旨，笔者会整理原神1.6版本以来的游戏内活动，初探各版本的活动配置思路。最终目标大约是要能够自行初步设计一个活动，甚至（更大胆一些！），是为某个版本初步设计一套活动。对象仅包括游戏以内的限时活动，不包括内容的周期刷新更替，例如礼包、BP、限定角色卡池、月本等等。\n* 事先提醒：本文写作的初衷，是为了从游戏研运的角度学习游戏活动的设计排期思路，结论可能如管中窥豹一般受限于个人视角。\n一、2.0～2.5各版本活动简述 以下表格梳理了2.0-2.5版本期间各个活动所属版本、活动内容、类型和奖励。\n活动名称 活动类型/目的 玩法 奖励类型 2.0上半（开放稻妻；UP角色：神里绫华） 谒索雷痕 地图挑战类 【维稳】 活动四幕分别为地图机关挑战、敌人挑战、敌人挑战和副本挑战（分阶段开启） 四星角色、原石、稀有养成道具和普通养成道具 秘宝迷踪第二期 探索地图类 【维稳】【回流】 探索地图上特定地点获得活动道具以兑换限定道具（跟随宠物） 原石、限定道具 2.0下半（UP角色：宵宫） 机关棋谭·灵妙之局 解谜挑战类（塔防）、社交 【维稳】【回流】 布局机关并抽取增益效果，阻挡敌人的前进 原石、限定名片、养成道具 幻影心流 战斗挑战类 【维稳】 挑战分阶段开放的、各自机制不同的战斗关卡 原石和养成道具 地脉移涌 掉落加成 【维稳】【回流】 养成道具限时翻倍掉落 / 活动名称 活动类型/目的 玩法 奖励类型 2.1上半（开放清籁岛、海祇岛；UP角色：雷电将军） 月中王国 钓鱼小游戏 【维稳】【回流】 在大世界特定地点钓鱼 原石、限定钓鱼道具、家园摆设 百人一揆 试用类、战斗挑战类 【维稳】【回流】 将试用角色与自有角色编成6组队伍，搭配限定buff，进行接力式闯关挑战 原石、限定名片和养成道具 飘浮秘灵 掉落加成 【维稳】【回流】 7日内每日数次特殊探索派遣 原石、养成道具 首充双倍重置 返利 【回流】【拉收】 / / 星之归还第二期 回归 【回流】 回归奖励 原石等 2.1下半（UP角色：珊瑚宫心海） 云流星崩 登陆类 【维稳】【回流】 7天累计登录活动 抽卡道具（共十抽） 韶光抚月·初试神机 小游戏 【维稳】【回流】 通过移动火源控制火候，完成烧饭小游戏（分阶段开启） 四星武器（咸鱼）、原石、稀有养成道具和普通养成道具 韶光抚月·觅取月晖 探索地图类 【维稳】【回流】 指定区域收集活动材料，达到一定数量解锁奖励（分阶段开启） 原石、养成道具、活动道具 韶光抚月·珍肴霞踪 消耗、地图挑战类 【维稳】【回流】 献祭美食获得强化效果，击败特定敌人完成挑战（分阶段开启） 原石、限定武器精炼材料、稀有养成道具和普通养成道具 活动名称 活动类型/目的 玩法 奖励类型 2.2上半（开放鹤观岛；UP角色：达达利亚） 谜境悬兵 解谜挑战类 【维稳】【回流】 完成试炼（带一点肉鸽性质的稻妻挑战副本+抽卡式buff）获得活动道具 四星角色、原石、稀有养成道具和普通养成道具 镜花听世 音乐小游戏 【维稳】【回流】 完成任务获得道具并进行演奏 原石、限定小道具 2.2下半（UP角色：胡桃） 古时孤影·调查勘测/数据采样/实践测试 探索地图类 【维稳】 装备小道具前往指定地点完成挑战（分阶段开放） 原石和养成道具 梦里生花 社交、休闲 在家园系统中种植花朵 原石和养成道具 地脉移涌 掉落加成 【维稳】【回流】 养成道具限时翻倍掉落 / 活动名称 活动类型/目的 玩法 奖励类型 2.3上半（UP角色：阿贝多/优菈） 皑尘与雪影·诞于雪中 小游戏 【维稳】【回流】 完成挑战得到雪人部件制作雪人，可以与好友互赠部件 四星武器（阿贝多外观）及突破素材、原石、稀有养成道具和普通养成道具 皑尘与雪影·疾行特训/觅踪特训/战斗特训 探索地图类 【维稳】【回流】 特定区域的障碍跑（共四条，分三阶段开放）；在特定范围内融化雪堆，寻找雪人部件（共八个，分阶段开放）；完成怪物挑战（分阶段开放） 原石和活动道具 皑尘与雪影·骤起的魔花 战斗挑战类（BOSS） 【维稳】 挑战新BOSS 原石和活动道具 万端珊瑚事件簿·犬武者 探索地图类 【维稳】【回流】 在指定地点通过潜行或战斗的方式使用限时道具解救失踪的小动物（共四个阶段，陆续开放） 原石和养成道具 2.3下半（UP角色：荒泷一斗） 迷城战线·光界篇 试用类、解谜挑战类 【维稳】【回流】 用试用角色编队并挑战7个不同主题的试炼（分阶段开放） 原石和养成道具 导能原盘·跋尾 解谜挑战类 【维稳】 完成前置挑战，选择buff和难度（debuff）进行关卡挑战 原石和养成道具 百货奇货 消耗类 【维稳】 消耗资源兑换奖励 原石和养成道具 活动名称 活动类型/目的 玩法 奖励类型 2.4上半（UP角色：申鹤/魈） 魔药研析 战斗挑战类、试用类 【维稳】 玩家编队（提供试用角色）并配备不同魔药（buff），自选关卡顺序挑战四关为一组的「实验」（怪物挑战），同一角色不能连续两关使用 原石和养成道具 风行迷踪 社交、小游戏 【维稳】【回流】 复刻活动，玩家联机进入特定地图捉迷藏 原石和养成道具 2.4下半（UP角色：甘雨/钟离） 飞彩镌流年·焰羽星花 小游戏 【维稳】【回流】 使用特殊道具「烟花筒」制作、燃放烟花 原石和活动道具A（ABC可用于兑换活动商店内物品，达到一定数量可领取角色皮肤） 飞彩镌流年·玄壁云聚 地图挑战类 【维稳】【回流】 驾船或打怪 原石、限定菜谱和活动道具B（BC可用于兑换自选四星角色） 飞彩镌流年·灯中妙影 解谜小游戏 【维稳】 根据灯影形状猜出灯谜 原石和活动道具C 飞彩镌流年·武卫重溟 战斗挑战类（BOSS） 【维稳】 挑战BOSS「跋掣」 原石和活动道具 山海八所巡禮 探索跑图类 【维稳】【回流】 带着吉法师完成蒙德和璃月的七条旅游线路，每天解锁1条新线路 家园摆设、原石、养成道具 富贵登门 登录类 【维稳】【回流】 7天累计登录活动 抽卡道具（共十抽） 流光飞彩 奖励发放 【维稳】【回流】 连续五天邮件奖励 抽卡道具 活动名称 活动类型**/**目的 玩法 奖励类型 2.5上半（UP角色：八重神子） 三界路飨祭 探索跑图类 【维稳】【回流】 使用小道具「睦疏之匣」驱散黑雾完成区域探索（使用对象包括怪物、挑战台、宝箱及采集物）获得奖励 四星武器（心海外观）及突破素材、原石、稀有养成道具和普通养成道具 冰呼雷啸 战斗挑战类（BOSS） 【维稳】 挑战龙蜥 原石和养成道具 神工天巧 DIY、社交、小游戏 【维稳】 玩家自由设计关卡秘境并分享给他人游玩闯关 原石和养成道具 2.5下半（UP角色：雷电将军/珊瑚宫心海） 曲生酌微梦 小游戏 【维稳】 作为酒保，根据顾客需求调制饮品获得奖励 原石、限定名片和养成道具 百人一揆 试用类、战斗挑战类 【维稳】 将试用角色与自有角色编成6组队伍，搭配限定buff，进行接力式闯关挑战 原石和养成道具 二、初探原神游戏内活动——版本活动规划 1. 表层规律总结 通过观察以上样本，我们可以不完全地归纳出几则原神版本活动的表层规律：\n1）活动规模上，分别以大版本和版本的半场为单位看\n【规律A】对于单个持续近6周的大版本，每个版本至少会有1个特殊大活动，这个活动可以是节日框架下有全新玩法的主题活动，也可能是以往特殊活动的复刻。 *“特殊”在此意指有特定主题或是独立于大世界探索、副本挑战等普通玩法以外的玩法。\n举例：2.0版本下半的塔防游戏复刻「机关棋谭」，2.1版本下半的逐月节系列活动，2.2版本上半带有肉鸽要素的新活「谜境悬兵」，2.3版本上半的雪山活动「皑尘与雪影」，2.4版本的新年活动「飞彩镌流年」，2.5版本的大活动「三界路飨祭」等等都证明每个版本都存在一个大活动（尽管1.x的版本不在样本范围内，但大多也是这样）\n【规律B】对于单个版本的上下半场，基本是由一个体量较大的活动（一般为战斗/探索）+1-2个休闲/消耗/社交的小活动组成 举例：2.2版本上半除了「谜境悬兵」以外，只有一个「镜花听世」音乐游戏；2.3下半的迷城战线以外是消耗活动「百货奇货」。\n【规律C】遇到版本自带内容较多的，版本上半活动会设置成较为轻量的类型；遇到节假日，活动内容会增多 举例：2.0开放稻妻时，上半的活动本质多为地图探索和挑战，不涉及全新玩法；2.1开放2个新岛时，上半活动玩法主要是挑战类和休闲类，体量适中。2.4春节版本，活动种类和数量明显增多。\n2）活动类型上，且看半个版本的活动\n【规律D】就各个活动的类型来说，基本每半场版本都会有至少1个战斗/副本/地图挑战类活动、1个探索跑图类活动和1个小游戏。 补充：除此以外，可能会融入基本类型或是构成独立活动的元素有解谜、社交联机、角色试用、资源消耗、掉落加成、登陆奖励。前三个会融入“基本款”的活动类型，后三个一般独立存在。\n举例：2.4春节版本的活动构成大致为上半[挑战+试用]、[小游戏]，下半[挑战]*2、[小游戏]*2、[休闲跑图]、[登陆奖励]，基本同规律一致（撇除春节假期活动内容增加的影响）\n2. 底层原则分析 但即使了解了上述规律，我们还是会发现自己在策划排布活动时有些手足无措。这或许是由于上述的安排是表面的、经验性的归纳（induction），只能让我们对整体样貌有个粗略认识（可以照葫芦画瓢），而真正规划时的需要采取的是演绎的思维模式（deduction），即先知晓举办活动的核心目的，从目的出发来细化架构。这意味着，我们还需要从活动核心目的入手，分析设计活动的原则。\n首先我们可以假定，原神游戏内活动的根本目的，首要是保持玩家活跃和提高在线时长，次主要目的是转化消费。这是因为，原神中的各类游戏内限时活动都不存在明显的氪金点（甚至大多也不伴随礼包更新、角色皮肤以外的付费活动），于是推测至少大多情况下，相比拉收，维持活跃才是其主基调。\n*关于活动目的的补充说明：原神是这个情况，但在很多游戏中，都存在付费拉收性质的活动和免费活动一起上线（比如对标原神的幻塔最近的活动中就有累充类限定礼包），因此这条原则并不适用于其他游戏中。\n于是，为了达到目的，提高玩家活跃度（一天上线一次，一次上线一天当然最好），最好的办法就是使得设计出来的活动是玩家乐意参加的、甚至是不得不参加的，也即兼顾到不同玩家需要。这其中“乐意参加”指向活动过程，比如内容优质可玩性高，而“不得不参加”指向活动结果，比如奖励符合需要。\n根据这个底层原则，可以结合玩家类别画出如下表格。前两列是根据不同维度区分出的不同种玩家，类别之间是可以重叠的，比如一个微氪玩家可以既重视强度，又关注玩法，还天天在社区整活。第三四列考量是指吸引某一类玩家的活动过程或结果，比如对于看重玩法的友友，游戏过程的玩法创新就很重要，也就是说吸引这类玩家的要素是好不好玩。「对应活动要素」列是这类玩家对活动的具体需要，比如休闲玩家希望流程短、奖励多，体现在活动中便是短流程和点击就送类（登陆奖励、消耗奖励）。总的来说，要尽可能满足「对应活动要素」的每一项，因为这意味着满足的活动需求更多。\n表：不同类型玩家对游戏活动各方面的需求\n3. 架空案例尝试 做一个小小的案例尝试：假设运营数据表明近期平均每日游戏时长本身就比较短的玩家间，活跃度进一步降低了，怎么通过活动提高他们的活跃度？ ***只是一个假想案例，实际情况不可能只考虑一类玩家的活跃，猜测尽可能要涵盖表格里的大部分需求。\n1）考虑目标玩家需求，选取活动要素：\n平均每日游戏时长短的玩家，可能没空参加流程长、耗时长的活动，但是仍有奖励的需求（在新卡池具有强吸引力的情况下，会需要攒抽卡道具），那么活动可以考虑的类型是——登陆奖励（只需上线）、短流程探索跑图（只需每日上线几分钟即可领奖）、小游戏（理由同前）、难度自选挑战（时间不够可以只拿低保奖励，同时也兼顾重度玩家）、消耗类。\n2）按照之前分析的基本规律ABD，先拟定几个活动类型，例如：\n上半为：探索跑图、战斗挑战\n下半为：版本大活动（包括小游戏）、消耗类\n3）针对目标玩家，给几个活动类型增加特征要素，例如：\n上半为：休闲短流程探索跑图、自选难度战斗挑战\n下半为：版本大活动（包括小游戏）、消耗类（每日更新）\n4）进一步单个细化活动（具体见后一部分）\n三、再谈单个游戏活动——拓宽活动设计思路的一种方式 1. 从「属性空间」看游戏活动 前文主要在分析如何确定一个版本有多少个、什么类型的活动，接下来转向单个活动的设计。在确定了活动类型以后，便可以重组大世界玩法和以往活动中的玩法，来制定新活动的细节设计。这里可以采取「属性空间」的理解方式来看待活动设计。\n简单来说，活动具有多种属性，比如活动目的、活动类型、主玩法、单元玩法、活动场景、奖励类型/方式、是否有联机模式、是否有难度分层。而每种属性下分别有不同的选项，就类型这一属性来说，就有挑战、跑图、小游戏等等选项。所以，可以把活动想象成一个n维空间（n=属性数），其中的不同点代表属性有所不同的活动。就用原神的几个活动举例：\n*简化过以后涉及到的属性有活动类型、活动场景、主玩法、单元玩法、附加要素。从属性空间角度看，两个活动本质其实很像。\n「谜境悬兵」的属性 = 挑战作为活动类型+稻妻副本挑战作为活动场景和主玩法+挑战台作为单元玩法+解谜作为附加要素1+roguelike作为附加要素2\n「迷城战线」的属性 = 挑战作为活动类型+活动专属副本作为活动场景和主玩法+挑战台作为单元玩法+解谜作为附加要素1+试用作为附加要素2\n由此更进一步，我们可以通过在属性空间中选取不同点（也就是更改每个属性选择）来尝试探索不同的活动设计。在此，先罗列一下能想到的属性可选项（自我反省：对游戏系统的认知不够全面，一时间无法给出所有的玩法）：\n活动类型：挑战（战斗/地图/解谜）、探索跑图、小游戏、掉落加成、累计登陆 活动场景：大世界（蒙德/璃月/稻妻/渊下宫等）、已实装副本（各类秘境）、家园、活动限定场景等 常驻主/单元玩法：打怪、挑战台、机关（仙灵台/元素方碑/雷种子大约都算）、供奉、区域BOSS、秘境副本、收集、家园、探索、钓鱼、烹饪、浪船、拍照、时间等 附加要素：解谜、社交联机、角色试用、其他游戏的玩法（roguelike、塔防、沙盒、策略） 奖励制度：难度达成、任务达成、积分目标、商店兑换 2. 应用活动属性空间的案例尝试 接下来，基于2.5版本活动「三界路飨祭」，我们尝试在其中几个活动「属性」中选取不同的选项，以此构思出一个玩法不同的新活动：**\n「三界路飨祭」的属性 = 探索跑图作为活动类型+渊下宫作为活动场景+供奉系统作为主玩法+大世界探索（打怪、收集、解谜等）作为单元玩法\n改变场景和主玩法，增加解谜要素，设计一个新活动：\n新活动X的属性 = 探索跑图作为活动类型+璃月作为活动场景+剧情任务作为主玩法+大世界探索（打怪、收集、解谜等）作为单元玩法+解谜作为附加要素1\n于是，一顿整理思路后——新活动X的玩法大致为：在活动期间，开启X活动任务。玩家需要通过完成分阶段解锁的特殊任务或特殊日常任务，收集「传闻」指引 -\u0026gt; 根据「传闻」指示前往大世界某地（需要小解谜），探索并获得解谜线索（文字、小道具、照片形式）-\u0026gt; 特殊任务全部解锁后，根据收集到的解谜线索，完成大地图解谜，解锁剧情结局。\n*反思：此活动有点像旷野之息的主线任务、原神任务「寻找画家的颜料」、海岛找壁画和归离原圆盘宝藏解谜（都是根据照片找位置），但是相比之下自由度低不少，所以更面向偏重度的/爱好解谜/爱好剧情的玩家。\n小结与反思 整篇文章的架构上，开头框定了讨论范围并且简单介绍了原神近几个版本的活动；第二部分侧重于发掘版本层面上的活动节奏，一方面总结了每个版本活动规模、类型的经验性规律，另一方面提出了这些规律的核心——兼顾到不同玩家需要来达到促活等目的；第三部分，从版本层面走向单个活动的层面，分析怎么拓宽活动设计思路，最终落足于“属性空间”的方法；最后在附录里，尝试运用以上自己的总结分析，去实际“挑战”一个完整活动方案的设计（见附录：原神风花节活动设计草案）。\n但是回过头来想，不免觉得后两部分有些割裂，甚至矛盾。第二部分论述的起点是“目的”和“需求”——活动运营应当是有“目的”的，而为了达到目的，需要知道玩家的“需求”来安排一个个活动，也即“设置目的-调查需求-设计内容”。然而第三部分更像是给出了一种天马行空的、无特定目的的活动设计方式，它可以依靠每个属性的变化给出无数的活动玩法，但无法严格按照“设置目的-调查需求-设计内容”的顺序来策划活动，这实际上违背了第二部分的意图。\n不过，游戏本就是商业性和艺术性一体两面的奇妙存在，从“想法”出发的艺术创想和从“目的”出发的商业逻辑之间必然需要平衡，这点对于活动大概也是一样。要想平衡两者，或许只能寄期望于作为玩家、作为运营的经验积累。继续努力咯！\n附录：原神风花节活动设计草案 【活动目的】提高用户活跃、留存\n【活动类型】见下表\n【目标用户】全体玩家（*奇趣秘园需要lv16以上，联机功能开启）\n【玩法说明】\n此次风花节活动共分为两个部分：「万物风华」和「奇趣秘园」（复刻）。下面主要介绍前者。\n大活动名 包含的小活动 活动目的/类型 活动内容/玩法 设计原因 万物风华 累计登录奖励 促活/留存 累计登录，领取奖励 其余小游戏比较零散，需要配合留存类活动，保持用户上线频率 音乐小游戏 （风物之歌复刻） 拉新促活/小游戏 基本玩法同上次，完成音游挑战，达成不同难度积分挑战可获得限定道具和相应奖励（已获得道具玩家则只有奖励） 【新增机制】活动期间，每通过一首音游挑战，便可以抽取随机音游技能效果（buff），效果包括不同程度的完美判定和积分加成。 【复刻原因】对于入坑晚、错过21年音游限定道具的新玩家较有吸引力，可以起到促活（以及回流）的作用。 【新增机制原因】增加音游随机性、减少反复刷分的枯燥感；帮助不适应高难度的玩家，用buff来降低难度；减少“制作组吃老本、不设计新活动”的负面舆论 剧情向系列任务 促活/剧情任务为主，探索为辅 以“风”和“时间”为主题的蒙德剧情向系列任务，分阶段开放。玩法涉及滑翔/时间系统/射击/小挑战。 完成流程后有每日更新的npc小彩蛋（类似海灯节钟离）。 在大世界开展，减少活动割裂感（其实这一系列活动都是） 分阶段开放（每次开放时间和其他几个活动错开），作为提升留存的一种途径 （可选）绘画小游戏 拉新促活/小游戏 完成前置任务「尘风捎信来」获得尘歌壶留言板小道具（类似《动物森友会》可以画画写字的留言板）。 在活动期间达成相关任务条件（例如拜访xx旅行者并留言），即可领取奖励。 考虑到音游限定道具的复刻可能给老玩家带来不满，也可以换成/增加另一个全新限定道具小游戏。 绘画和音乐一样都是很好的二创题材，借此激活二创社区后或许可以还达到拉新的效果 【效果预估指标】\n涉及指标：（针对促活类活动）日活跃用户数、活跃率、活跃用户时长；（针对留存类活动如累计登录）留存率、留存用户活跃率\n预估：\n* 因为没有历史数据，无法采取绝对值的预估，因此会把过往活动数据作为基准值来衡量。\n* 估计得比较保守，因为对这些数字的增量级别没有概念（求生欲拉满）\n1）日活跃用户数数据高于2.3上半「皑尘与雪影」10-20%，活跃率大致相同或略高，活跃用户时长推测会增加20-50%\n说明：DAU选择和「皑尘与雪影」活动比较是因为两者都有几个小游戏并且包含大世界探索元素，尽管不是严格意义上的等同。之所以此次活动预估DAU数据更高，是因为还带了留存活动（登陆），推测可以带动活跃率。用户时长预计提高是由于本次活动中的联机要素，单局联机游戏时长（算上等待、网络和游戏玩家的整活能力等因素）显著长于「皑尘与雪影」的小游戏。\n2）和2021年节日活动「风花的馈赠」相比，预计活动7日留存会提高至少50%，留存用户活跃率提高10-30%。\n说明：前者是考虑到新增的登陆奖励活动、主活动中每日更新的彩蛋，后者是考虑到这次活动中和去年活动的可类比的活动，玩法上都有新增机制，因此可能会一定程度提高活跃率。\n【其他说明】\n因为风花节整体基调是偏休闲、趣味、轻松的，所以设计上没有考虑数值战斗类的活动，基本是大大小小不同类型的小游戏。\n","permalink":"http://eimy.ink/zh/posts/2023/genshin-events/","summary":"曾经想过去搞游戏","title":"原神版本活动设计思路分析"},{"content":"最近终于完成了CS61C (fa20)，浅写个总结。\n英文是从我的repo直接抄来的\n课程结构 Centered on several great ideas in computer architecture. Specifically,\nThe first half of the course teaches what\u0026rsquo;s called \u0026ldquo;the old school machine structures\u0026rdquo;.\nHigh level language program - C [lec3-6]\nAssembly language program - RISC-V [lec7-13]\nMachine Language - still RISC-V, but without pseudo instructions [lec7-13]\nHardware architecture description - block diagrams, datapaths, cache, pipelining, virtual mem, etc. [lec17-27]\nLogic circuit description [lec14-16]\nBasically, that\u0026rsquo;s everything from the top \u0026ndash; the programmer-friendly high level language C\u0026ndash;, to the bottom arch \u0026ndash; circuits, logic gates, and transistors\u0026ndash;.\nIn terms of actual sequence, it\u0026rsquo;s like top -\u0026gt; middle, then bottom -\u0026gt; middle, and finally the two lines meet at around project3 (DIY a CPU datapath).\nThe second half teaches the new-school structures, which include more recent ideas of parallelism / high performance programming that companies hardware improvements.\ndata-level parallelism - SIMD [lec32], MapReduce, Spark, etc. [lec36]\nthread-level parallelism - threads, cache coherency, OpenMP, etc. [lec33-35]\ndependability [lec38]\nLab总结 跳过了几个没有成功setup的lab。\nLab1 Number Rep, C and CGDB: familiarize you with c and debugging tools Lab2 Advanced C: bit manipulations, memory allocation, and pointers in C Lab3 RISCV Assembly: ask u to figure out how simple C programs work on a lower level and write RISC-V assembly code Lab4 RISCV Functions, Pointers: still RISC-V practices, asking you to modify code to make the program work Lab5 Logisim: ~ build logic gates and practise with combinational logic Lab7 Caches: back to RISC-V, implement and optimize matrix-related functions to understand how cache works. This lab is valuable as it touches on one way to squeeze out performance. Lab8 OS, I/O, DMA, Disks, Networking \u0026amp; Virtual Memory: ~ play with a virtual memory simulator to understand how it works Lab9 SIMD Instructions: ~ work on single instruction multiple data (SIMD) \u0026ndash; write C functions and improve their performance with x86 intrinsics. It\u0026rsquo;s like inserting assembly code into C code. (Note that ARM users unfortunately would have to use ARM NEON intrin to be able to compile the programs.) Lab10 Thread Level Parallelism: have you experience parallel programing with C + OpenMP. Ask you to apply parallelism to the implementation of sum vector and dot product C funcs. 后记 课如其名，这门课最重要的是几个great ideas in computer architecture，是一层一层往下理解计算机的工作原理，其次才是掌握具体的实现细节（不是说不重要，是ideas \u0026gt; implementation）。但可能是因为课程设定是体系结构入门+老师都有ee背景，感觉好多地方通识性质很强，且是从硬件设计角度切入的。于是之后还打算去补一下15-213的csapp。\n关于笔记：本来在考虑整理笔记，但想了下61c里对我比较重要的知识都没办法系统性整理，或者说意义不太大，理由同上。比如C和RISC-V的语法没必要全部照抄一遍，OS部分大多是概念，datapath的部分很多又已经给了discussion notes，最后的并行也只教了冰山一角。\n其他注意事项：20fa的版本里Bora负责的部分听起来稍吃力一些，但两位老师讲得都还是很好的。以及，m芯片带来了少许麻烦，中间碰到需要用x86指令相关库的时候还得被迫学一遍arm的对应指令（btw cgpt翻译是可行的）。\n进度 计划30个自然日内完成——顺利实现，虽然实际span将近两个月。\n【0611】setup, lab00 【0615】lec1\u0026amp;2 【0616】lec3 【0617】lec4 【0625】lec5, lab01 【0626】lec6 【0627】proj1A 【0702/03】proj1 Fin 【0704】K\u0026amp;Rch1-2 【0705】lec7+8.1, lab2 【0706】disc2 【0715】lec8-10 【0716】lab3 【0719】disc3, disc4 【0724】proj2 partA 50% 【0725】proj2 partA fin 【0801】lec11-13 【0802】disc5, lab4, lec14-15 【0803】lecs16+SDS State Logic handouts, lec17 【0804】lab5, lec 18-19 【0805】lec20-27 (fin CPU Pipelining Caches), disc6-8 【0806】disc9, lab7, lec28-2931 (fin OS VMi) 【0807】lec30-31(VMii I/O), disc10, lab8, disc11 【0808】lec32-35 (SIMD/MIMD, Parallelism), lec36-38 (MapReduce, WSC, RAID) 【0809】disc12, lab9, lab10, disc13-14 【skipped due to compatibility probs】proj4, proj3, lab6, lab11 ","permalink":"http://eimy.ink/zh/posts/2023/cs61c/","summary":"虽然和近期该做的事无关，但是看起来特别有趣所以还是抽时间学了","title":"CS61C 完结记录"},{"content":"在aws官网上找到了amplify的项目型教程，这个似乎还没有汉化，玩的时候顺便记录一下。\nAWS Amplify简介 Amplify也是一个提供静态资源网络托管的综合平台【Ref】\n在几分钟内为 Web、iOS 或 Android 应用程序创建具有身份验证、数据、存储等功能的 AWS 后端\n通过从设计到代码的 Figma 集成直观地构建前端 UI，并通过点击将 UI 连接到后端\n只需几次点击即可轻松部署和托管快速、安全且可靠的网站和服务器端渲染的应用程序\n将应用程序扩展到 175+ AWS 服务，支持新的使用案例、DevOps 实践和用户增长\n简单来说，除了以下几个特点以外，和Netlify这些差不多，也是一定用量免费：\nAWS Amplify特点 支持可视化开发全栈网站或应用程序 支持部署移动应用程序，Netlify不支持 生态完善，使用其他 AWS 服务比较方便 Amplify上手教程 主要完成托管网页和部署后端，除此以外添加了AWS验证和存储服务作为附加功能示例。\n注：以下只展示amplify相关的配置部署流程，App本身的代码不全，具体参照原文。\n前置步骤 创建一个前端应用或者用已有的\npush到github repo\n部署前端 注册AWS账号（需要可以扣$1的信用卡） 登录并找到AWS Management Console Get started页 - (host your web app) 点get started 选择基于github部署，确认repo/branch信息然后next*N save and deploy，完成。后续每次修改并push后会自动更新网页。 完成页 安装Amplify CLI \u0026ndash; 添加/管理AWS服务 安装CLI 可以通过Amplify的CLI给项目添加AWS提供的服务。\n1 2 # 安装cli npm install -g @aws-amplify/cli 插曲：ARM Mac不适配\n这里M1/M2的mac可能会碰上cli安装成功但命令没反应的问题，不知为什么至今没适配好。解决方案参考issue#10193：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # solution 1: 安装rosetta（不一定有用） softwareupdate --install-rosetta # solution 2: git clone旧版本 @danrivett（也不一定有用） # 环境：amplify-cli@v10.4.1 node@16 git clone https://github.com/aws-amplify/amplify-cli.git cd amplify-cli git checkout v10.4.1 # Avoids building the dev branch but builds a release tag; update as necessary yarn \u0026amp;\u0026amp; yarn build rm ~/.amplify/bin/amplify ln -s $(pwd)/packages/amplify-cli/bin/amplify ~/.amplify/bin/amplify # solution 3: release页手动下载安装旧版本 @kzetxa # 环境：node@16.12.0, Amplify 10.3.1, macOS Monterey 12.6 # 1. deleted the binary at /usr/local/bin/amplify # 2. renamed the binary inside the package downloaded # 3. moved it to the location where the old deleted binary was sudo chown -R $(whoami) ~/.amplify 三个都试了，最终成功的是第三种，环境完全同上。后续看了眼活动，似乎还是从x86转译的。\n配置CLI 1 2 3 4 5 6 7 8 # configure amplify configure # 1. 需要跳转网页登录console # 2. 选择地区 # 3. 回到网页创建用户 # 需要赋予programmic access # 记录access key id和secret access key 后续各种添加服务都需要用cli。以及现在可以一键传送到console了\n1 2 # in local terminal amplify console 部署后端 开启amplify studio 回到应用页 - backend environments - get started - launch studio - 在terminal运行local setup的命令（从网页上复制）\n然后选择配置项：\n1 2 3 4 5 6 7 8 ? Choose your default editor: Visual Studio Code ? Choose the type of app that you\u0026#39;re building javascript ? What javascript framework are you using react ? Source Directory Path: src ? Distribution Directory Path: build ? Build Command: npm run-script build ? Start Command: npm run-script start ? Do you plan on modifying this backend? Y 增加后端构建配置 1 2 3 4 5 6 7 8 9 10 11 # App settings \u0026gt; Build settings # 增加backend的配置 ... backend: phases: build: commands: - \u0026#39;# Execute Amplify CLI with the helper script\u0026#39; - amplifyPush --simple frontend: ... 例：添加AWS服务-验证 应该是为了展示添加aws配套服务很方便，这个教程专门为note应用添加了auth功能。\n命令行添加服务 1 2 3 4 5 # in local terminal # create the authentication service locally amplify add auth # deploy it amplify push --y src/index.js中应用服务 1 2 3 4 // in `src/index.js` import { Amplify } from \u0026#39;aws-amplify\u0026#39;; import config from \u0026#39;./aws-exports\u0026#39;; Amplify.configure(config); 导入src/App.js 导入类似这样的（一个只有验证的sample）\n1 2 3 4 5 6 7 8 9 10 import \u0026#34;@aws-amplify/ui-react/styles.css\u0026#34;; import { withAuthenticator } from \u0026#34;@aws-amplify/ui-react\u0026#34;; function App({ signOut }) { return ( /* 中间省略 */ ); } export default withAuthenticator(App); 最后push到远程仓库\n添加后端数据库 添加graphgl api 1 2 amplify add api # 选择graphql 本地配置 在/amplify/backend/api/\u0026lt;api_name\u0026gt;/schema.graphql中创建schema\n1 2 3 4 5 6 // sample： type Note @model @auth(rules: [ { allow: public } ] ){ id: ID! name: String! description: String } 部署服务 1 amplify push --y # --yes: 省略所有命令行配置项，设置为default This will do three things:\nCreate the AWS AppSync API Create a DynamoDB table Create the local GraphQL operations in a folder located at src/graphql that you can use to query the API 在前端send query 例：\n1 2 3 4 5 6 7 8 9 async function deleteNote({ id }) { const newNotes = notes.filter((note) =\u0026gt; note.id !== id); setNotes(newNotes); // query await API.graphql({ query: deleteNoteMutation, variables: { input: { id } }, }); } 例：使用AWS存储服务 展示如何使用Amazon S3（AWS simple storage service）存储图片数据\n添加存储服务 1 amplify add storage 修改schema 1 2 3 4 5 6 7 // amplify/backend/api/notesapp/schema.graphql type Note @model @auth(rules: [ { allow: public } ] ){ id: ID! name: String! description: String image: String // update } 在app中使用存储 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // update imports import { API, Storage } from \u0026#39;aws-amplify\u0026#39;; import { Button, Flex, Heading, Image, Text, TextField, View, withAuthenticator, } from \u0026#39;@aws-amplify/ui-react\u0026#39;; // update functions, e.g. createNote async function createNote(event) { event.preventDefault(); const form = new FormData(event.target); const image = form.get(\u0026#34;image\u0026#34;); const data = { name: form.get(\u0026#34;name\u0026#34;), description: form.get(\u0026#34;description\u0026#34;), image: image.name, }; // put image into storage if (!!data.image) await Storage.put(data.name, image); await API.graphql({ query: createNoteMutation, variables: { input: data }, }); fetchNotes(); event.target.reset(); } 部署服务 1 amplify push --y # --yes: 省略所有命令行配置项，设置为default 完 ","permalink":"http://eimy.ink/zh/posts/2023/aws-amplify/","summary":"playing with AWS","title":"AWS Amplify记录"},{"content":" 又名：Gitlet in Hindsight: Why I Suggest U Always Read the DON\u0026rsquo;Ts Part in Spec First\n花了几天补票了61b的知名项目Gitlet——60页重量级spec面面俱到（笑），项目内容自带科普性，覆盖从系统设计到集成测试的每种技术基础普及和训练，不愧是该课史上评价最高的pj。\n【指路】UCB CS61B-21SP-Gitlet\n项目概述 Gitlet是一个版本管理系统，仿照主流系统Git的功能并实现了其部分基本命令，包括init, add, commit, rm, checkout, branch, reset, rm-branch, merge等。\n作为一个课程个人项目，开局仅有几个必要的类.java和几行代码样例，要求根据需求自行设计并完成系统、对象方法、数据结构和少量算法的构造。\nGitlet版本控制原理 Git（let）的版本控制说白了就是「怎么保存某个版本」和「怎么切换到某个版本」的问题。可以从由上至下三个层面理解这两个问题：一是从最上面的用户层面；二是从对象层面；三是从文件读写层面。\n从设计上来说这三层之间应该存在abtraction barrier。也就是说用户使用命令时不需要知道也不能操作对象、指针这些，对象之间也不应该出现文件读写操作。\n用户层面 先是一些上层发生的事情，也就是用户能知道的部分。\ngit初始化干了什么？在当前工作目录（CWD）创建一个.git的隐藏目录目录和里面的一些文件。 怎么保存文件的版本？每次commit时，获取所提交的文件的当前快照（snapshot），并保存在.git中。 怎么切换到指定的版本？使用像是checkout, reset 这样切换版本的命令时，git会根据给定的分支名/commit id等，在.git中查找对应的快照，然后把CWD中指定的文件或是整个目录还原成这个快照的样子。 对象层面 然后再看对象层是如何实现这几个步骤的。gitlet在一定程度上简化了git的目录结构，各个对象少存了一些元数据，但本质不变，就用gitlet举例了。下图里是.gitlet目录的结构示意。\ngitlet的版本控制实现用到了两类的对象：Commit和Blob。 每个Blob对象对应一个文件快照。 每个Commit对象对应一次commit。 怎么利用这些对象记录文件的版本？ 每次把文件加入staging area暂存区（add [file name]）时，会创建一个Blob对象存储当前的文件内容，然后把（文件名: 对应的Blob实例）映射关系丢到暂存区里。 每次commit一些文件时，会创建一个Commit对象，从暂存区把可以提交的映射关系保存进Commit对象中。每个对象里除了索引对以外还会记录其父Commit、时间戳、commit message等。 例子：下图中每个蓝色方块代表一个Commit对象，每个Commit对象中存有一个Map，里面记录了当前commit的文件对应的文件快照。比如Commit 1和Commit 2的Hello.txt都指向Blob 0，这就是说在两次commit时文件内容（快照）没有变化。 怎么实现切换到指定的版本？——移动指针 要让HEAD指针切换到另一个分支branchB的branchHeadCommit，这在对象层就等于：HEAD指针本来指向branchA上的某个Commit对象，现在让它指向另一个branchHeadCommit这个Commit对象。类似updatePointerToCommit(HEAD, branchHeadCommit)。 文件读写层面 最后看更低一层，文件读写层。因为执行一部分命令时要把Blob对象和Commit对象以及暂存区的当前内容存储到本地，这就涉及到两个问题：\n如何对象存成数据（方便后续需要的时候从文件中取出调用）？\n利用Java的序列化（Serialization）。Java里的序列化读写操作：\n在gitlet里，所有对象都是可以序列化存进文件里的，包括Blob、Commit和StagingArea（如有）。在.git里，它们被存放在/.git/objects/目录中。\n而指针变动实际是通过文件读写实现的（不需要序列化）。每个指针都是一个文件，文件里存着它指向的对象的id。在修改指针指向时，实际修改的是文件里的id。在.git里，它们被存放在.git/refs/目录中。\n1 2 3 4 5 6 7 8 9 10 11 /* Serialize a Model object */ Model m = ....; // 可序列化前提：Model类需要implements Serializable File outFile = new File(saveFileName); // 新建File try { ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(outFile)); out.writeObject(m); // 将对象写入steam out.close(); } catch (IOException excp) { ... } 1 2 3 4 5 6 7 8 9 10 11 12 /* Deserialize a Model object */ Model m; File inFile = new File(saveFileName); try { ObjectInputStream inp = new ObjectInputStream(new FileInputStream(inFile)); m = (Model) inp.readObject(); // cast object into expected class inp.close(); } catch (IOException | ClassNotFoundException excp) { ... m = null; } 如何查找并获取对象/修改指针指向？\nGitlet和Git都使用SHA-1（Secure Hash Algorithm 1）加密数据，产生一个160位的哈希值作为当前对象的id（40个十六进制数）。每个对象在创建时会根据自身的内容产生id，比如相同的文件内容经过加密会产生相同的id；并且它们保存的文件名就是它们的id。这意味着通过id就可以在目录中找到对应序列化过的对象。更重要的是，这就允许根据内容寻找文件的地址（content-addressable)。 关于对象获取，以获取Commit对象为例，步骤是：获得commit id（对象在构造时应有id字段） -\u0026gt; 根据id获取文件路径（因为都存放在指定目录下，根据id寻址） -\u0026gt; 反序列化文件。同理，修改就是修改对象内容后，再序列化写入文件。 关于修改指针指向，在文件读写层实际需要完成的操作是：获取targetCommit的id -\u0026gt; 把id写入HEAD指针对应的文件中。 （提醒自己）需要注意的是这些操作都应该封装在对象里，在主逻辑里不该出现commitMap.put(readContentAsString(commitPath), readContentAsString(blobPath))这种东西。写完翻别人实现的时候，看到有人是这样在对象层混用文件读写操作的，达咩。\n小结 以上是三遍不同的废话。版本控制系统类比一下基本就是：\n初始化版本控制系统 == 在当前工作目录放一个小盒子 保存文件的版本 == 每次提交时，把提交的东西拷一份存档放盒子里 切换当前目录/目录中某个文件到某个版本 == 在盒子里找对应的存档，拿出来放在CWD 其余的对象、指针和编码等等方式，都是用来精简每次拷贝的东西、加快盒子里找东西的速度的tricks（至少我是这么理解）：\nBlob对象 == 一个文件的存档 Commit对象 == 一张记录哪个时候该找哪个文件版本的小抄 Commit tree == 小抄们的目录大纲 SHA-1编码 == 给每个文件按照他们的内容起名（在快速对比文件内容、寻址上都有用） 指针 == 写着现在盒子里是哪个版本的标签 暴力存档谁都会（试想：paper_final_final_final.docx)，要说的话，我觉得精髓在于sha-1。\n思考 边写代码边记录的，比较乱\n关于spec阅读顺序 gitlet的项目说明很长，一次读完再开始不现实。如果再写一次，我会先看视频+扫读所有commands说明和avoids事项，然后边写边看。 spec里的「注意不要xxx」部分要仔细看，之所以写上去是因为大家真的会这样做，比如默认Map都是HashMap然后写出Heisenbug，实际为了维护顺序应该用TreeMap。←callback开头 关于设计 一开始需要整体地阅读spec，明确每个对象的作用和它们之间的常用交互方法，设计好了再开始实现。\n正面案例：在写\u0026lt;branch\u0026gt;命令的时候准备大改目录，但因为前面abstraction设计得还不错，除了File目录加一句以外什么都不需要改。\n保护abstraction barrier。上层对象之间的交互一定要避免使用底层操作。\n反面案例：前期直接在主逻辑里完成hashing、序列化，中间为了封装重构改了好久\n起名很重要。经过血的教训总结以下几点：\n统一性\u0026ndash;就像数据表连接一样，既然对象之间需要通信，那它们一定有一些共通的名字。反面案例就像是我一开始干的，把sha-1 hash得到的id，在不同类里写成shaName、shaId、hashName\u0026hellip; 直观性\u0026ndash;变量名越具体越好，比如map可以写出keyToVal，不然想起来费劲 泛用性\u0026ndash;方法最好不要太具体，这样再别处调用的时候也能想起来。比如getHead getMaster就可以写成getCommit/getPointer。 其他 可以读下git的源码寻找better practice，虽然只看spec也基本够用。 数据 time and space 代码总行数大约1k；时间上大概花了4.5天，wakatime统计的用时是40小时左右，虽然里面十多个小时在debug（。）这方面我记得Josh课上有分享同学的数据，大部分人完成时间也差不多是30-40hrs。\n从统计上看gitlet体量不大，不过考虑到它要求独立完成且涉及到了设计、单元和集成测试、makefile、java file i/o、算法、编码、甚至git本身的训练，还是非常rewarding的。\nAutograder情况 通过了所有功能性测试。Fail的几个Extra-Credit，style (mainly naming，下次一定)和迟交我认为无伤大雅，就没有继续面向autograder编程。\n没有写EC的原因：1）到了后期很多指令都是组合前面的指令，边际效益低；2）gitlet中的remote指令和git相去甚远，不见得有助于学习git的底层逻辑；3）在de了一个Heisenbug以后心力憔悴。\n感想 Gitlet是一款我的世界名校震撼.jpg 就像开头吹的一样，我坚信大部分水平和我类似的人都能通过这个project收获很多，具体只要看一眼spec就知道了。\n技术上我太菜也没资格说什么，只能最后讲几句别的。Josh在不记得哪节课上分享过Gitlet的survey结果，印象深刻的是有一部分学生在这个pj上花了50+小时（就我个人经历，这远超出正常大一的一门课的一个课设的workload），但是最后给了负面评价的只有寥寥几人，Josh好像还单独拿出来表示抱歉了。从侧面反映了The Gitlet Grind的价值。\n61B至此完结，感恩开源！继续肝别的去咯\n附录 以下是从写的readme中转载的my gitlet设计方面的说明\nDesign Abstraction Principle An issue with version control systems:\nRequires cumbersome operations like hashing, serialization, map operations, directory concatenation, file I/O, etc.\nSolution:\nOn a higher level, involve only communications between objects (between Blob and Commit, there should only be Blob b = commit1.get(filename)) Eliminate the need to dive into low-level operations through encapsulation. i.e. Outside the class of that object, never try to hash things, or modify maps inside Commit/Blob objects. E.g. The StagingArea supports common map operations. Upon put (fileName, Commit), it completes: read commit into commit id -\u0026gt; put into its map -\u0026gt; serialize itself and write into the file for staging. Persistence The directory structure looks like this:\n1 2 3 4 5 6 7 8 9 10 CWD └──.gitlet └── --commits/ # all commits ├──blobs/ # file content ├──branchHeads/ # branch heads | └──--master # master branch | ├──..\t# other branches ├──HEAD\t# HEAD commit ├──add # staging area for addition └──rm # staging area for removal The Main class is the entry class of the project. It is responsible for calling different functions according to given commands.\nThe Repository class will set up all persistance. It will\nCreate and initialize files and directories in the .gitlet folder if the directory does not exist; Handle all updates of HEAD , master, branchHeads and the serialization of two StagingAreas add and rm. Execute the commands / function calls from Main. The Commit class handles the serialization of Commit objects. It also deals with conversion between commit ids and commit objects. Each Commit records mappings of held file names and their corresponding file content. Specifically, it fulfil the following purposes:\nConstructs Commit objects; Serializes and saves Commit objects to the .gitlet/commits directory; Given a commit id, retrieves the corresponding Commit object. The Blob class handles the serialization of Blob objects. A blob is a snapshot of a file\u0026rsquo;s content at the moment of addition. For instance, a file named \u0026ldquo;hello.txt\u0026rdquo; can refer to different Blobs in different Commits.\nIts functions are similar to Commit, namely object construction, serialization and retrieval.\nThe StagingArea class stores files for addition and removal. A StagingArea works like a Java Map, stores mappings of file plain names to their blob ids, and supports basic map operations (remove, get, put). add and rm are StagingAreas for staged addition and removal respectively.\n","permalink":"http://eimy.ink/zh/posts/2023/gitlet-fin/","summary":"♪(´ε｀ )","title":"CS61B Gitlet 完结记录"},{"content":"日本中部旅游Plog ｜ 高山 富山 白川乡 先后拜访了富山-雨晴海岸、白川乡、高山市内。这段行程围绕巡礼展开，拉着朋友巡礼了几个非常喜欢的作品的取景地1。这次来日本可以说就是为了巡礼，等了好多年才有机会，对我来说比毕业意义重大。\n富山 Toyama 01: 等了五年的「ただ君に晴れ」圣地巡礼（雨晴海岸）\n天气特别好，海风凉爽\n高山 Takayama 02: 最最喜欢的动画「氷菓」的巡礼\n出门时只是为了找飛騨牛吃，回过神来已经坐在了冰菓咖啡厅\n后面还找到了op很多镜头的取景地点\n03: 高山一家叫「丸明」的飛騨牛店，连吃了两次，好吃得做梦都想追着牛啃\n白川乡 Shirakawa-Go 04: 某书上吹成网红的白川乡，其本体竟是寒蝉里的雏见泽村\n这么接地府的地方被当天堂拍..（但确实是一个很平静的村子）\n最后一点话\n这是第一次和朋友单独出国旅行。曾经去过欧洲北美东亚的几个国家，但每次回忆的时候发现旅游的细节都忘得差不多了，只剩下一些很朦胧的印象，于是就会责怪自己怎么这么不认真对待机会、是不是在仓促的行程中忽略了很多值得注意的文化风情etc。\n这次在路上一直反思，这些经历除了作为谈资还给我带来了什么，最后我得出的结论是「旅行的意义是去审视异己感，然后在差异中认识自己」。\n我对异己感的定义是两重的：第一是文化的差异，在进入异域文化的「日常」的时候，很容易发现当地人和自己的行为/观念差异，而「我认识的/做的为什么和他们不一样」值得细想。为什么日本人这么礼貌？为什么我讲汉语英文没事，但说日语的时候会下意识道谢鞠躬？文化的性质到底是「基因」还是「氛围」？环境和教育哪个对人影响更大？这都是很有趣的问题。\n第二是个人之间的差异，因为是在较长的时间内和朋友一起完成衣食住行的所有任务，矛盾很容易暴露出来（不是冲突的意思，是广义的矛盾），借这个机会，还可以在比较中确定自己到底在人格/性格/思维谱系中的相对位置。我觉得确实如此，这次旅行中好几次遇到「你为什么会这么想/怎么是这个反应」的时刻。盆友诧异我旅游还带电脑天天熬夜肝任务，我羡慕盆友可以很放松地享受生活和旅行；分享了我最近感兴趣的okr人生管理方法x，盆友说完全不能接受，觉得非常压抑受限，大家就是会有不同的思维方式。\n总之，旅行是非常个人的事情，它不是田野调查，没必要从中考察出什么社会现象文化理论，所以很模糊的体验也没问题，只要多想想所见人事物和自己的异同就算有收获（还有多吃好吃的 好想念鸟贵族）。虽然看的是外部世界，但目光最终是落在自己身上的。\n以上看起来非常故弄玄虚，实际到处玩的时候没想这么多，大部分时间在吃饭走路睡觉，小部分时间做些坏事，比如和朋友互坑2、享受日本人没发现我不是日本人的时刻3。说明日语水平提高了，一定要炫耀一下。\n「氷菓」——初中看的一部12年的轻改动画和「ただ君に晴れ」——一个18年的歌曲mv\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n因为有人想去大阪的八阪神社，但是长途跋涉把我带到了京都的八阪神社呢\u0026hellip;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n比如成功伪装土著帮日本人指路，比如成功伪装日本人点单\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://eimy.ink/zh/posts/2023/plog-japan-ii/","summary":"高山 富山 白川乡","title":"日本中部旅游Plog 2"},{"content":"日本关西-中部旅行Plog 大阪 01: 用荒诞的结束方式否定荒诞的本科时光（指缺席自己毕业典礼）\n02: 幼年卡比兽在马里奥餐厅进食珍贵影像\n03: 自学七年日语，归来仍是英文点单\n注: 看日本麦门菜单体验堪比阅读日文版元素周期表\n04: hogwarts里乌漆麻黑像回到了房间一样，真好.jpg\n05: (咒回4D电影候场）但如果我的咒术和kita一样，阁下该如何应对呢？\n注：「あなたの呪術が世界を救う」＝你的咒术将拯救世界\n","permalink":"http://eimy.ink/zh/posts/2023/plog-japan-i/","summary":"讲五个不好笑的冷笑话","title":"日本关西旅游Plog 1"},{"content":"闪现！四年后 录取通知书 - 19年报名@老番茄的活动时拍的 毕业纪念纸 - 23年6/13的毕业典礼 零碎的感想 有很多遗憾：在一个巨大的错误中试错，试一个错一个\n明确了价值：四年后终于可以坚定地说出我追求的不是“自由而无用”（民间校训）\n四年后还是没能和专业和解，我的黑灰底色还是和它格格不入，但感谢它把我染成五彩斑斓的黑（？\n典礼上老师的赠言: I guess this is goodbye -- from Lost in Translation 岂止lost in translation，大多事情是lost in expression，语言里找不到明确的答案（所以润了）。\n最近期末叠加毕业，忙得没时间整理东西。明天又要考试，认真学了四年还是那么地不擅长，最后只能归结为没有天赋了哈哈（A-是我对自己本科学力的全部理解）\n","permalink":"http://eimy.ink/zh/posts/2023/graduation/","summary":"「がんばってもそれが公正に報われない社会があなたたちを待っています」","title":"Graduation"},{"content":"Hashing 这一课笔记的逻辑结构和课件略有区别，总体根据最初设定的两个优化目标分为两部分。\n第一部分找到一种数据结构（hash table），解决了search tree的generalization的问题；第二部分优化这个结构，解决了performance的问题。\nLimits of Search Tree sets requires the objects to be comparable performance not good enough (Θ(log N)) 因此之后的改进主要在这两方面：1）generalize to more types of objects；2）节约内存、降低复杂度。\nGeneralization to various objects 第一部分找到一种数据结构（hash table），解决了search tree的generalization的问题\nA Better Structure: Data Indexed Sets 这一部分从generalization入手，从Data Indexed Integer Set (Int -\u0026gt; index）引入，扩展到Data Indexed English Word Set（EN word -\u0026gt; Int -\u0026gt; index），最后一步步generalize到Data Indexed String Set（String -(based on ASCII)-\u0026gt; Int -\u0026gt; index）。\n首先想到的是Data Indexed Integer Set 缺点是它太浪费memory了，并且无法表示除了integer以外的其他对象 其次，为了能够表示其他种类的对象，通过进制转换将字母转换成integer的index。 在进制的选择上，为了防止index重复（collision），选择base \u0026gt;= N（item种类） 比如将27作为base转换26个字母 因此就有了Data Indexed English Word Set。 缺点是这个方法无法应对字符（“eGg!”） 为了进一步从英文单词generalize到字符，采用ASCII码/Unicode将String转化为index。 于是进化出了Data Indexed String Set 缺点是index过大，会造成overflow，超过java的限制（+2,147,483,647）。 而overflow会进一步导致index重复（collision） 为了“解决”这个generalization部分的遗留问题，将引入hash code的编码方式。\nHandling Collision: Hash Code and Hash Table Definition:\na hash code “projects a value from a set with many (or\neven an infinite number of) members to a value from a set with a fixed\nnumber of (fewer) members.”\n首先“解决”刚才的overflow导致collision的问题。 turns out collision无法避免，只能应对。\n应对方法是把hashcode相同的item放进一个bucket。可以用LinkedList、ArrayList、ArraySet等等。 bucket在示意图里是每一个index格子所指向的一筐item。 于是它又进化成了Separate Chaining Data Indexed Array 终于处理好了collision——这也意味着generalization部分的问题至此彻底解决。\nImproving Performance 第二部分优化hash table的结构，解决了performance的问题\n接下来就是开头的第二个问题performance（memory \u0026amp; complexity）。\n这个问题可以分解为两部分，一是几万个bucket太浪费memory，二是complexity可能会很高（比如所有的item都连成了一串）。\nSaving Memory 为了节约memory，改成只用N个bucket。\n方法是HashCode % NumBuckets把hashCode重新归档。比如，只用10个bucket，就把hashCode%10：\n以上完成的就是Hash Table。完整流程示意图如下：\nReducing Complexity 为了让每个bucket里的平均item数量保持恒定，需要动态改变bucket数量——resizing。\n具体来说，\n已知N为item总数，M为bucket总数 设定load factor = N / M （即最多平均每个bucket里有几个item） 下为示意图，如果load factor ≥ 1.5，将bucket数M翻倍：\nFinale: Hash Table Runtime Analysis Worst Case Runtime:\ncontains(x) add(x) Bushy BSTs Θ(log N) Θ(log N) DataIndexedArray Θ(1) Θ(1) Separate Chaining Hash Table With No Resizing Θ(N) Θ(N) \u0026hellip; With Resizing Θ(1)† Θ(1)*† *: Indicates “on average”. †: Assuming items are evenly spread. 这里尤其要注意，如果hashCode()不好（无法平均分配items），那么还是会像without resizing的HT一样有Θ(N)。\n有了resizing后，worst case operation数\n不再是遍历全部连成一串的N个item【$\\Theta(N)$】 而是遍历最多N/M个item【$\\Theta(N/M) = \\Theta(1)$】 由此performance的问题也解决了。\n(Op) How to Compute a hashCode Q: How to write a good hashCode() method?\nA: Use a small prime base, for it yields better randomness and cost less to compute\n下面是两个hashCode()方法的例子：\n1 2 3 4 5 6 7 8 9 10 // Hashing a collection @Override public int hashCode() { int hashCode = 1; for (Object o : this) { hashCode = hashCode * 31; // elevate the current hash code hashCode = hashCode + o.hashCode(); // add new item’s hash code } return hashCode; } 1 2 3 4 5 6 7 8 9 10 // Hashing a recursive structure (e.g. a tree) @Override public int hashCode() { if (this.value == null) { return 0; } return this.value.hashCode() + 31 * this.left.hashCode() + 31 * 31 * this.right.hashCode(); } ","permalink":"http://eimy.ink/zh/posts/2023/hashing/","summary":"\\hashbrown/\\hashbrown/","title":"61B Notes - Hashing"},{"content":"B-Tree, LLRB Hug一般会顺滑地衔接/引入知识点，但这些衔接部分写在笔记里多少有点啰嗦，所以这里会略写。\nBST的局限 先引入两个BST的属性：height和average depth height：determines the worst case runtime to find a node average depth：determines the average case runtime to find a node 然后看看BST的各种属性 Worst case $ \\Theta( N)$ height Best case $ \\Theta(log N)$ height Random trees have $ \\Theta(log N)$ average depth and height (bushy) 随机情况下表现还不错，问题是现实中会不断从右边insert数据，这会导致不平衡，比如 add(“01-Jan-2019, 10:31:00”) add(“01-Jan-2019, 18:51:00”) B-Trees / 2-3 trees / 2-3-4 trees 接上，为了防止不平衡，我们不断把新的key insert进原来的node中，然后进行node splitting。\n于是就出现了新的树B-trees。\nB-trees should be called juicy trees.\n定义 B-tree是一种自平衡树，总的分为以下几类： B-trees of order L=3 (like we used today) are also called a 2-3-4 tree or a 2-4 tree（如图） B-trees of order L=2 are also called a 2-3 tree （如图） B-trees of large L are used in practice for databases etc. 构成机制 （node-split）\n1/ Insert into a leaf until the number of keys exceeds L\n2/ In case of excessive keys, send the second (1 st) node up, and split the node\n几个例子：\n【非连锁反应】 【涉及到连锁反应】 【涉及到root split】 性质 （or Invariants）\n基于以上构成机制，可以得出B-tree的一些性质。B-trees are balanced in that:\nAll leaves must be the same distance from the source\n考虑：涉及到root-split，height+1，所有node都会下降一层； 如不涉及root-split，height不变 A non-leaf node with k items must have exactly k+1 children\nRuntime Analysis Height：Θ(log N) for both worst cast and best case best case是每个node都有L个items（满的） $\\Rightarrow$ Height grows with $\\Theta(log_{L+1}N)$ worst case是每个node只有1个item $\\Rightarrow$ 所以和BST一样Height grows with $\\Theta(log_2N)$ operation runtime: contains() and add() are both $O(log N)$ 【worst case】contains(): $C = （层数）log_{L+1}{N} \\space·\\space （node \\space per \\space layer）1 \\space·\\space （work \\space per \\space node）L$ 【worst case】add(): 多了一些split operation，但化简后是一样的 B-Tree的局限 猜猜为什么上面没有代码实现部分\nLeft Leaning Red-Black Trees 定义 A BST with left glue links that represents a 2-3 tree is often called a “Left Leaning Red Black Binary Search Tree” or LLRB\n可以理解为：LLRB是一种和某一个B-Tree对应的BST。具体备注：\nLLRBs are normal BSTs! There is a 1-1 correspondence between an LLRB and an equivalent 2-3 tree. The red is just a convenient fiction. Red links don’t “do” anything special 性质 和BST一样\n尤其需要注意的几个性质：\nAll leaves must be the same distance from the source（只数black links） No node has two red links 构成机制 原理上是基于2-3 tree，将node中较小的item下移，如 实际上，因为不可能先实现2-3 tree，再调整成LLRB。在代码中会利用red link, rotate, flip color直接实现LLRB：\nalways use a red link when inserting （类比在2-3中会先往node中添加item）\nwhen inserting items on the right, rotateLeft()\nwhen inserting on the left twice, rotateRight()\n(a new rule) allows representing temporary 4-nodes as BST nodes with two red links\nIn case of tmp 4-nodes, flipcolor().\nIf a rotation or flip operation cause an additional violation, fix it\n代码实现 以下是这些方法的代码实现，包括调整过的Node Class、put()、新增的rotate系列、flipColors()和isred()。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 // LLRB insertion (p.439) public class RedBlackBST\u0026lt;Key extends Comparable\u0026lt;Key\u0026gt;, Value\u0026gt; { private Node root; private class Node // BST node with color bit (see page 433) private boolean isRed(Node h) // See page 433. private Node rotateLeft(Node h) // See page 434. private Node rotateRight(Node h) // See page 434. private void flipColors(Node h) // See page 436. private int size() // See page 398. public void put(Key key, Value val) { // Search for key. Update value if found; grow table if new. root = put(root, key, val); root.color = BLACK; } private Node put(Node h, Key key, Value val) { if (h == null) { // Do standard insert, with red link to parent. return new Node(key, val, 1, RED); } int cmp = key.compareTo(h.key); if (cmp \u0026lt; 0) { h.left = put(h.left, key, val); } else if (cmp \u0026gt; 0) { h.right = put(h.right, key, val); } else { h.val = val; } if (isRed(h.right) \u0026amp;\u0026amp; !isRed(h.left)) { // 基于BST只需要修改这里三个clause h = rotateLeft(h); } if (isRed(h.left) \u0026amp;\u0026amp; isRed(h.left.left)) { h = rotateRight(h); } if (isRed(h.left) \u0026amp;\u0026amp; isRed(h.right)) { flipColors(h); h.N = size(h.left) + size(h.right) + 1; return h; } } // some omitted methods within RedBlackBST Class private boolean isRed(Node x) { if (x == null) return false; return x.color == RED; } private Node rotateLeft(Node h) { // rotateRight() is similar Node x = h.right; h.right = x.left; x.left = h; x.color = h.color; h.color = RED; x.N = h.N; h.N = 1 + size(h.left) + size(h.right); return x; } private void flipColors(Node h) { h.color = RED; h.left.color = BLACK; h.right.color = BLACK; } } // delete比较麻烦，详细见p.441. Runtime Analysis Height: $O(logN)$ contains(): $O(logN)$ insert(): $O(logN)$ $O(logN)$ to add the new node $O(logN)$ for rotation and color flip operations per insert （化简后忽略常数 所以还是 $O(logN)$） Summary of search trees 逻辑梳理 Cited from the slides [lec 18, 19sp]\nBinary search trees** are simple, but they are subject to imbalance.\n2-3 Trees (B Trees) are balanced, but painful to implement and relatively slow.\nLLRBs insertion is simple to implement (but delete is hard).\nWorks by maintaining mathematical bijection with a 2-3 trees. Java’s TreeMap is a red-black tree (not left leaning).\nMaintains correspondence with 2-3-4 tree (is not a 1-1 correspondence).\nAllows glue links on either side (see Red-Black Tree).\nMore complex implementation, but significantly (?) faster.\nComplexity/runtime对比 WC = worst case\nBST B-Trees LLRB Height $O(logN)$ $\\Theta(logN)$ $O(logN)$ WC：$O(N)$ WC：$O(log N)$ WC：$O(log N)$ contains() $O(logN)$ $O(log N)$ $O(logN)$ WC：$O(N)$ WC：$O(log N)$ WC：$O(log N)$ insert() $O(logN)$ $O(log N)$ $O(logN)$ WC：$O(N)$ WC：$O(log N)$ WC：$O(log N)$ 说明：B树和LLRB是self-balanced（不会出现BST变成LinkedList的极端情况），所以比较快。\n总的来说：\nB-trees的自平衡避免了BST的worst-cast complexity， 而LLRB不仅继承了B-trees的自平衡特性，还继承了BST易于实现的特点。 ","permalink":"http://eimy.ink/zh/posts/2023/b-tree-llrb/","summary":"B树と旋转と红黑色树","title":"61B Notes - B-Trees \u0026 LLRB"},{"content":"Reference是19sp的lec slides。\nTrees 首先引入abstract data type的概念，然后递进/逐步优化式地介绍三种树（BST, B-Tree, LLRB）。\n笔记会分成两部分，这一篇只整理ADT和BST。\nAbstract Data Types（ADT） An abstract data type is defined by its operations, not implementations. 层级 例子 ADT Deque; DisjointSets Implementations of ADT ArrayDeque, LinkedListDeque;\nQuickFindDS, WeightedQuickUnionDS Operations of ADT size(), get(), addFirst(Item x), etc. Among the most important interfaces in the java.util library are those that extend the Collection interface. 关系如图。 List Set Map 这次关注的是两个tree相关的，TreeSet和TreeMap。 Binary Search Tree BST缘起 问：怎么改进linkedlist，才能更加快速地完成搜索？\n答案是：1）将entry point设置在中间而不是一端 2）从中间往两端 3）跳跃地遍历（如图）\nBST定义与性质 A binary search tree is a rooted binary tree with the BST property. Tree properties: A set of nodes, One path between any two nodes Rooted trees prop: 除root外每个节点都只有一个父节点 root 一般画在最顶上 (for binary tree) 每个节点下只能有0/1/2个子节点 BST properties: Ordering: Every key in the left subtree is less than X’s key. Every key in the right subtree is greater than X’s key No duplicate keys allowed （路过一颗BST）\nBST Operations 介绍BST的三个operation。\nSearch / Find 代码实现 （看代码更方便）对比searchKey和T.key\u0026ndash;\u0026gt; 找到了！/ searchKey较小，search T.left / searchKey较大，search T.right\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // reference: Algorithms, p.399 /** Return value associated with key in the subtree rooted at x; * return null if key not present in subtree rooted at x. */ public Value get(Key key) { return get(root, key); } private Value get(Node x, Key key) { // helper if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp \u0026lt; 0) { return get(x.left, key); } else if (cmp \u0026gt; 0) { return get(x.right, key); } else { return x.val; } } Runtime Analysis Worst case（茂密的二叉树.jpg）runtime：$\\Theta(log{N})$ Tree Height：~$log_2{(N)}$ 这样考虑：每增加一层需要x2倍的节点 Insert 代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** Search for key. Update value if found; grow table if new. */ public void put(Key key, Value val) { root = put(root, key, val); } /** Change key’s value to val if key in subtree rooted at x. * Otherwise, add new node to subtree associating key with val. */ private Node put(Node x, Key key, Value val) { if (x == null) return new Node(key, val, 1); int cmp = key.compareTo(x.key); // compare searchKey to curKey if (cmp \u0026lt; 0) { x.left = put(x.left, key, val); } else if (cmp \u0026gt; 0) { x.right = put(x.right, key, val); } else { x.val = val; } x.N = size(x.left) + size(x.right) + 1; return x; } Insert.2 Runtime Analysis 应该和find一样。\nDelete 删除一共有三种情况：\n被删除的key没有子节点（\u0026ndash;\u0026gt;see \u0026ldquo;glut\u0026rdquo;, 直接断开连接）\n被删除的key有1个子节点（\u0026ndash;\u0026gt; see \u0026ldquo;flat\u0026rdquo;，把父节点的指针指向子节点）\n被删除的key有2个子节点（如图，找到predecessor或successor代替它的位置）\n代码实现 p.411 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 private Node min(Node x) {\t// 找到x下最小的节点\u0026amp;其子节点 if (x.left == null) return x; return min(x.left); } public void deleteMin() {\t// 返回删除最小节点后的root root = deleteMin(root); } private Node deleteMin(Node x) {\t// deleteMinHelper if (x.left == null) return x.right; x.left = deleteMin(x.left); x.N = size(x.left) + size(x.right) + 1; return x; } public void delete(Key key) { root = delete(root, key); } private Node delete(Node x, Key key) { if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp \u0026lt; 0) { x.left = delete(x.left, key); } else if (cmp \u0026gt; 0) { x.right = delete(x.right, key); } else {\t// 假设已经找到了Node P if (x.right == null) return x.left; // 确认P有无sub-nodes，A)有0/1subnodes则返回它 if (x.left == null) return x.right; Node t = x;\t// B) 有2个nodes就需要调整一下树 x = min(t.right); // 1. find the new substitute for the deleted node P x.right = deleteMin(t.right); // 2. connect the updated right nodes to the new P x.left = t.left;\t// 3. connect the original left sub-nodes to the new P // 注意这里的顺序matters！ } x.N = size(x.left) + size(x.right) + 1; return x; } Runtime 应该和前面是一个数量级，因为只是额外多了一些修改步骤。\nBSTSet v.s. BSTMap 这部分是Lab9 BSTmap的引入。\nBSTset和BSTmap结构相同（tree），区别是把每个node改成了用map来表示（如图）。\n","permalink":"http://eimy.ink/zh/posts/2023/bst/","summary":"ヽ(´o｀；","title":"61B Notes - ADT and BST"},{"content":"注：本文原文为英语，由ChatGPT翻译成中文。\n计算$\\Theta (f(N))$的技巧 示例1：一个For循环 1 2 3 4 5 6 int N = A.length; for (int i = 0; i \u0026lt; N; i += 1) for (int j = i + 1; j \u0026lt; N; j += 1) if (A[i] == A[j]) return true; return false; 方法1：计算操作次数（精确计数） \u0026ldquo;==\u0026ldquo;操作的总成本/操作次数为： $$ C(N)=1+2+3+\\dots+(N-2)+(N-1) = \\frac{N(N-1)}{2} $$ 因此，运行时间为$\\Theta (N^2)$。\n方法2：几何可视化 （想象彩色方块-由于是一个三角形区域-运行时间为$\\Theta (N^2)$。）\n示例2：另一个For循环 1 2 3 4 5 6 7 8 public static void printParty(int N) { for (int i = 1; i \u0026lt;= N; i = i * 2) { for (int j = 0; j \u0026lt; i; j += 1) { System.out.println(\u0026#34;hello\u0026#34;); int ZUG = 1 + 1; } } } 方法1：通过可视化找到界限 绘制0.5N（下方虚线）和4N（上方虚线）的轨迹\nC(N)将位于这两条线之间\n因此，运行时间为$\\Theta (N)$。\n（个人认为这种方法不如数学方法直观。）\n方法2：通过数学方法找到界限 想象一下方框：\n基于简化的几何分析 因此，$C(N)$将为： $$ C(N)=1+2+4+\\dots+N= 2N-1 $$ 因此，运行时间为$\\Theta (N)$。\n示例3：树递归 1 2 3 4 5 public static int f3(int n) { if (n \u0026lt;= 1) return 1; return f3(n-1) + f3(n-1); } 方法1：直觉 每次将n增加1，工作量加倍\n\u0026hellip;这导致运行时间直观上为$2^N$。\n树递归 方法2：代数 $C(N)$的成本为： $$ C(N) = 1+2+4+\\dots+2^\\left(N-1\\right)=2^N-1 $$ 因此，运行时间为$\\Theta (2^N)$。\n方法3：递归关系（超出范围） 从以下开始： $$ C(N)=2C(N-1)+1 $$\n示例4：二分查找 二分查找 方法1：直觉 我们从N个选项开始，然后N/2，然后N/4 \u0026hellip; 直到只剩下1个。\n每次，我们将数组分成两半，因此最后我们必须执行总共$\\log_{2}(N)$次操作\u0026hellip;\n因此，总体运行时间为$\\Theta (\\log(N))$。\n方法2：精确计数 二分查找 因此，$C(N)=\\left\\lfloor \\log_{2}(N) \\right\\rfloor + 1$（根据观察）。\n运行时间为$\\Theta(\\log(N))$。\n示例5：归并排序 任意时间单位：相对的时间需求 例如，如果我们运行N=6的选择排序，运行时间的阶数为$N^2$，那么运行时间将为约36个AU。\n关于归并排序-一个简单的情况（将两个列表合并为一个） 归并排序 其运行时间为$\\Theta (N)$。\n归并排序-将归并排序应用于排序一个长列表 归并排序 关键思想是将原始数组分割成最小的片段，并应用归并排序（其运行时间为$\\Theta (N)$）。\n因此，归并排序的最坏情况运行时间为$\\Theta (N \\cdot \\log(N))$，其中\n最上层花费约N个AU。\n下一层花费约N/2 + N/2 = N个AU。\n再下一层：N/4 + N/4 + N/4 + N/4 = N个AU。\nSummary There is no magic. Just count. 一个比较规范的方法见disc07的andwelcome()： 【1】求Tree Height (number of layers)，如二叉树的话就是$logN$ 【2】求branching factor（分叉系数/ nodes per layer），如二叉树是$2^N$ 【3】求每个node的operations (work per node)，如二叉树是$N/2^i$ 最后乘起来：$\\sum_{i=0}^{logN}\\space·\\space2^i\\space·\\space(\\frac{N}{2^i}) = n\\log{N}$ ","permalink":"http://eimy.ink/zh/posts/2023/asymptotics2-notes/","summary":"copied from the textbook","title":"61B Notes - Asymptotics II"},{"content":"Asymptotics CS61b算法部分的第一个lecture（中英混记）。记录的是lec的主要脉络。\nGeneral Goal 这部分引出核心问题——“如何衡量算法效率”。\nEfficiency comes in two ways\n编程成本（programming cost）\u0026lt;\u0026ndash; 61b前半程的关注点 执行成本（execution cost）\u0026lt;\u0026ndash; 现在开始的关注点 time cost memory cost 引出问题：How to measure code efficiency？\n因此这一讲的目标是引入衡量算法效率的正式标准\nIntuitive Runtime Characterizations 这部分由浅入深展示了几个可以衡量程序效率的方法。\n比较执行时间 优点是直观，缺点是因为影响因素过多，不太可靠 计算所有运算步骤累计次数（用实数/抽象N表示） 优点是可以看出增长规模（how it scales），但是算起来麻烦 scrnshot Asymptotic Analysis 这部分首先介绍算法效率多大程度上受到增长规模（order of growth）的影响，然后引出能够简化渐进分析的方法。\nOrder of Growth的影响\n基本原则是，在分析效率时，只关注asymptotic behavior（即N趋向无穷大时的表现）\n基于这个原则，可以观察比较N无穷大时的函数形状\n暂时称这个函数形状为order of growth，比如它可以是line、cubic、quadratic etc.\n也就是说，我们可以通过Order of Growth来衡量算法效率\n但目前的分析增长规模的方式（symbolic count）不够简单，在数学上也不太严谨，所以需要将其简化：\n只看worst cast count 只选一个有代表性的操作来count 只看对order影响最大的一项，比如：n^3~~+n^2+1~~ 忽略系数 simplification/1 到这步为止，分析时需要1）计算一整个表格，2）挑出一个代表性count，3）简化。这种分析步骤还可以进一步简化：\n一种是直接看着代码，选择某个运算符进行计数 Approach1-based on exact count 更加简单的一种是几何上的分析（假设边是$N-1$，直接得出$N^2$） Approach2-simpler geometric argument Asymptotic Notation 最后介绍渐进分析的常用记号Big Theta（即Order of Growth）和Big O。\nBig theta 可以用Big Theta来描述某一程序运行时间的增长速率。\n记号 假设有一个runtime function $R(n)$，如果$R(n)$的order of growth（函数形状）是$f(N)$\n则记作： $$ R(n) \\in \\Theta (f(N)) $$\n定义 $$ R(n) \\in \\Theta (f(N)) $$\n的意思是存在正常数$k_1$, $k_2$，使得 $$ k_1 · f(n) \\leq R(N) \\leq k_2 · f(N) $$ 对$N\u0026gt;N_0$（i.e. very large N）的所有数均成立。\n举例 Big Theta demo Big O Big Theta更像是描述一种“等于”的关系（某一函数的增长速度等于xx），而Big O描述的是“小于等于”的关系。\n定义（*可以看出相比$\\Theta$是把下限去掉了） $$ R(n) \\in \\Theta (f(N)) $$\n的意思是存在正常数$k_2$，使得 $$ R(N) \\leq k_2 · f(N) $$ 对$N\u0026gt;N_0$（i.e. very large N）的所有数均成立。\n举例： $$ N^3+3N^4 \\in \\Theta(N^4) $$\n$$ N^3+3N^4 \\in O(N^6) $$\nBig O vs Big Theta Informal meaning Family Family Members Big Theta$$\\Theta(f(N))$$ Order of Growth is f(N) $\\Theta(f(N^2))$ $$N^2/2$$$$2N^2$$$$N^2+38N$$ Big O$$O(f(N))$$ Order of growth is less than or equal to f(N) $O(f(N^2))$ $$N^2/2$$$$2N^2$$$$lg(N)$$ ","permalink":"http://eimy.ink/zh/posts/2023/asymptotics-notes/","summary":"halfway through 61b!","title":"61B Notes - Asymptotics"},{"content":"因为是intel转m1，会涉及到一些软件的重装和重新配置，所以在这里备忘一下\n主要参考：https://sspai.com/post/64301\n设备情况 旧机：MBP 13\u0026rsquo; 2018 256+8 Intel i5，系统是Monterey 12.1\n新机：MBP 14\u0026rsquo; 2021 512+16 M1\n步骤 旧机准备 01 升级系统至最新版本\n实际因为不剩多少内存了，就没有升级\n备注：迁移后新机的系统版本是和旧机保持一致的！\n02 整理归档文件\u0026amp;应用\n具体完成了以下事项：\n【文件】系统性分类归档所有文件夹（以前分的太随意了） 【文件】删除“下载”和“桌面”上显然不需要的文件 【文件】删除/硬盘备份占用容量过大的文件 【文件】从用户文件夹中备份命令行工具配置文件（可选） 【应用】记录预备安装的软件（因为应用打算在新机上全部手动装） 【应用】删除基本不用的软件 顺便分享一下我目前的归档方案。\n桌面一般不放东西，下载一般乱放文件。除此以外，文稿分成以下几个文件夹：\n【ug-fdu】：UnderGrad，包含了每学年的文件夹、证书和资料以及社团和活动 【grad】gradschool 【life】：各种爱好 【work】：工作相关的 【selfedu】：自学内容+相应的作业和笔记 【misc-notes】：miscellaneous, 存放没有明确父项目的笔记或整理，未来可能会分成tech和non-tech两类 【misc-zatsu】：杂记。读笔、随笔什么的 【常用证书和照片】：时不时被要求上传的东西，比如护照、证件照、电子签名 说明：整体分为学业、生活、工作三块，因为想尽可能减少层级方便查找，所以“生活”中的笔记、自学、杂记、照片都被独立出来平行放置了。\n03 创建备份\n用的是west digital的硬盘和系统自带应用time machine\n04 退出iCloud\n退出iCloud且关闭查找我的mac 解除各种授权（可选，之后可以补救） 新机配置 01 迁移\n同一wifi连接状态下，两机打开迁移助手，选择需要迁移的文件即可。\n一些个人小故障：迁移完后旧机的触控板反应速度突然变得过于灵敏\u0026hellip;\n02 安装软件\n秉持实质极简主义，不想全部迁移以后再一个个卸载，于是新机上的所有应用软件都是一个个安装的。\n第一批安装的主要应用（用不到这些感觉浑身有bug在爬）：\nChrome Alfred 5 ClashX pro：用旧机下dmg然后drop过去 typora IINA 其他东西：\ngit：有新版本，但还是用的旧机迁移的\njdk\nPraat\nR+Rstudio\nvscode\nintellij idea\nAdobe photoshop（备忘）\nlogic\nfinal cut pro（备忘）\noffice全家桶\naldente（电池管理软件)\n03 其他设置\n桌面：系统偏好设置-桌面与屏幕保护程序 本地主机名：系统偏好设置-共享 这次给mac起了个独特又好记的名字——ipad-pro-max！ 04 软件使用测试\n测一下 git本地仓库使用 和旧机完全相同，不需要重新配置 检查各个应用的耗能 附录：遇到的问题 git和homebrew 问题描述：执行官网quickstart的命令，显示“///git: bad CPU type in executable\u0026quot;\n原因：迁移过来的旧机系统没装rosetta\n解决方案：装rosetta\n配置x86和arm的brew新名字时候出错 问题：\n1 2 › source ~/.zprofile The operation couldn’t be completed. Unable to locate a Java Runtime. 原因：看来是因为没装java\n解决：去oracle极速装了个jdk就好了。顺便这里最后没有把arm brew改成abrew，只把intel brew配置成了ibrew。\n不知道git是自带的还是迁移的版本 问题：如题\n解决：通过which git和git \u0026ndash;version确认版本和位置\n迁移旧brew软件包 解决：看这里\n","permalink":"http://eimy.ink/zh/posts/2023/mbp-setup/","summary":"再见了，所有的intel mbp(哦咩跌多パチパチ)","title":"Intel Mac迁移至M1 Mac记录"},{"content":"在整理文献时突然想看夜鹿live，于是整理了一篇攻略备用。不过有些细节是我自己查资料以后的理解，不一定准确，欢迎指正。\n01 买票 不幸的热知识 比较大的live都是抽选制，即先抽票，剩下的票才会开抢票。——欧皇才是婆罗门！ 位置都是随机的，但内场票一般都在前几轮中抽完。部分会分不同等级的指定席分价格卖。 抽票买票都需要日本手机号 基础知识 Fan Club（FC） 有些日本艺人会有自己的收费订阅制fanclub/会员俱乐部，会有特典内容、先行抽票等等福利。\n抽live票的各种途径里这应该是中奖率最高、位置最好的一种。\n「抽选者」与「同行者」问题 FC抽票时需要注意，如果抽一张票（即无同行者），那么这张票最终「使用者」需要和「抽选者」保持信息一致。说人话就是，谁抽的谁去。拿着别人名字的票有被查的风险。\n而如果是一个人用FC抽两张票，第二张票（也叫002）除非有特殊标注，一般不要求使用者身份。纸质票要求「同行者」和「抽选者」一起入场，电子票则可以直接app内转让。\n这个问题在代抽「改名字」、买二手票时都会遇到，务必弄清情况。\n开票轮次 日本live分批次开票，顺序一般为：（*有些会省略几轮）\n1）fanclub先行（会員先行），按阶级依次一轮二轮。以yrsk为例，购票人\u0026amp;同行者双会员第一批，其次是同行者非会员。\n2）艺人官网先行（オフィシャル先行）\n3）票务网站登陆者先行\n4）罗森/7-11/全家先行\n5）一般发售\n举两个例子：\n1）米津玄师2023 Tour 分为1次先行（需专辑）、2次先行（需专辑）、一般抽选\n抽过19年老米演唱会的一般抽选，没抽到。\n米津 2023 Tour 2）Yorushika 2023 「月と猫のダンス」分为会员先行1、会员先行2、官方先行\nYORUSHIKA 2023 实际操作（for大陆） 正规途径 如果有日本手机号 ==\u0026gt; 正常流程抽选 - 中选 - 支付 - 出票 etc\n没有 ==\u0026gt;正经人走什么正规途径（敲黑板）\n不太规范但更加方便的途径 一个是通过票通收二手票。票通是一个专注演出票交易的日本网站，我看下来这种方式的优点是流程正规有安全保障，价格相对透明，缺点是需要知道其中的术语潜规则，需要自己挑入手时机、自己跟卖家沟通，有时候还需要被卖家集中起来（？）一起入场，所以完全不懂日语会比较麻烦。\n票通 另一个是淘宝代抽票，比如可以搜索”pia抽票“。\n这里也分成两种，一种是商家直接帮你代抽，费用组成是商家抽票费用+（抽到了再付的）票费。这种优点是方便无脑，不过要弄清这个票是否要求「使用者身份与购票信息一致」，需要的话就意味着代抽时要提供自己的个人信息，这个就智者见智了。\n另一种是商家提供日本手机号，费用自己直接支付。这一种相当于是全程自己操作，没有任何信息泄露风险，不会有「使用者与抽选者信息不一致」的问题，但相应地会增加自己的操作成本。\n另外，推特等SNS平台也是一种渠道，这就和国内wb收票有点像，最大区别是「同行者身份」这个老问题。\n小结（TLDR） 选择你的回合——fan club抽选/一般抽选或贩卖/二手市场 选择你的英雄——各个买票渠道 不分先后 1）tb代抽（全包 ver.）\n2）tb代抽（手机号ver）\n3）通过票通/官方resale/其他二手市场收二手票\n4）用日本（朋友的）手机号正常买\n使用你的技能——在此基础上问清卖方以下问题 1）票是否要求「同行者」的身份？最最重要的问题\n2）怎么把票给我？\n3）我到现场怎么用？（需要人带or直接进）\n*如果有出票需求，还可以问二次转让的问题\n02 卖票/退票 考虑到跨国看live的时间轴长，不确定性更高，所以把卖票退票相关事宜一起整理出来。\n流程 官方原因停办：官方会退款\n个人原因去不了：\n1）提交官方转售 可搜索关键词 演唱会名字+チケットリセール or 演唱会名字+チケットトレード\n米津官方转售页 2）其他的二手市场如Mercari、雅虎拍卖、票通 或许对日语水平有一定要求\n3）tb代转卖（万能的、）\n费用及损失 官方交易 不管是退款还是官方转售，都是按照票面价给的。\n所以最终的Cost = 买入价格 - 票面价格\n二手市场 要看卖的时机和定价了，需要承担一定卖不出去的风险和与国际友人沟通造成的精神损失\ntb代卖 基本同上，还会附加tb转卖的手续费cost。\n随便举一个case 单位是rmb\n票本体：450\n收票手续： X（取决于几抽出货） * tb手续费50～70\n转卖额外：+ 手续费算100\n总共损失= 手续费100～200\n","permalink":"http://eimy.ink/zh/posts/2023/live-japan/","summary":"论文开题副产物","title":"日本Live购票攻略"},{"content":"在此记录一些突然想通的生活小寄巧或者对什么事情的碎片想法\n思考 功利视角下，学校的本质是资源平台而不是学习场所。学生身份会给人超出想象的权限，合理（或者不合常理）利用权限在时限内完成资源的累积或许是作为学生最重要的事。其中的学习资源是最直观但最不值得一提的。对于一些人来说这是自然行动的一部分，但是这种事情对像我一样的人其实需要先验地提醒。 如果在同一个位置发现很多棘手问题，它们可能是一个系统性问题造成的。系统性问题无法解决，只能选一个舒服的姿势顺应或者换一个系统。 观察和经验告诉我人的心智和能力不一定和“资历”/地位正相关，所以不应该用社会属性建构人。 拖延圣经：现在不想做的事情，明天这时候真的也不会想做；计划可以落在未来但是期待不能。 我认同对大学设立目的的一切理想化描写，但是反对一些「强迫人将此视为上大学的目的」的精英主义观点。首先，大学的目的和人对它的实际接受是两件事，就像猪生命的原本目的不是给人类吃（提醒：觉得为什么不是的人是犯原罪咯），所以大学应当怎样不能在逻辑上推出人应该对大学怎样。其次，从现实角度上看也不成立。有些人还是没有跨出过精英圈层，整天说些何不食肉糜的鬼话。不是每个人的起跑线都在马斯洛顶层。不用迫于现实的、物质的原因把大学看作工具，本来就是一种特权。 人是在寻找最优解，机器也是在寻找最优解，所以人有时候可以参考机器学习方法精妙地抽象出的策略。这大概就是为啥偶尔看到有人说人生是强化学习或者梯度下降etc。-追记：跟几个朋友聊过以后发现不是所有人都这个思路，我格局小了 观身边一些人去心理咨询的经历分享有感：我非常抗拒无条件的支持，觉得这是不负责的表现，是非常浅薄的关心。考虑到“移情”关系的存在，心理咨询在我这里基本等同于花钱买工业糖精。 健康第一。 有时候会觉得所有事物的底层是一套共通的抽象原则，这些原则通过不同方式具象表达出来（自然现象、定理算法、个体发展）。有点像“理念”的本体论，但是不一样的是比起独立的一个个概念，我想象中的本体更像是一系列规则/逻辑/模型。-追记：有点像斯宾诺莎的平行论。 时间有限。好像大家都知道人生有大限，一件事有期限，但是很多人（包括我自己）在拼命生活的过程中都会忘记一天（时间标尺的中间）的时间也本应是有限的。具体体现为反正晚上可以熬夜透支时间，白天就摸摸鱼这样的做法。我在想，重新给自己的一天也设限能不能让我更珍惜时间。 这代人又会是一代GenX吧 -追记：不许装 时间果然是终极计量单位，发现大部分能力差异都可以换算成时间。 随笔 2023/04 关于Yorushika的“变化” 看到b上对yorushika风格变化的乐评，有一些共鸣。我觉得这不是单方面的渐行渐远（“君がまた遠くを行くんだ”），不是湖上行舟望远山走近又淡出的感觉。n-buna只是“先に大人になった”。总有一天大家都会走到那里，所以失去摇滚的伤感是暂时的，只存在于他和我（们）的时间差中。（过了几个月的补充：现在我确实能接受并且还挺喜欢新的减法风格，可能是不再那么愤世嫉俗了）\n2023/07 关于读书的意义 以前会纠结为什么读了很多书但什么都想不起来。不光是内容和金句，有时书名作者都会忘，一般只能记个大概的阅读感受。比如我特别喜欢密尔的《论自由》，但如果问我它的主要思想，我只能七七八八说点no harm principle、individualism。即使中文英文都读了几遍，即使是和21/22年某时期十分相衬的应景读物，还是只保留了一部分印象。于是长久以来，我一直以为读闲书对我个人而言影响不大。\n但是最近偶尔反思自己的想法时，觉得这种影响比我想象地更潜移默化。经济学的理论书我在课上只看过一本，但不妨碍我不自觉代入它的视角去入世地考虑边际效益、相对优势、还有今天蔬菜的价格为什么又涨了；我可能记不清精神分析书里说的方法论，但每次做梦、发现口误笔误，我都会去随意分析梦里的隐喻、每个外显的失误中无意识，这样也总能有些有趣发现；我不可能记清每个哲学家的思想体系，我观察世界和行人的视角也更偏向胡乱缝合，但这些已经足够帮我完善关乎个人的定义，比如目的(end)、意义、自由、主体的坐标系、整点薯条；不需要重大新闻提醒，我几乎每天都会想到死亡，只因为有一本随笔集里谈到生活态度，说值得的人生的标准是「即使下一秒突然死了也不会有任何遗憾」（大意）（，说到这个，哪天要是重大新闻降临在自己身上，我也不会感到惋惜，因为我确实践行着这个原则）。\n这些例子写出来会显得非常刻意，但实际的体验更接近：发现某些突然浮现的想法来自过去不经意看到的一段话、读过的名字都忘了的一本书。或许它就和吃饭一样，吃和完全不吃之间会有质的差异，一定范围内的吃多少、吃什么，却很难和生命或是生活找到显性的相关，但非显性不等于不存在。有句话叫「I am what I eat」，其实相似地，也可以认为「I am what I read」。\n2023/09 生活近况汇报 今天是难得在睡前两小时就完成了所有todo的一天，终于可以简单整理下最近的情况。\n在这之前，先说说对这篇随想杂谈做出的结构改动——分出了思考和随笔两个板块。原本是打算像帕斯卡一样，真正按照想到的顺序记录思想结晶的。但是持续了一段时间以后，发现了一个问题：思想结晶频率太低，或者说大部分想法其实到不了值得作为规律准则记录下来的门槛，这就导致它阻塞了很多日常有趣但不深邃的想法的诞生（比起结晶，功能上听着更像结石呢），让我遗失了很多在散步洗澡或者写作业摸鱼时的顿悟。\n关于两者的功能，「思考」部分普遍长度比较短，理想中它应该有本体论的性质，会收集一些宏观抽象的总结，或者关于自己内核的思考。「随笔」部分比较随意，长则小作文，短则一句话。它应该会收集所有值得记录，但是达不到「思考」深度的想法或者关于我个人的分享，也就是类似L2 cache的东西。虽然我估计，以后肯定是99%都属于后者。另外还有另一个本地private文件，里面记录了长期的规划和短期方向性的确认。这些组成了脑子的全部业余产出。\n接着就是近期重要事件汇报。\n九月初乘飞机开启了美国留学的新生活。虽然说是新生活，身心上我其实并没有感到有巨大的变化。比如生活习惯上，在中国时我每天七八成时间在电脑前做事，在这里也是；在饮食上，说来奇异，我好像特别适应美国的饮食，可能是因为在国内时我就偏好吃面包奶酪水果鸡蛋咖啡等经典白人饭（一天这样吃三顿的那种），也可能是待得还不够久，还可能是确实没什么时间做正经饭；娱乐上，我喜欢把所有大脑空闲时间灌满Jpop和新番，这点也没理由因为换了个地方生活就改变。\n留学生活的另一面即是找实习，甚至有可能这才是主业，因为很难有人能一辈子只上学。虽然早就听说北美实习难找，但来了以后发现实际只有更加残酷。几个月前我给自己定的目标是一年收集100封拒信，但或许我还是高看自己（i.e. 一个没有身份的f1陆本文科背景的转专业学生）了。乐观点说，在国内找实习时，带着大家喜欢的“Top4本科”、”岗位对口大厂实习“的buff，也被拒到怀疑人生，目前debuff都叠这么高了，情况还是在预期之内的。啊，好像也不是特别乐观，不过算了。\n对了，不适应的地方还是有一点的，就是networking的文化。我理解它的意义和重要性，但是很难践行它。尤其是单独面对和我从相同环境走出来的人的时候，我很难找到合适的表述，把我自己代入或是邀请对方进入一个对我们来说都是异己的语境里，哪怕我自己已经不在乎了，在对话说我还是能明显感知到a potential sense of peaceful rejection。但同样乐观点说，这方面我的心态向来是，任何软硬技能都是能学习的，即便我生来不会，也可以通过学习和练习掌握。大部分只是训练时间的问题。\n某些亲戚总唱衰我的选择，说我一定会后悔这个错误的决定。但事实上我不会后悔任何一个真正意义上是自己做出的选择。这是真心话，不是那种英雄主义的影视剧主角临死逞强式的自我感动发言。一方面因为我发现选择的正确性是一个伪命题，真正的命题叫做预期管理，可以边走边学；另一方面也因为，我对公式型的人生规划祛魅了，走hua边的人生更有可能带来我想看到的惊喜（或者惊吓）。\n最后是我挺长一段时间以来的心态。极度悲观且现实地看待客体的同时，主体永远坚持growth mindset和长期主义。\n2023/09 notitle 最近几个反复浮现的想法：\n1\n观察到非常优秀的人里大致存在两类（我也不喜欢二分法，请姑且认为这是一个spectrum，而我讨论的只是两端吧），一类人思而后行，另一类行而后思。同样给定一个目标，前者的行为模式经常是大比重的路径规划+稳定可预测的行动实现，就像解一道多变量的方程；后者则敢于进行反教科书的大胆尝试，依赖于风险和机会。有趣的是在我近些年身边的和听说的案例里，这两者的至少在中位水平附近是没有优劣之分的，不论采取哪一种手段都能达到很高的目标完成度。\n我是病情严重的思而后行爱好者。其实之前反思到这种差异以后，我和几个有过人之处、但和我恰好行为模式相反的朋友也聊了下底层到底是怎么想的，思维上学到了很多，但觉得实践上很难转换过去（可能也是路径依赖问题）\u0026hellip;“别想太多“实在不容易。\n最近因为各种原因又把它提上了日程，用暴露疗法治治应该就习惯了。\n2\n效率最大化的方法是：do what matters most every morning。人应该是有那种捡简单事情做的惰性的，但简单的事大多不是“主线”，日积月累把大量注意力和时间给最不重要的支线只是在自我感动。\n比较典型的反面案例是每天早上拖延高脑力消耗的todo，虽然日间完成了一堆琐碎小事，最后到了晚上却没有时间也没有力气再做重要的事，然后开始明日复明日的循环。\n应该从最重要的事开始做（复读）。\n2023/10 最近想到的几个点：\n回想了一下所有在某一方面有所成就的人，好像都是把对自己的人生很重要的一部分东西倾注到一个事业里的（其实有点赌的意思，极致的Fi，把一件事做到100而不是每件事80）。虽然可能大部分人对名垂青史这件事毫无兴趣，但这点对于喜欢询问意义的人来说应该能带来启发。 速写时突然悟了，绘画其实是一种语言，每个体块、每种褶皱、头发片、五官就像是词汇。和学习语言一样，打基础时该做的不是不断仿写别人的句子，而是背单词、看语法（单词的组合）。应该做atomic practice而不是整体的练习，之前怎么就没有想通呢。 Update Log 2023-02-08: 开始记录\n2023-09-16: 分出了「思考」和「随笔」两块，理由见上。\n","permalink":"http://eimy.ink/zh/posts/2023/thoughts/","summary":"长期更新中","title":"【置顶】随想录"},{"content":" 追记：我故意保留了一部分抽风文学，这样大家才知道我是抽象人（九转博客）\n自我介绍是为了让别人了解一个人。对于我这种习惯在大脑本地单机的人来说，可能直接展现我平常在想什么事情、打算去哪里整薯条，更能让隔着3-2-3次元壁的人快速明白我是怎样的人。\n正好也快年终了，就当是一年内思想历程的总结吧！\ntldr：是一直抽风偶尔抽象的人\n2021～2022的备忘录选 - 2021.11.15 1 权力理论与全球化语境的联系？在全球化语境里，我们怎么理解生命政治学？rf知乎\n2 如何从当代视觉文化的角度理解福柯哲学？\n（rd：居伊德波《景观社会》鲍德里亚《生产之境》布尔迪厄《实践理性》）\n个人对这个还挺感兴趣 正好景观社会也在list里\n3 权力理论与性别批评结合？\n（《性别麻烦：女性主义与身份的颠覆》《陌生的自我》）\n感觉可以和亚文化圈的问题结合起来谈\n- 2021.11.18 生理疼痛也许是防止自我客体化的最好途径（之一）精神疼痛或许也是\u0026hellip;\n膝盖的伤让我这几天深切体会到主体性，世界怎么样完全取决于我怎么样\u0026hellip;\n- 2021.11.20 把所谓的虚无主义（或类似的表述）当成自己人生信条的人，他们的生活行为大多与这一信条相矛盾。他们仍然在所谓的无价值、无意义的世界中界定价值寻求意义——他们说有些事物是好的而另一些是坏的，他们说这是正确的那是错误的，他们认为一部分是有价值的而另一部分是无意义的。从这种意义上来说，虚无主义只是他们将物质安乐与精神空虚合理化的工具，是为不经审视的权力话语准备的免责声明（甚至，掩盖自己人生的虚无的遮羞布，什么的）。\n- 2021.12.07 《胰岛素-肝锅力自律法》 又名《自律的胰岛素有多可怕》\n最近在研究一些营养学知识aka每天一则伪科学冷知识，发现竟然可以应用在日常提高效率上：\n比如盛传的间歇性断食，据说可以通过减少摄入食物的时间来增强胰岛素的敏感性，由此可以及时控制血糖，一定程度上降低患糖尿病的风险。说得通俗点就是让#您的降血糖小助手#随时待命，更加机动灵活些，防止人浸死在糖水里。\n于是我就想到自己日常的做事状态——如果把血糖类比「生活压力（学业+各种）」，胰岛素的作用对应「肝作业/完成任务以减轻压力的行为」，胰岛素处理血糖的效率（即敏感性）对应「处理压力的效率」，那么间歇性断食就可视作「在压缩过的短期内完成压力的处理，在其他时段内保持低或无压力状态，由此提升短期内压力处理效率即做事效率，防止人无时无刻泡在低效率的生活重压中」。\n（*虽然比较致命的是，血糖升高的前置行为一般给人带来快乐，而压力水平升高就\u0026hellip;当然我们不排除有人喜欢这种）\n在实际执行中，根据性格、生活方式和健康状况的不同可以有两种方法。第一是可以被拍成自律视频上传某站的提前规划按时完成剩下时间放飞自我，或者干别的。这种显然适合高Te人，但建议配合N系技能食用（ni是很好的），否则会变成沉迷执行计划，但问前程一问三不知的状态。还有一种是，ddsk的死线前夜精神小伙久坐不起原地瘫痪法，也就是把事情拖到真的来不及，被迫在短期内完成。听起来很容易，但是只有心态良好的朋友才适合。Te+Si强行整这种，估计会被致郁。\n- 2022.01.20 关于“mbti会不会变” 简单的y/n答案：会\n简单问题复杂化的解释：\n众所周知x，你测出来的mbti 和 你感知的自己的mbti 和 客观上你的人格（假设存在这种人格本体论的话）是三件事情。\n1 关于测出来的mbti会不会变\n这个问题可以类比成在问“一个人做的混合蔬果汁的风味会不会变”一样，答案是废话当然可能变，不过具体还是看人。从底层原理来说，mbti是定性或定量考察一个人八种认知思维功能以后综合得出的人格倾向，就像一杯混合蔬菜汁的综合味道由放进去的蔬菜种类比重决定一样（）继续类比，蔬菜汁的味道会随一个人【不同情况下】放的蔬菜种类和比例不同而改变，测试结果也会受各种要素影响（包括但不限于个体在测试时期主要使用的八维功能eg“我今天emo了”、测试者自己对mbti某人格的偏好eg典中典之“我一定要测成人上人intj”等等），所以mbti测出来不一样是很正常的。\n至于为什么说“具体看人”，，因为总有人持之以恒地喝400ml菠菜羽衣甘蓝汁八种功能极性强（or mbti自我感知十分坚定等等），在各种情况下测出来都差不多。\n2 关于自我感知的mbti会不会变\n答案也是有可能，但或许只是巴纳姆效应etc啥的间接结果呢？撇除被测试结果误导的情况，导致自我感知变化的可能有长期短期的【个人】因素。举几个例子。短期影响导致结果不一的例子：我原本是xntj但是我今天emo了=我陷入了Fi-Ni loop=\u0026gt;我感觉我变成了知名emo人xnfp（是用成见在举例没有冒犯的意思）。长期一点的架空例子：我本是xsfp带艺术家但自从上了高中压力贼大，每天化身学习自律人见证凌晨四点的上海，这段经历过于刻骨铭心导致自此以后我一直觉得自己是xstj。归根结底这就是看一个人对自己主要使用的功能的印象有没有变。\n3 关于客观人格类型（if any）会不会变**\n斯密马塞，纯纯知识盲区。本来我就有点被（似乎是荣格学派的）人格面具理论带跑，觉得这玩意儿老是在变，然后之前上课走马观花地听了一些social identity theory（还有social role/reresentation）以后我就更加觉得不存在一以贯之的本体人格了\nps 我过于文盲以至于都不知道把这个问题界定在社会学还是心理学还是哪里的范畴来讨论（不过似乎人格心理学是社会心理学的分支）orz只是在瞎搞一些乱七八糟的namedropping，给看到且有兴趣的赛博有缘人一些研究线索[rose emoji]\nbtw我是真的看不惯用mbti反过来去解释行为 怎么能对如此复杂的问题采取这种reductionist的方法捏..\n- 2022.03.10 考试因为疫情取消 疫情天天开盲盒封校 我算是要溺死在焦虑里了\n刚刚看完《花束般》 一些无端联想的感悟：\n保护一个爱好的最好方式或许是让它成为孤岛。最近发现任何本质是非物质的东西一旦沾染上社会性就会变质（那种艺术追求会被磨损）：我曾经很喜欢画画，但自从接过一次稿后就再也没有画过一张，甚至都不再愿意构思；我曾经很喜欢pjsk，但自从去这个游戏的组里实习过后一次游戏也没有打开过。说起来不只是我，在游戏行业失去梦想的人不计其数（所谓第九艺术也只是对于韭菜们，对商业化产品的制作者来说这大约不会是这么pure的东西，除非有一个组、一个公司的人愿意陪你一天吃三顿梦想）。这个，虽说有可能这只是correlation而不是causation，有可能只是我自己在通过丢弃沾染上mishap的事物来逃避需要长大的现实，但用来说明理想的磨损大概是够了。虽然我听到过别人说工作和爱好从来不是对立的，但是我会怀疑是否有“很多人”愿意在九十点到家后“略感疲惫”地坚持一些纯碎的事业。就我自己，甚至连回到提瓦特还是海拉鲁的力气都没有。我不觉得这是可以长存于“普通人”身上的理想主义。为什么？详情可扫描二维码添加小助手领取以下书籍《在社会里寻求梦想是否搞错了什么》《当我画画、看书、打游戏的时候，我到底在想什么？》《如果这样说的话还不清楚怎么想都是你们的问题。》你看，你无法成为“an island”，你必须先一步“大人になる”，但你也不愿意失去“无用的灵魂”，那么真相又只有一个了。\n不过话说回来，三四个月没怎么看书，文字也变得无趣，逻辑也变得无序起来，好像只是一些意识流抱怨的堆砌 斯米马赛\n- 2022.04.05 是这样的 定期输入好的作品很像是在积攒势能（实质可能是「下次一定」式创作欲）是在拯救一些生活动能耗尽失去灵魂的咸鱼 绝对不是在找借口摸鱼\n不然谁会去管什么八月翘打工月光下骑车逃跑、放学不回家在教室玩推理游戏、去斯德哥尔摩对着照片圣地巡礼、开着萝卜跟哥哥塔塔开说什么“我要亲手了结你”的怪话 这种和自己八杆子打不着的桥段！seyana\n- 2022.05.14 用别人的意见（节奏）作为价值判断的依据的等同于放弃思考。我坚决抵制“因为大家都在骂，所以它是坏的”这种思维模式。\n- 2022.08.14 最近读一些精分流派的书，最大的感受是人的精神倾向、人格风格这类性质早在幼年期就已经被决定了（不管是受到那几个时期的客体影响，还是继承自集体无意识什么的）人终其一生其实都不能也不应该压抑、改变、泯灭这些预先决定的属性，仅能学习如何控制脾性，接纳种种衍生的悲喜剧。从这个角度来看，相信存在先于本质不如相信预定论，这样还不至于活到半路突然幻灭。\n- 2022.09.12 之前想到se-te轴，总觉得是需要美食、运动这样se的象征来激发te功能，比如品尝到美食后的间歇性振作。今天突然领悟，反完美主义的「立刻行动」，或许才是se字面的、原本的涵义。\n- 2022.09.20 我会选择牺牲一部分当下的生活而活在未来。我看过去总是不那么美好的，因为它们是被牺牲的每一个当下的瞬间的集合。\n- 2022.11.13 近期发现：从认识的很多家庭案例里观察到 孩子的人格形成 和 家人的人格以及家里的权力关系相关性非常显著。粗略分似乎有积极型和消极型发展两种模式 后者是B功能的使用被压抑导致被迫向功能的另一端A发展 比如Fi被威权型家长压抑就变成Fe（倒也不一定是ti啦 前者是A功能使用时不断收到正反馈从而自然发展 我的观察是一般积极型的孩子会健全一些 消极型的扭曲程度就取决于具体是哪种人格了\u0026hellip;\n- 2022.11.15 “象征界的法则决定了我的身份，也就是说，无论我认为自己是谁，除非在象征界的机制内获得自己和他人的认可，否则这种身份认同就是不真实的。\n- 2022.11.26 发现对于「某个群体将受到一定程度的剥削」这件事 有些人在意群体的范围 有些人在意剥削程度 嗯\u0026hellip;倾向于觉得后者可能是fe高（自动代入）或者fi高（个人喜好） 前者大概是te（实践影响）和ti（合理程度）高一点\n人与人之间思维差异还是很有趣的 \u0026ndash;观察sns有感\n- 2022.12.20 アコギ和エレキ虽然都是吉他 但作为乐器好像对我来说有很不一样的性质 就像用来日常写字的钢笔和用来写硬笔书法的钢笔 应该是as means和as end的比例不一样\n- 2022.12.22 事物往往以综合的形式展现在人眼前\n但人在特定阶段的核心诉求一般都是单一而隐蔽的\n所以经常会出现这样的悲剧：一个人在零星的黑盒式案例中推定因果论 奋力追求那个选定的某个综合的“因” 但回头发现真正想要的只是其中的某个性质或部分 其余的努力被浪费在既要又要的贪婪和建巴别塔的傲慢上\n其实也不是悲剧 就是在共时的视角下没法回避的常态（意思是历时就可以解决了）\n\u0026hellip;\n","permalink":"http://eimy.ink/zh/posts/first-post/","summary":"一篇为了填充个人主页临时拼凑的自我介绍","title":"First Post"},{"content":"\u003c!DOCTYPE html\u003e ","permalink":"http://eimy.ink/zh/posts/gallery/","summary":"my gallery","title":"Gallery"},{"content":" 假定点进这里的人想知道些别的\n关于本站 个人博客，缘起于有朋友说我很神秘.jpg\n性质更接近学习笔记和生活存档，不打算写成纯技术博客。\n关于我（in life） 经历 本科Linguistics@FDU =\u0026gt; 研究生CS@NEU\n说来话长，总之现在学得很开心。\n面包体 intj 5w6 虽然当面问的话我一般说IMSB\n语言 汉语 \u0026gt; 英语 \u0026gt; 日语（N1） \u0026gt; 法语（幼儿园）\n常听的乐队 Official髭男dism｜Yorushika 自其出道单推六年 其他 人格心理学爱好者，热衷分析荣格八维 木吉他三品战士，还有一把观赏用电吉他 谁没有过ギターヒーロー梦 业余画过插画接过稿，会一点pcr/sai2/ps等软件的安装与卸载 平涂和伪厚涂 三分钟热度Vocaloid调教师，V4时代入坑\u0026amp;发布过几首翻调 非常享受广义上的学习，努力成为life-long learner 希望有一天心态变得能去码头整薯条 最后更新：2023-12\n","permalink":"http://eimy.ink/zh/about/","summary":"about","title":"关于"}]