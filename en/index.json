[{"content":"Lab 11 networking 实验记录 lab link: https://pdos.csail.mit.edu/6.828/2020/labs/net.html\n11.1 E100 1 要求 补全网卡驱动里的e1000_transmit()和e1000_recv()函数，使之能够接受发送数据packets。\n这个task的自由度不高，细节主要跟着prompts和hints就可以实现。需要了解大致步骤\u0026amp;原理可以参考manual里的ch3。\n2 实现 实现e1000_transmit() 首先获取当前的ring index以及对应的desc：\n1 2 3 4 5 6 7 8 9 10 11 12 13 int e1000_transmit(struct mbuf *m) { // // Your code here. uint32 end; struct tx_desc *desc; acquire(\u0026amp;e1000_lock); end = regs[E1000_TDT]; // cur desc id desc = \u0026amp;tx_ring[end]; // index into ring to get cur desc // ... } 然后检查desc overflow。如果desc上设置好了E1000_TXD_STAT_DD，说明上一轮已经完成，可以释放buf里上一轮的内存。\n1 2 3 4 5 6 7 8 9 10 // check overflow if (!desc-\u0026gt;status \u0026amp; E1000_TXD_STAT_DD) { release(\u0026amp;e1000_lock); return -1; } // use mbuffree() to free the last mbuf if (tx_mbufs[end]) { mbuffree(tx_mbufs[end]); } 最后更新当前desc中的信息，更新ring index\n1 2 3 4 5 6 7 8 9 10 desc-\u0026gt;addr = (uint64) m-\u0026gt;head; tx_mbufs[end] = m; desc-\u0026gt;length = m-\u0026gt;len; desc-\u0026gt;cmd = E1000_TXD_CMD_EOP | E1000_TXD_CMD_RS; // update the ring position regs[E1000_TDT] = (end + 1) % TX_RING_SIZE; release(\u0026amp;e1000_lock); return 0; 实现e1000_recv() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 static void e1000_recv(void) { // ask the E1000 for the ring index int end = (regs[E1000_RDT] + 1) % RX_RING_SIZE; // get the next waiting received packet struct rx_desc *desc = \u0026amp;rx_ring[end]; // check if a new packet is available while ((desc-\u0026gt;status \u0026amp; E1000_RXD_STAT_DD)) { if(desc-\u0026gt;length \u0026gt; MBUF_SIZE) { panic(\u0026#34;e1000_resv\u0026#34;); } // update the length reported in the descriptor rx_mbufs[end]-\u0026gt;len = desc-\u0026gt;length; // deliver the mbuf to the network stack net_rx(rx_mbufs[end]); // allocate a new mbuf replace the one given to net_rx() rx_mbufs[end] = mbufalloc(0); if (!rx_mbufs[end]) { panic(\u0026#34;e1000_resv\u0026#34;); } // update descriptor and status desc-\u0026gt;addr = (uint64) rx_mbufs[end]-\u0026gt;head; desc-\u0026gt;status = 0; end = (end + 1) % RX_RING_SIZE; // mod if exceeding ring size desc = \u0026amp;rx_ring[end]; } regs[E1000_RDT] = (end - 1) % RX_RING_SIZE; // // Check for packets that have arrived from the e1000 // Create and deliver an mbuf for each packet (using net_rx()). // } Grade ","permalink":"http://eimy.ink/en/posts/2023/xv6/lab-net/","summary":"MIT 6.S081 Lab 11 Networking","title":"xv6: Lab 11 networking Notes"},{"content":"Lab 9 file system 实验记录 lab link: https://pdos.csail.mit.edu/6.828/2020/labs/fs.html\n9.1 Large files 1 要求 要求修改file system的block结构，使其支持doubly-indirect block，同时block上限从当前的$268 = 256 + 12$升高到 $65803 = 256*256 + 256 + 11$ 个blocks。\n主要修改的函数是bmap(), itrunc()\n2 实现 修改fs.h中定义的参数 1 2 3 4 5 // fs.h #define NDIRECT 11 // 原12 现在把其中一个block作为doubly #define NINDIRECT (BSIZE / sizeof(uint)) #define NDOUBLE (NINDIRECT * NINDIRECT) // 定义doubly的容量 #define MAXFILE (NDIRECT + NINDIRECT + NDOUBLE) // 相应增加 相应修改inode和dinode的addrs数组大小 1 2 3 4 5 6 7 8 9 10 11 12 // fs.h struct dinode { // ... uint addrs[NDIRECT+2]; // 一共有11 + 1 + 1个block }; // file.h struct inode { // ... uint addrs[NDIRECT+2]; // 11 + 1 + 1 }; 修改bmap函数 doubly indirect block相当于一个block指向了一个size=256的块，而每一块又指向一个size=256的block，所以最后一共增加了256*256 可用blocks。\n只要在原有代码基础上增加分配中间层block内存的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 // fs.c 附部分解释comment static uint bmap(struct inode *ip, uint bn) { uint addr, *a, *a1; struct buf *bp; if(bn \u0026lt; NDIRECT){ if((addr = ip-\u0026gt;addrs[bn]) == 0) ip-\u0026gt;addrs[bn] = addr = balloc(ip-\u0026gt;dev); return addr; } bn -= NDIRECT; // if (bn \u0026gt;= 250) printf(\u0026#34;bn: %d\\n\u0026#34;, bn); // 至此 bn=blocknumber=singly block中的计数 [0, 255] if(bn \u0026lt; NINDIRECT){ // Load indirect block, allocating if necessary. // 给singly indirect block分配内存 if((addr = ip-\u0026gt;addrs[NDIRECT]) == 0) ip-\u0026gt;addrs[NDIRECT] = addr = balloc(ip-\u0026gt;dev); bp = bread(ip-\u0026gt;dev, addr); a = (uint*)bp-\u0026gt;data; if((addr = a[bn]) == 0){ a[bn] = addr = balloc(ip-\u0026gt;dev); log_write(bp); } brelse(bp); return addr; } // ++++++++++++++++++++++++以下新增++++++++++++++++++++ bn -= NINDIRECT; // 至此 bn = doubly block中的计数 [0,65535] if(bn \u0026lt; NDOUBLE){ // n1 = bn / NINDIRECT 中间层的block number/索引号 // n2 = bn % NINDIRECT 实际的（最后一层）的block number // Load 1st layer of doubly indirect block, allocating if necessary. if((addr = ip-\u0026gt;addrs[NDIRECT + 1]) == 0) ip-\u0026gt;addrs[NDIRECT + 1] = addr = balloc(ip-\u0026gt;dev); // Load 2nd layer of doubly indirect block. allocate if necessary bp = bread(ip-\u0026gt;dev, addr); a = (uint*)bp-\u0026gt;data; if((addr = a[bn / NINDIRECT]) == 0){ a[bn / NINDIRECT] = addr = balloc(ip-\u0026gt;dev); log_write(bp); } brelse(bp); // use block bp = bread(ip-\u0026gt;dev, addr); a1 = (uint*)bp-\u0026gt;data; if((addr = a1[bn % NINDIRECT]) == 0){ a1[bn % NINDIRECT] = addr = balloc(ip-\u0026gt;dev); log_write(bp); } brelse(bp); return addr; } panic(\u0026#34;bmap: out of range\u0026#34;); } 相应地修改itrunc函数 用来释放内存 遍历中间层，释放其中每个block对应的第三层的内存blocks（增加一个嵌套循环），具体见下。\n这里需要注意的是，因为要分别release不同层的buffer lock，所以各层不能像之前一样共用locked buffer pointer变量名（bp）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 void itrunc(struct inode *ip) { int i, j, k; struct buf *bp, *bp2; uint *a, *a1; for(i = 0; i \u0026lt; NDIRECT; i++){ if(ip-\u0026gt;addrs[i]){ bfree(ip-\u0026gt;dev, ip-\u0026gt;addrs[i]); ip-\u0026gt;addrs[i] = 0; } } if(ip-\u0026gt;addrs[NDIRECT]){ // the bp of 256 blocks bp = bread(ip-\u0026gt;dev, ip-\u0026gt;addrs[NDIRECT]); // blocks addr arr a = (uint*)bp-\u0026gt;data; // free every block in a for(j = 0; j \u0026lt; NINDIRECT; j++){ if(a[j]) bfree(ip-\u0026gt;dev, a[j]); } brelse(bp); bfree(ip-\u0026gt;dev, ip-\u0026gt;addrs[NDIRECT]); ip-\u0026gt;addrs[NDIRECT] = 0; } // ++++++++++++++++++++++++以下新增++++++++++++++++++++ if(ip-\u0026gt;addrs[NDIRECT + 1]){ // the bp of 256 blocks bp = bread(ip-\u0026gt;dev, ip-\u0026gt;addrs[NDIRECT + 1]); // 1st addr arr a = (uint*)bp-\u0026gt;data; // rls every blocks in every arr in a for(j = 0; j \u0026lt; NINDIRECT; j++){ if(a[j]) { // 注意 bp2必须和bp区分开 否则会造成提前释放lock的问题 bp2 = bread(ip-\u0026gt;dev, a[j]); a1 = (uint*)bp2-\u0026gt;data; for (k = 0; k \u0026lt; NINDIRECT; k++){ if (a1[k]) bfree(ip-\u0026gt;dev, a1[k]); } brelse(bp2); bfree(ip-\u0026gt;dev, a[j]); a[j] = 0; } } brelse(bp); bfree(ip-\u0026gt;dev, ip-\u0026gt;addrs[NDIRECT + 1]); ip-\u0026gt;addrs[NDIRECT + 1] = 0; } ip-\u0026gt;size = 0; iupdate(ip); } 9.2 Symbolic links 1 要求 实现symlink(char *target, char *path) system call\nYou will implement the symlink(char *target, char *path) system call, which creates a new symbolic link at path that refers to file named by target. For further information, see the man page symlink. To test, add symlinktest to the Makefile and run it. Your solution is complete when the tests produce the following output (including usertests succeeding).\n2 实现 设置syscall num、声明syscall函数等 按照hints里一个个来，涉及到文件：user/usys.pl, user/user.h, kernel/syscall.h, kernel/syscall.c, 以及在kernel/sysfile.c里声明这个syscall函数（暂时为空）。\nkernel/stat.h 中增加T_SYMLINK，作为一个新的inode type\nkernel/fcntl.h中增加一个O_NOFOLLOW flag，和其他区分开，用来作为后续判断是否追踪symlink path的flag\n实现symlink()\n每个步骤都在注释里说明了，可以参考sys_link的实现。主要涉及到：1）创建一个特殊类型的inode（type=sym），它的路径和传入的path（下面命名为source以防搞混）相同；2）然后在inode里存放target path。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // sysfile.c uint64 sys_symlink(void) { // symlink(\u0026#34;/testsymlink/b\u0026#34;, \u0026#34;/testsymlink/a\u0026#34;); // arg0 target pathname // arg1 path pathname char source[MAXPATH], target[MAXPATH]; struct inode *sip; int len; // load args if((len = argstr(0, target, MAXPATH)) \u0026lt; 0 || argstr(1, source, MAXPATH) \u0026lt; 0) return -1; begin_op(); // create a symnode to store target sip = create(source, T_SYMLINK, 0, 0); if(sip == 0){ end_op(); return -1; } // ilock(sip); deadlock create里已经lock了 // write the target path to symnode if (writei(sip, 0, (uint64)target, 0, len) != len) { iunlockput(sip); end_op(); return -1; } iunlockput(sip); end_op(); return 0; } 修改sys_open()。 需要实现：如果当前path指向一个symlink inode，根据O_NOFOLLOW决定是否要跟踪symlink中的target path。\n如果跟踪，用link depth进行环检测+及时终止跟踪；\n如果不跟踪，直接读取该symnode（即不用额外操作）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // sysfile.c // 主要步骤见comment 具体略 struct inode* getirec(struct inode *ip) { uint inums[10]; // prompt建议设置最大深度为10 超过10默认err int i, j; char target[MAXPATH]; for(i = 0; i \u0026lt; 10; i++) { inums[i] = ip-\u0026gt;inum; // read the target path from symlink file // 用readi 略 // get the inode of target path if((ip = namei(target)) == 0) { return 0; } // ... // 判断是否为symnode 不是则直接返回ip 是则继续跟踪path if(ip-\u0026gt;type != T_SYMLINK) { return ip; } } iunlockput(ip); return 0; } uint64 sys_open(void) { char path[MAXPATH]; int fd, omode; struct file *f; struct inode *ip; int n; // ... if(ip-\u0026gt;type == T_DEVICE \u0026amp;\u0026amp; (ip-\u0026gt;major \u0026lt; 0 || ip-\u0026gt;major \u0026gt;= NDEV)){ iunlockput(ip); end_op(); return -1; } // ++++++++++++ 以下新增 ++++++++++++++++ // if inode is a symnode if (ip-\u0026gt;type == T_SYMLINK \u0026amp;\u0026amp; (omode \u0026amp; O_NOFOLLOW) == 0) { // if symnode not marked NOFOLLOW, read recursively // getirec需要额外写一下（略） 根据promt 不建议写成递归 if ((ip = getirec(ip)) == 0) { end_op(); return -1; } // ... } Grade ","permalink":"http://eimy.ink/en/posts/2023/xv6/lab-fs/","summary":"MIT 6.S081 Lab 9 File System","title":"xv6: Lab 9 file system Notes"},{"content":"Lab 5 lazy 实验记录 Lab lazy page allocation要求：https://pdos.csail.mit.edu/6.828/2020/labs/lazy.html\n5.1 Eliminate allocation from sbrk() 1 要求 在syscall sbrk中删除即时分配内存的部分。\n2 实现 把原函数中调用growproc的部分注掉，再增加proc sz即可，diff如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 diff --git a/kernel/sysproc.c b/kernel/sysproc.c index e8bcda9..a410cd5 100644 --- a/kernel/sysproc.c +++ b/kernel/sysproc.c @@ -47,8 +47,9 @@ sys_sbrk(void) if(argint(0, \u0026amp;n) \u0026lt; 0) return -1; addr = myproc()-\u0026gt;sz; - if(growproc(n) \u0026lt; 0) - return -1; + myproc()-\u0026gt;sz += n; + // if(growproc(n) \u0026lt; 0) + // return -1; return addr; } 如果最后报错为page fault（unexpected scause 0x000000000000000f）就对了。\n3 reflection 这是实现lazy allocation的第一步。增加size相当于给proc开空头支票，所有内存面额增长，但实际还没有映射到物理内存。下一部分才处理proc真的需要使用内存的情况。\n5.2 Lazy Allocation 1 要求 要求修改trap.c以处理上一部分引起的page fault，需要给报错的虚拟地址分配对应的物理内存页。\n2 实现 首先在usertrap()中增加应对page fault的代码，总的来说是判断page fault -\u0026gt; 分配内存 -\u0026gt; 映射地址三步。\n根据hints，r_scause()可以用来判断是否pagefault。 需要分配内存的虚拟地址就是报错的地址，可以用r_stval()找到。此处的虚拟地址需要再rounddown对齐到page boundary。 然后参考vm.c中的uvmalloc()，用kalloc分配物理内存，mappages把处理过的虚拟地址映射到物理内存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // kernel/trap.c - usertrap() // ... } else if((which_dev = devintr()) != 0){ // ok } else if(r_scause() == 13 || r_scause() == 15) { // +++++ // if pagefault // get the page boundary uint64 addr = PGROUNDDOWN(r_stval()); // alloc memory char *mem = kalloc(); if(mem == 0){ printf(\u0026#34;usertrap: failed to alloc mem\\n\u0026#34;); } memset(mem, 0, PGSIZE); if(mappages(p-\u0026gt;pagetable, addr, PGSIZE, (uint64)mem, PTE_W|PTE_X|PTE_R|PTE_U) != 0){ kfree(mem); printf(\u0026#34;usertrap: failed to mappages\\n\u0026#34;); } } else { printf(\u0026#34;usertrap(): unexpected scause %p pid=%d\\n\u0026#34;, r_scause(), p-\u0026gt;pid); // ... } 到这里再次echo hi，不出意外会出现panic:uvmunmap not mapped的报错。看一下uvmunmap的代码就会发现，这个报错说明我们在取消虚拟地址和物理内存之间的映射时发现va对应了无效的pte。在实现lazy allocation前不可能有这种情况，所以被认为是错误。但现在lazy alloc的模式里遇到空头支票pte是正常的，所以可以放心地把报错删掉。\n1 2 3 4 5 6 7 8 9 10 // kernal/vm.c void uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free) { // ... if((*pte \u0026amp; PTE_V) == 0) continue; // ++++ normal for lazy alloc if(PTE_FLAGS(*pte) == PTE_V) // ... } 最后echo hi不报错就算通过。\n3 小结 现在lazy alloc的核心部分完成了（甚至就只需要这么几行）。下一部分还需要处理这个改动波及到的其他原有功能。\n5.3 Lazytests and Usertests 1 要求 修改代码以通过提供的压力测试\u0026amp;原功能测试。hints如下：\nHandle negative sbrk() arguments. Kill a process if it page-faults on a virtual memory address higher than any allocated with sbrk(). Handle the parent-to-child memory copy in fork() correctly. Handle the case in which a process passes a valid address from sbrk() to a system call such as read or write, but the memory for that address has not yet been allocated. Handle out-of-memory correctly: if kalloc() fails in the page fault handler, kill the current process. Handle faults on the invalid page below the user stack. 2 实现 其他几个都比较简单，只需要简单加条件/加一行kill（具体看后面的diff）。有一个比较隐秘的：\nHandle the case in which a process passes a valid address from sbrk() to a system call such as read or write, but the memory for that address has not yet been allocated. 还没处理这个问题时，有个usertest会失败：test sbrkarg: sbrkarg: write sbrk failed FAILED\n为此看了下test里报错位置的函数调用链，似乎是这样write -\u0026gt; sys_write -\u0026gt; filewrite -\u0026gt; pipewrite -\u0026gt; copyin -\u0026gt; walkaddr/memmove。于是初步判断问题出在最后几个函数（主要是没找到usertests的正确对单debug方法，不然还是gdb判断更快）。又因为问题必然是出在va没有对应的pa上，所以锁定在了walkaddr函数，而不会是memmove。\n再看walkaddr，显然是还需要处理下pte invalid的情况，报错似乎是在pte2pa这一步发生的（因为lazy alloc下会出现空头pte）。在保证这个pte在有效范围内的前提下，再次分配物理内存即可。以下的lazyalloc是把上一部分usertrap中的片段单独抽成一个函数，方便调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 uint64 walkaddr(pagetable_t pagetable, uint64 va) { pte_t *pte; uint64 pa; if(va \u0026gt;= MAXVA) return 0; pte = walk(pagetable, va, 0); // 这里以下修改了+++++ if(pte == 0 || (*pte \u0026amp; PTE_V) == 0) { // make sure the va is ACTUALLY valid if (va \u0026gt;= PGROUNDUP(myproc()-\u0026gt;trapframe-\u0026gt;sp) \u0026amp;\u0026amp; va \u0026lt; myproc()-\u0026gt;sz) { // lazy alloc lazyalloc(va); } else { return 0; } } if((*pte \u0026amp; PTE_U) == 0) return 0; pa = PTE2PA(*pte); return pa; } 其他部分：\n1 2 3 4 5 6 7 8 9 10 // 加了一个lazyalloc函数 diff --git a/kernel/defs.h b/kernel/defs.h index 4b9bbc0..5dd45a6 100644 --- a/kernel/defs.h +++ b/kernel/defs.h @@ -171,6 +171,7 @@ uint64 walkaddr(pagetable_t, uint64); int copyout(pagetable_t, uint64, char *, uint64); int copyin(pagetable_t, char *, uint64, uint64); int copyinstr(pagetable_t, char *, uint64, uint64); +uint64 lazyalloc(uint64); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // sbrk里处理负数情况 diff --git a/kernel/sysproc.c b/kernel/sysproc.c index a410cd5..ee9cf46 100644 --- a/kernel/sysproc.c +++ b/kernel/sysproc.c @@ -47,7 +47,12 @@ sys_sbrk(void) if(argint(0, \u0026amp;n) \u0026lt; 0) return -1; addr = myproc()-\u0026gt;sz; - myproc()-\u0026gt;sz += n; + if (n \u0026gt; 0) { + myproc()-\u0026gt;sz += n; + } else if (n \u0026lt; 0) { + int sz = myproc()-\u0026gt;sz; + myproc()-\u0026gt;sz = uvmdealloc(myproc()-\u0026gt;pagetable, sz, sz + n); + } // if(growproc(n) \u0026lt; 0) // return -1; return addr; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 // usertrap()中简化代码 + 增加几处err handling diff --git a/kernel/trap.c b/kernel/trap.c index 4f41264..191f717 100644 --- a/kernel/trap.c +++ b/kernel/trap.c @@ -70,16 +70,15 @@ usertrap(void) } else if(r_scause() == 13 || r_scause() == 15) { // if pagefault // get the page boundary - uint64 addr = PGROUNDDOWN(r_stval()); - // alloc memory - char *mem = kalloc(); - if(mem == 0){ - printf(\u0026#34;usertrap: failed to alloc mem\\n\u0026#34;); + uint64 addr = r_stval(); + if (addr \u0026gt;= p-\u0026gt;sz || addr \u0026lt; p-\u0026gt;trapframe-\u0026gt;sp){ + p-\u0026gt;killed = 1; + // printf(\u0026#34;usertrap: invalid address\\n\u0026#34;); + exit(-1); } - memset(mem, 0, PGSIZE); - if(mappages(p-\u0026gt;pagetable, addr, PGSIZE, (uint64)mem, PTE_W|PTE_X|PTE_R|PTE_U) != 0){ - kfree(mem); - printf(\u0026#34;usertrap: failed to mappages\\n\u0026#34;); + if (lazyalloc(addr) != 0) { + p-\u0026gt;killed = 1; + exit(-1); } } else { 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // uvmunmap、uvmcopy中允许pte == 0的情况 // 改uvmcopy是为了解决fork中拷贝内存时的bug diff --git a/kernel/vm.c b/kernel/vm.c index caddaa7..4e258b1 100644 --- a/kernel/vm.c +++ b/kernel/vm.c @@ -5,6 +5,8 @@ #include \u0026#34;riscv.h\u0026#34; #include \u0026#34;defs.h\u0026#34; #include \u0026#34;fs.h\u0026#34; +#include \u0026#34;spinlock.h\u0026#34; +#include \u0026#34;proc.h\u0026#34; @@ -181,7 +188,8 @@ uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free) for(a = va; a \u0026lt; va + npages*PGSIZE; a += PGSIZE){ if((pte = walk(pagetable, a, 0)) == 0) - panic(\u0026#34;uvmunmap: walk\u0026#34;); + continue; + // panic(\u0026#34;uvmunmap: walk\u0026#34;); if((*pte \u0026amp; PTE_V) == 0) continue; // normal for pagefault if(PTE_FLAGS(*pte) == PTE_V) @@ -223,6 +231,27 @@ uvminit(pagetable_t pagetable, uchar *src, uint sz) memmove(mem, src, sz); } // Allocate PTEs and physical memory to grow process from oldsz to // newsz, which need not be page aligned. Returns new size or 0 on error. uint64 @@ -315,9 +344,11 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz) for(i = 0; i \u0026lt; sz; i += PGSIZE){ if((pte = walk(old, i, 0)) == 0) - panic(\u0026#34;uvmcopy: pte should exist\u0026#34;); + continue; + // panic(\u0026#34;uvmcopy: pte should exist\u0026#34;); if((*pte \u0026amp; PTE_V) == 0) - panic(\u0026#34;uvmcopy: page not present\u0026#34;); + // panic(\u0026#34;uvmcopy: page not present\u0026#34;); + continue; pa = PTE2PA(*pte); flags = PTE_FLAGS(*pte); if((mem = kalloc()) == 0) Grade 相比pagetable来说真是非常仁慈的lab了。\n","permalink":"http://eimy.ink/en/posts/2023/xv6/lab-lazy/","summary":"MIT 6.S081 Lab 5 Lazy Allocation","title":"xv6: Lab 5 lazy Notes"},{"content":"Lab 4 traps 实验记录 课上的截图，对理解trap很有帮助：high-level picture of the procedure of switching from user mode to supervisor mode\n4.2 Backtrace 1 要求 实现backtrace()函数，打印当前stack中的函数调用位置\n2 实现 跟着hints一步步实现:\n主要函数如下，除此以外还需要声明函数、在指定位置调用etc.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // kernel/printf.c void backtrace() { // // read the current frame pointer uint64 curfp = r_fp(); uint64 begin = PGROUNDDOWN(curfp); uint64 end = PGROUNDUP(curfp); // while curfp still in range of stack while(curfp \u0026gt;= begin \u0026amp;\u0026amp; curfp \u0026lt; end) { // print frame printf(\u0026#34;%p\\n\u0026#34;, *(uint64 *)(curfp - 8)); // get prev fp // be careful with pointers! curfp = *((uint64 *) (curfp - 16)); } } // also modified kernel/defs.h, kernel/riscv.h, // kernel/sysproc.c 3 reflection 循环里的逻辑是打印frame pointer - 8位置的return addr -\u0026gt; 更新frame pointer为其指向的prev frame pointer -\u0026gt; 循环直到超出范围。\n唯一一个卡手点在pointer casting那里（可见我写C真的不熟练、）。\n4.3 Alarm 1 要求 通过实现两个syscall\u0026ndash;sigalarm(interval, handler)和sigreturn()，实现对进程的定时警报。sigalarm(interval, handler)使得每隔intervel数量的硬件ticks，会触发一次handler函数来进行警报。\n2 实现 instruction里分了两部分。\n第一部分先实现（sigalarm中初始化警报相关参数 -\u0026gt; 在tick数量达到interval的要求时，触发第一次警报）。实现方法是在usertrap()（kernel/trap.c）中，在当前进程累计tick数达interval时，把handler装进trapframe的epc中。这样在返回user program时就会首先执行epc里的函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 先写sigalarm函数 初始化警报参数 uint64 sys_sigalarm(void) { int interval; uint64 handler; // get interval a0 if(argint(0, \u0026amp;interval) \u0026lt; 0) return -1; // get pointer to the handler function if(argaddr(1, \u0026amp;handler) \u0026lt; 0) return -1; // put it into the struc of myproc() myproc()-\u0026gt;alarm_handler = handler; myproc()-\u0026gt;interval = interval; // myproc()-\u0026gt;numticks = 0; return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 void usertrap(void) { int which_dev = 0; // ... // give up the CPU if this is a timer interrupt. if(which_dev == 2) { p-\u0026gt;numticks++; if( p-\u0026gt;interval \u0026gt; 0 \u0026amp;\u0026amp; p-\u0026gt;numticks == p-\u0026gt;interval){ // save the current trapframe bf overwriting p-\u0026gt;tpcopy = *(p-\u0026gt;trapframe); // put the handler func into the program counter // user will exec this func after returning p-\u0026gt;trapframe-\u0026gt;epc = p-\u0026gt;alarm_handler; } yield(); } usertrapret(); } 但这样直接写进epc会导致原epc被覆盖，同时许多原进程保存在寄存器的内容也会在执行handler函数时被覆盖，所以第二部分中要用sigreturn()来解决这个问题。instr里已经指定了sigreturn()的作用，它会在traphandler结束时被调用，专门用来恢复原进程内容。\n关于怎么恢复原进程，lab instr里的推荐做法（似乎）是在覆盖epc前，保存相关的寄存器。根据riscv convention我猜测至少需要保存所有的argument/pointer/save reg以及几个特殊寄存器。\n但这样好像有点麻烦，更加直接（？）的解决方式是覆盖前直接拷贝一份进程的trapframe放一边，再在需要恢复时拷回来。\n第三部分（第三个test）要求handler在没有返回前，不可以再次被调用。这里稍微卡了下，后来发现只要用tick计数就可以控制：目前累计ticks在只有在达到interval时会触发handler，也就是说只要累计ticks没有被重置，handler就只会被触发一次。利用这点，我们只在sigreturn中重置累计ticks，这样就等同于“在调用sigreturn（即handler结束）之前，不会有再次调用发生“。\n主要代码是这些：\n1 2 3 4 5 6 7 8 9 // usertrap()中加一句 if( p-\u0026gt;interval \u0026gt; 0 \u0026amp;\u0026amp; p-\u0026gt;numticks == p-\u0026gt;interval){ // save the current trapframe bf overwriting p-\u0026gt;tpcopy = *(p-\u0026gt;trapframe); // +++++++tpcopy是在proc.h中声明的新参数 // put the handler func into the program counter // user will exec this func after returning p-\u0026gt;trapframe-\u0026gt;epc = p-\u0026gt;alarm_handler; } 1 2 3 4 5 6 7 8 9 uint64 sys_sigreturn(void) { // 把trapframe恢复成进入handler前的样子 *(myproc()-\u0026gt;trapframe) = myproc()-\u0026gt;tpcopy; // 重置计数器 由此只有当一次handler call结束后才可能有下一次alarm myproc()-\u0026gt;numticks = 0; return 0; } 其他还有一堆syscall声明相关的修改，跟之前的syscall lab差不多。\n3 思考 这个task中最关键的是理解trap的流程和riscv中相关寄存器的作用。\nGrade ","permalink":"http://eimy.ink/en/posts/2023/xv6/lab-traps/","summary":"MIT 6.S081 Lab 4 traps","title":"xv6: Lab 4 traps Notes"},{"content":" Translation WIP: written in Chinese.\nLab url：https://pdos.csail.mit.edu/6.828/2020/labs/pgtbl.html\ncourse site：https://pdos.csail.mit.edu/6.828/2020/schedule.html\ngdb usage：https://pdos.csail.mit.edu/6.1810/2022/labs/gdb.html\n3.1 Print a page table 1 具体要求 要求实现一个vmprint()函数，接受一个pagetable参数，按照要求的格式打印出这个pagetable。\n1 2 3 4 5 6 7 # Print Format: # page table [argument] page table 0x0000000087f6e000 # [depth] [pte index]: [pagetable entry] pa [physical address] ..0: pte 0x0000000021fda801 pa 0x0000000087f6a000 .. ..0: pte 0x0000000021fda401 pa 0x0000000087f69000 .. .. ..0: pte 0x0000000021fdac1f pa 0x0000000087f6b000 2 实现方法 这个task相关的知识点：\nVA, PA, PPN, PTE的构成、作用和它们之间的关系，比如 虚拟地址（VA）中包括27bits，其中每9bits对应一个page table entry（PTE） VA包含几个部分，其中27位（3*9）用于在各层页表中索引PTE，另有12位offset用来在PA中索引定位 页表PTE中的PPN用来寻找下一层页表 xv6页表的three-level tree结构 (xv6book, p.30-1)： VA-PA转换的逻辑是：最上层页表的地址是由satp寄存器记录的；通过va中27bits里最左的9bits索引，查找到最上层的页表中对应的PTE；然后通过这个PTE中的PPN找到第二个页表，由VA中第二个9bits索引到对应的PTE，以此类推\u0026hellip;最后再结合VA中的offset定位PA VA-PA translation是由硬件memory management unit（MMU）实现的（如果没听错，lec里说软件也可以，但是硬件更快） 如何判断PPN映射到了下一层页表还是物理内存？ 参考freewalk()，如果(pte \u0026amp; (PTE_R|PTE_W|PTE_X)) == 0，即不可读/写/执行，就说明PPN没有映射到物理内存，而是映射到了更低层的页表 有三层pagetable，我选择了递归打印。这个task标了easy难度，跟着hints就能实现。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // helper function for vmprint void printhelper(pagetable_t pagetable, int depth) { // there are 2^9 = 512 PTEs in a page table. for(int i = 0; i \u0026lt; 512; i++){ pte_t pte = pagetable[i]; // skip invalid pages if (!(pte \u0026amp; PTE_V)) { continue; } // print indentation for (int i = 0; i \u0026lt;= depth; i++) { printf(\u0026#34;..\u0026#34;); if(i != depth) { printf(\u0026#34; \u0026#34;); } } printf(\u0026#34;%d: pte %p pa %p\\n\u0026#34;, i, pte, PTE2PA(pte)); // has lower-level pt -\u0026gt; recursive call on child if((pte \u0026amp; (PTE_R|PTE_W|PTE_X)) == 0){ uint64 child = PTE2PA(pte); printhelper((pagetable_t)child, depth + 1); } } } // print the content of a page table void vmprint(pagetable_t pagetable) { // refer to freewalk() printf(\u0026#34;page table %p\\n\u0026#34;, pagetable); printhelper(pagetable, 0); } 3 结果 和要求print内容一致，test ok。\n4 问题\u0026amp;思考 最后有个challenge question问打印出来的page0、page1、page2里是什么。\n因为vmprint是在kernel/exec.c中调用的，所以回去看kernel/exec.c里有分配页表的地方，源码上面有注释：\n1 2 3 4 5 6 7 8 9 10 11 ... // 分配了1 page // Load program into memory. 那这个页表应该是data+text if((sz1 = uvmalloc(pagetable, sz, ph.vaddr + ph.memsz)) == 0) goto bad; ... // 分配了2 pages // Allocate two pages at the next page boundary. // Use the second as the user stack. if((sz1 = uvmalloc(pagetable, sz, sz + 2*PGSIZE)) == 0) goto bad; 所以根据Figure3.4，这些应该是init user stack时分配的，page0是data+text，page1是guard page（PTE_V not set, 不可read/write），page2是顶上的stack。\n3.2 A kernel page table per process 1 要求 让每个进程都有一个自己的kernel pagetable，它们的页表和global kernel page保持一致。在切换进程时，也要切换到该进程对应的kernel pagetable（无进程运行时用global kernel pagetable。\n和当前task相关的知识点：\n每个进程维护一个页表的用户地址空间和一个页表的内核地址空间：\u0026ldquo;Xv6 maintains one page table per process, describing each process’s user address space, plus a single page table that describes the kernel’s address space.\u0026rdquo; (xv6book, p.31) Figure 3.3 内核地址空间里的映射关系（明白这点才知道之后如何构建kernel pagetable的mapping），里面哪些是直接映射、哪些不是（和后面的kstack有关）。 以及上面的页表结构，还会再次用到 2 实现方法 和hints给的顺序基本一致：\n声明kernel pagetable变量：在 struct proc 中增加变量pagetable_t kpagetable，由此每个process都有了自己的kpt 1 2 3 4 5 6 // kernel/proc.h 结构体里增加一个变量 struct proc { // ... private pagetable_t kpagetable; // (+) Kernel page table } 仿照kvminit 写一个函数，用来创建kpagetable页表并构建映射： 理解：要在分配进程（即allocproc()里）时，增加「给kpagetable分配内存」 -\u0026gt; 「直接映射到和global kernel pagetable相同物理地址」这些构建操作 思路：这些功能在kvminit中已有类似实现，但是不能直接调用kvminit，因为它调用了kvmmap()，后者是用mappages direct map了global kernel page和对应的pa。这里是要map各个进程的kernel page和pa，所以需要另写一个和kvmmap类似、但是允许传入指定pagetable的函数，然后在构建kpagetable时调用。 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // kernel/vm.c 实现一个类似kvmmap的函数 // +++++++以下都是新增的 // add a mapping to a given page table void uvmmap(pagetable_t pt, uint64 va, uint64 pa, uint64 sz, int perm) { if(mappages(pt, va, sz, pa, perm) != 0) panic(\u0026#34;uvmmap\u0026#34;); } // 参考了kvminit, // 把kvmmap换成了上面的uvm以自定义需要map的pagetable // Create a kernel page table for a given process pagetable_t proc_kpagetable(struct proc *p) { pagetable_t kpagetable = (pagetable_t) kalloc(); memset(kpagetable, 0, PGSIZE); // uart registers uvmmap(kpagetable, UART0, UART0, PGSIZE, PTE_R | PTE_W); // virtio mmio disk interface uvmmap(kpagetable, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W); // CLINT uvmmap(kpagetable, CLINT, CLINT, 0x10000, PTE_R | PTE_W); // PLIC uvmmap(kpagetable, PLIC, PLIC, 0x400000, PTE_R | PTE_W); // map kernel text executable and read-only. uvmmap(kpagetable, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X); // map kernel data and the physical RAM we\u0026#39;ll make use of. uvmmap(kpagetable, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W); // map the trampoline for trap entry/exit to // the highest virtual address in the kernel. uvmmap(kpagetable, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X); return kpagetable; } // +++++++ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // kernel/proc.c 新增代码片段 // Look in the process table for an UNUSED proc. // If found, initialize state required to run in the kernel, // and return with p-\u0026gt;lock held. // If there are no free procs, or a memory allocation fails, return 0. static struct proc* allocproc(void) { // .... // An empty user page table. p-\u0026gt;pagetable = proc_pagetable(p); if(p-\u0026gt;pagetable == 0){ freeproc(p); release(\u0026amp;p-\u0026gt;lock); return 0; } // +++++++++++ // Create a kernel page table. p-\u0026gt;kpagetable = proc_kpagetable(p); // 在这里调用 if(p-\u0026gt;kpagetable == 0){ freeproc(p); release(\u0026amp;p-\u0026gt;lock); return 0; } // +++++++++++ // .... } 在kpagetable的页表中添加kernel stack的映射： 理解+思路：原本kernel stack的初始化是在启动时的procinit()里完成的。现在为了把它加进kpagetable的映射中，需要把整个初始化过程移动到创建kpagetable的地方——也就是allocproc()中。 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // kernel/proc.c 移动代码 // initialize the proc table at boot time. void procinit(void) { struct proc *p; initlock(\u0026amp;pid_lock, \u0026#34;nextpid\u0026#34;); for(p = proc; p \u0026lt; \u0026amp;proc[NPROC]; p++) { initlock(\u0026amp;p-\u0026gt;lock, \u0026#34;proc\u0026#34;); // ----- 这里注释/删除掉原本的kstack初始化 } kvminithart(); } static struct proc* allocproc(void) { // ++++++++上面删掉的代码移动到这里 // Allocate a page for the process\u0026#39;s kernel stack. // Map it high in memory, followed by an invalid // guard page. char *pa = kalloc(); if(pa == 0) panic(\u0026#34;kalloc\u0026#34;); // get kstack va uint64 va = KSTACK((int)(p - proc)); // map kernal pagetable with kernal stack \u0026lt;- 这里构建映射 uvmmap(p-\u0026gt;kpagetable, va, (uint64)pa, PGSIZE, PTE_R | PTE_W); // 把va存在proc结构里 p-\u0026gt;kstack = va; // ++++++++++ // Set up new context to start executing at forkret, // which returns to user space. memset(\u0026amp;p-\u0026gt;context, 0, sizeof(p-\u0026gt;context)); p-\u0026gt;context.ra = (uint64)forkret; p-\u0026gt;context.sp = p-\u0026gt;kstack + PGSIZE; return p; } 修改进程调度函数 scheduler() ： 理解：（1）在切换进程时，把对应的kpagetable加载到satp寄存器，并清除缓存[*否则会导致错误的mapping被留着继续用]（2）没有进程运行时用global kernel_pagetable 思路：参考kvminithart()函数，它实现了把global kernel pagetable加载到satp以及清除缓存。只要页表改成proc-\u0026gt;kpagetable即可 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // kernel/proc.c 修改调度函数 void scheduler(void) { // ... for(;;){ // Avoid deadlock by ensuring that devices can interrupt. intr_on(); int found = 0; // use kernel_pagetable when no process is running if(found==0){ kvminithart(); // ++++ 无进程时使用global kernel pt } for(p = proc; p \u0026lt; \u0026amp;proc[NPROC]; p++) { acquire(\u0026amp;p-\u0026gt;lock); if(p-\u0026gt;state == RUNNABLE) { // Switch to chosen process. It is the process\u0026#39;s job // to release its lock and then reacquire it // before jumping back to us. p-\u0026gt;state = RUNNING; c-\u0026gt;proc = p; w_satp(MAKE_SATP(p-\u0026gt;kpagetable)); // ++++++ sfence_vma(); // ++++++ // 在跳进进程之前，就要完成satp的切换 swtch(\u0026amp;c-\u0026gt;context, \u0026amp;p-\u0026gt;context); // ... } // ... } } 在freeproc()中增加释放kstack和kpagetable内存的操作 理解：要求清除kpagetable中的所有映射，但是不能动物理内存，否则会影响global kernel pagetable（毕竟它们的va直接映射到了同一物理内存上）；kstack是process-specific的，可以全部清除 思路：关于kpagetable，参考freewalk() 写一个函数，遍历三层pagetable，对有效pte进行递归释放；如果pagetable直接映射到了物理内存就不递归。至于kstack，直接调用已有方法uvmumap()就可以清除映射。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // kernel/proc.c 增加函数 //++++++ // Free a process\u0026#39;s page table without // freeing the physical memory it refers to void proc_freepagetable_vonly(pagetable_t kpagetable) { // there are 2^9 = 512 PTEs in a page table. for(int i = 0; i \u0026lt; 512; i++){ pte_t pte = kpagetable[i]; if(pte \u0026amp; PTE_V) kpagetable[i] = 0; // 只有当映射到了下一层页表时，才会继续递归 if((pte \u0026amp; PTE_V) \u0026amp;\u0026amp; (pte \u0026amp; (PTE_R|PTE_W|PTE_X)) == 0){ // this PTE points to a lower-level page table. uint64 child = PTE2PA(pte); proc_freepagetable_vonly((pagetable_t)child); } } kfree((void*)kpagetable); } //++++++ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // kernel/proc.c 对freeproc的改动如下 // free a proc structure and the data hanging from it, // including user pages. // p-\u0026gt;lock must be held. static void freeproc(struct proc *p) { // ... p-\u0026gt;killed = 0; p-\u0026gt;xstate = 0; // ++++ 以下新增 if(p-\u0026gt;kstack){ // 第四个参数do_free设置为1 即为同时释放物理内存 uvmunmap(p-\u0026gt;kpagetable, p-\u0026gt;kstack, 1, 1); } p-\u0026gt;kstack = 0; if(p-\u0026gt;kpagetable) proc_freepagetable_vonly(p-\u0026gt;kpagetable); p-\u0026gt;kpagetable = 0; // +++++ 以上新增 p-\u0026gt;state = UNUSED; } 彩蛋：修改kvmpa()函数 理解：似乎是初始化disk时需要调用kvmpa，但是这个函数中目前walk的是global kernel pagetable，需要改成proc的kpagetable。 实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // kernel/vm.c // translate a kernel virtual address to // a physical address. only needed for // addresses on the stack. // assumes va is page aligned. uint64 kvmpa(pagetable_t kpagetable, uint64 va) // 签名加了页表的参数 { uint64 off = va % PGSIZE; pte_t *pte; uint64 pa; pte = walk(kpagetable, va, 0); // 这里修改成kpagetable if(pte == 0) panic(\u0026#34;kvmpa\u0026#34;); if((*pte \u0026amp; PTE_V) == 0) panic(\u0026#34;kvmpa\u0026#34;); pa = PTE2PA(*pte); return pa+off; } 1 2 3 4 5 // 然后再跟着报错， // 把调用这个kvmpa的地方传入 myproc()-\u0026gt;kpagetable // kernel/virtio_disk.c disk.desc[idx[0]].addr = (uint64) kvmpa(myproc()-\u0026gt;kpagetable, (uint64) \u0026amp;buf0); 其他注意：\n添加函数后注意在def.h中更新声明 可以修改kernel/vm.c and kernel/proc.c，但不要动测试相关的代码 debug比较累 3 结果 tesk全部ok\n4 问题 有两个我觉得比较tricky的地方 freeproc的实现，主要是要理解释放内存的范围，然后找/写对应的函数 hints里没有提到的kvmpa()函数。在完成所有hints后make qemu会出现panic：kvmpa的报错，这个函数的调用链不是特别清楚。 3.3 Simplify copyin/copyinstr 1 要求 用vmcopy.c中给出的新函数copyin_new和copyinstr_new简化原有的copyin和copyinstr。\n2 分析 涉及到的知识点：\nuser address space和kernel address space（xv6book, p.32-36） kernel data和user data的起始虚拟地址不同 它们和物理地址的映射关系（kernel space中部分是direct-mapped的） address space和pagetable的关系 地址空间是一个抽象概念，它表示了一个进程的虚拟地址的范围 页表是实际用于将这些虚拟地址映射到物理地址的数据结构 然后简单分析一下task：\n原先由于global kernel pt里没有记录每个进程的用户地址空间的mapping，所以copyin在接受user的虚拟地址后，需要在软件中walk页表把虚拟地址转换成物理，然后才能从物理地址拷贝指定大小的内存到目标位置。\n现在我们每个进程都有自己的kpagetable，所以只要把用户地址空间的mapping也记录进来就能一定程度上简化步骤。为此需要把进程用户地址空间里的pte拷贝到kpagetable里。\n为什么可以记录进来？这和user space和kernel space的分布有关。kernel启动后的最低地址在PLIC（0xC000000），而user是从0开始的，它们的虚拟地址范围不重合，所以可以直接把user space的mapping直接加到（kernel自己不用的）kernel space里。\n3 实现 主要新写一个函数，用来把user pagetable拷贝到kpagetable里。\n简化copyin 1 2 3 4 5 6 7 8 9 10 // kernel/vm.c 修改函数 // Copy from user to kernel. // Copy len bytes to dst from virtual address srcva in a given page table. // Return 0 on success, -1 on error. int copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len) { return copyin_new(pagetable, dst, srcva, len); // ++ } 写一个从uvm拷到kvm里的函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // kernel/vm.c 新增函数uvm2kvm // copy uvm to kvm from START to END, // return 0 if successfull and -1 otherwise int uvm2kvm(pagetable_t upgtbl, pagetable_t kpgtbl, uint64 start, uint64 end) { // pointers to user pte and kernel pte // as walk() returns pointers pte_t *upte, *kpte; // exception: exceed plic limit if(end \u0026lt; start || PGROUNDUP(end) \u0026gt;= PLIC) return -1; // walk through every pte for(uint64 va = PGROUNDUP(start); va \u0026lt; end; va += PGSIZE){ // look up user pte if ((upte = walk(upgtbl, va, 0)) == 0) { panic(\u0026#34;uvm2kvm: failed to find user pte\u0026#34;); } // look up kernel pte if ((kpte = walk(kpgtbl, va, 1)) == 0) { panic(\u0026#34;uvm2kvm: failed to create kernel pte\u0026#34;); } // add mapping // and cancelling user accessibility meanwhile *kpte = *upte \u0026amp; (~PTE_U); // set the user flag to 0 (forbid user access) } return 0; } 修改所有可能会改动/初始化user mapping的函数，包括fork(), exec(), growproc(), userinit() 在改动后需重新把user pagetable拷贝进kpagetable\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // kernel/proc.c 修改fork \u0026amp; growproc \u0026amp; userinit int fork(void) { // ... np-\u0026gt;sz = p-\u0026gt;sz; // copy user addr space into kernel space // 注意是从newprocess的pagetable拷 if ((uvm2kvm(np-\u0026gt;pagetable, np-\u0026gt;kpagetable, 0, np-\u0026gt;sz)) \u0026lt; 0){ freeproc(np); release(\u0026amp;np-\u0026gt;lock); return -1; } np-\u0026gt;parent = p; // ... } // Grow or shrink user memory by n bytes. // Return 0 on success, -1 on failure. int growproc(int n) { uint sz; struct proc *p = myproc(); sz = p-\u0026gt;sz; if(n \u0026gt; 0){ if((sz = uvmalloc(p-\u0026gt;pagetable, sz, sz + n)) == 0) { return -1; } // ++++ mem grow了，重新map一次 if(uvm2kvm(p-\u0026gt;pagetable, p-\u0026gt;kpagetable, p-\u0026gt;sz, sz) \u0026lt; 0) { return -1; } } else if(n \u0026lt; 0){ sz = uvmdealloc(p-\u0026gt;pagetable, sz, sz + n); // ++++ mem shrink了，只清除映射 不动物理内存 if (n \u0026gt;= PGSIZE) { uvmunmap(p-\u0026gt;kpagetable, PGROUNDUP(sz), n/PGSIZE, 0); } } p-\u0026gt;sz = sz; return 0; } void userinit(void) { // ... // allocate one user page and copy init\u0026#39;s instructions // and data into it. uvminit(p-\u0026gt;pagetable, initcode, sizeof(initcode)); p-\u0026gt;sz = PGSIZE; // 在pagetable init完成之后 uvm2kvm(p-\u0026gt;pagetable, p-\u0026gt;kpagetable, 0, p-\u0026gt;sz); // +++ // ... } 1 2 3 4 5 6 7 8 9 10 11 12 // kernel/exec.c 修改exec int exec(char *path, char **argv) { // ... // （位置在进程页表初始化完之后） // copy user pagetable to kernel if(uvm2kvm(pagetable, p-\u0026gt;kpagetable, 0, sz) \u0026lt; 0) goto bad; // ... } 确认copyin没问题了，相似方法修改copyinstr 1 2 3 4 5 6 7 // kernel/vm.c 修改函数copyinstr int copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max) { return copyinstr_new(pagetable, dst, srcva, max); // +++ } 4 结果 tests ok\nFINAL：tests\u0026amp;grade 参考 https://clownote.github.io/2021/03/11/xv6/Xv6-Lab-page-tables/\nhttps://blog.csdn.net/LostUnravel/article/details/121340933\n","permalink":"http://eimy.ink/en/posts/2023/xv6/lab-pgtbl/","summary":"MIT 6.S081 Lab3 Pagetable","title":"xv6: Lab 3 pgtbl Notes"},{"content":"A summary of what i learned in CS61C (fa20).\nMy course repo on GitHub: github/cs61c\nSummary of the Course Centered on several great ideas in computer architecture. Specifically,\nThe first half of the course teaches what\u0026rsquo;s called \u0026ldquo;the old school machine structures\u0026rdquo;.\nHigh level language program - C [lec3-6]\nAssembly language program - RISC-V [lec7-13]\nMachine Language - still RISC-V, but without pseudo instructions [lec7-13]\nHardware architecture description - block diagrams, datapaths, cache, pipelining, virtual mem, etc. [lec17-27]\nLogic circuit description [lec14-16]\nBasically, that\u0026rsquo;s everything from the top \u0026ndash; the programmer-friendly high level language C\u0026ndash;, to the bottom arch \u0026ndash; circuits, logic gates, and transistors\u0026ndash;.\nIn terms of actual sequence, it\u0026rsquo;s like top -\u0026gt; middle, then bottom -\u0026gt; middle, and finally the two lines meet at around project3 (DIY a CPU datapath).\nThe second half teaches the new-school structures, which include more recent ideas of parallelism / high performance programming that companies hardware improvements.\ndata-level parallelism - SIMD [lec32], MapReduce, Spark, etc. [lec36]\nthread-level parallelism - threads, cache coherency, OpenMP, etc. [lec33-35]\ndependability [lec38]\nSummary of the Labs Not including ones I didn\u0026rsquo;t manage to set up.\nLab1 Number Rep, C and CGDB: familiarize you with c and debugging tools Lab2 Advanced C: bit manipulations, memory allocation, and pointers in C Lab3 RISCV Assembly: ask u to figure out how simple C programs work on a lower level and write RISC-V assembly code Lab4 RISCV Functions, Pointers: still RISC-V practices, asking you to modify code to make the program work Lab5 Logisim: ~ build logic gates and practise with combinational logic Lab7 Caches: back to RISC-V, implement and optimize matrix-related functions to understand how cache works. This lab is valuable as it touches on one way to squeeze out performance. Lab8 OS, I/O, DMA, Disks, Networking \u0026amp; Virtual Memory: ~ play with a virtual memory simulator to understand how it works Lab9 SIMD Instructions: ~ work on single instruction multiple data (SIMD) \u0026ndash; write C functions and improve their performance with x86 intrinsics. It\u0026rsquo;s like inserting assembly code into C code. (Note that ARM users unfortunately would have to use ARM NEON intrin to be able to compile the programs.) Lab10 Thread Level Parallelism: have you experience parallel programing with C + OpenMP. Ask you to apply parallelism to the implementation of sum vector and dot product C funcs. Progress Planned to complete the course within 30 study days, and achieved the goal!\n【0611】setup, lab00 【0615】lec1\u0026amp;2 【0616】lec3 【0617】lec4 【0625】lec5, lab01 【0626】lec6 【0627】proj1A 【0702/03】proj1 Fin 【0704】K\u0026amp;Rch1-2 【0705】lec7+8.1, lab2 【0706】disc2 【0715】lec8-10 【0716】lab3 【0719】disc3, disc4 【0724】proj2 partA 50% 【0725】proj2 partA fin 【0801】lec11-13 【0802】disc5, lab4, lec14-15 【0803】lecs16+SDS State Logic handouts, lec17 【0804】lab5, lec 18-19 【0805】lec20-27 (fin CPU Pipelining Caches), disc6-8 【0806】disc9, lab7, lec28-2931 (fin OS VMi) 【0807】lec30-31(VMii I/O), disc10, lab8, disc11 【0808】lec32-35 (SIMD/MIMD, Parallelism), lec36-38 (MapReduce, WSC, RAID) 【0809】disc12, lab9, lab10, disc13-14 【skipped due to compatibility probs】proj4, proj3, lab6, lab11 Postscript should\u0026rsquo;ve been preparing for the incoming semester, projects and stuff but couldn\u0026rsquo;t resist the temptation of learning how computer works :\u0026gt;\n","permalink":"http://eimy.ink/en/posts/2023/cs61c/","summary":"Interesting","title":"CS61C Completed"},{"content":"Note: This passage is written in Chinese and translated into English via ChatGPT.\nI found a project tutorial for AWS Amplify on the AWS official website. It seems that it has not been translated into Chinese yet, so I took some notes while exploring it.\nIntroduction to AWS Amplify Amplify is a comprehensive platform that provides static resource hosting for:\nCreating AWS backends with features like authentication, data storage, and more for web, iOS, or Android applications in minutes. Building frontend UI intuitively from design to code with Figma integration and connecting it to the backend with just a few clicks. In summary, apart from a few distinctive features, it is quite similar to services like Netlify and also offers a certain amount of free usage:\nAWS Amplify Features: Supports visual development of full-stack websites or applications. Supports deploying mobile applications, which Netlify does not. Comprehensive ecosystem, making it convenient to use other AWS services. Getting Started with Amplify The main goal is to host a web page and deploy a backend, and additionally, there are examples of adding AWS authentication and storage services as supplementary features.\nNote: The following steps only show the configuration and deployment process related to Amplify. The complete code of the app is not provided here. Please refer to the original article for the specific app code.\nPrerequisites Create a frontend application or use an existing one. Push it to a GitHub repository. Deploying the Frontend Register for an AWS account (requires a credit card that can be charged $1). Log in and find the AWS Management Console. Go to the \u0026ldquo;Get started\u0026rdquo; page and click \u0026ldquo;Get started\u0026rdquo; under the \u0026ldquo;Host your web app\u0026rdquo; section. Choose GitHub as the deployment option, confirm the repository and branch information, and click \u0026ldquo;Next\u0026rdquo; multiple times. Click \u0026ldquo;Save and deploy\u0026rdquo; to complete the process. Afterward, any modifications and pushes to the repository will automatically update the website. Completion Page Installing Amplify CLI - Adding/Managing AWS Services Installing the CLI Amplify CLI allows you to add AWS services to your project.\n1 2 # Install CLI npm install -g @aws-amplify/cli Note: Compatibility issue on ARM Macs\nIf you encounter issues on M1/M2 Macs, where the CLI installs successfully but commands don\u0026rsquo;t respond, you can try one of the following solutions. Refer to issue #10193 for more information:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Solution 1: Install Rosetta (may or may not work) softwareupdate --install-rosetta # Solution 2: Clone an older version of the CLI (@danrivett) (may or may not work) # Environment: amplify-cli@v10.4.1 node@16 git clone https://github.com/aws-amplify/amplify-cli.git cd amplify-cli git checkout v10.4.1 # Avoids building the dev branch but builds a release tag; update as necessary yarn \u0026amp;\u0026amp; yarn build rm ~/.amplify/bin/amplify ln -s $(pwd)/packages/amplify-cli/bin/amplify ~/.amplify/bin/amplify # Solution 3: Manually download and install an older version from the releases page (@kzetxa) # Environment: node@16.12.0, Amplify 10.3.1, macOS Monterey 12.6 # 1. Delete the binary at /usr/local/bin/amplify # 2. Rename the binary inside the downloaded package # 3. Move it to the location where the old deleted binary was sudo chown -R $(whoami) ~/.amplify I have successfully used the third solution, with the same environment as mentioned. It seems that it involves a translation from x86.\nConfiguring the CLI 1 2 3 4 5 6 7 8 # Configure the CLI amplify configure # 1. You will be redirected to the web console for login. # 2. Select your region. # 3. Return to the web console to create a new user. # The user needs programmatic access. # Record the access key ID and secret access key. You will need the CLI for adding various services. Additionally, you can now use the following command to directly access the console:\n1 2 # In the local terminal amplify console Deploying the Backend Launching Amplify Studio Go back to the application page - backend environments - get started - launch studio - and run the local setup command in the terminal (copy from the web page).\nThen choose the configuration options:\n1 2 3 4 5 6 7 8 ? Choose your default editor: Visual Studio Code ? Choose the type of app that you\u0026#39;re building: JavaScript ? What javascript framework are you using: React ? Source Directory Path: src ? Distribution Directory Path: build ? Build Command: npm run-script build ? Start Command: npm run-script start ? Do you plan on modifying this backend? Y Adding Backend Build Configuration 1 2 3 4 5 6 7 8 9 10 11 # App settings \u0026gt; Build settings # Add backend configuration ... backend: phases: build: commands: - \u0026#39;# Execute Amplify CLI with the helper script\u0026#39; - amplifyPush --simple frontend: ... Example: Adding AWS Authentication This example demonstrates how to add AWS authentication to a note-taking application.\nAdding Authentication via the Command Line 1 2 3 4 5 # In the local terminal # Create the authentication service locally amplify add auth # Deploy it amplify push --y Using the Auth Service in src/index.js Import the configuration and add the following code to your src/index.js file:\n1 2 3 4 // in `src/index.js` import { Amplify } from \u0026#39;aws-amplify\u0026#39;; import config from \u0026#39;./aws-exports\u0026#39;; Amplify.configure(config); Importing Authentication into src/App.js Import similar to the following (a sample with only authentication):\n1 2 3 4 5 6 7 8 9 10 import \u0026#34;@aws-amplify/ui-react/styles.css\u0026#34;; import { withAuthenticator } from \u0026#34;@aws-amplify/ui-react\u0026#34;; function App({ signOut }) { return ( /* Middle part omitted */ ); } export default withAuthenticator(App); Finally, push the changes to the remote repository.\nAdding a Backend Database Add a GraphQL API 1 2 amplify add api # Choose GraphQL Local configuration Create a schema in /amplify/backend/api/\u0026lt;api_name\u0026gt;/schema.graphql. For example:\n1 2 3 4 5 type Note @model @auth(rules: [{ allow: public }]) { id: ID! name: String! description: String } Deploy the service 1 amplify push --y # --yes: Omit all command-line configuration options and set as default This will do three things:\nCreate the AWS AppSync API Create a DynamoDB table Create the local GraphQL operations in a folder located at src/graphql that you can use to query the API Send a query in the frontend Example:\n1 2 3 4 5 6 7 8 9 async function deleteNote({ id }) { const newNotes = notes.filter((note) =\u0026gt; note.id !== id); setNotes(newNotes); // query await API.graphql({ query: deleteNoteMutation, variables: { input: { id } }, }); } Example: Using AWS Storage Services This example shows how to use Amazon S3 (AWS Simple Storage Service) to store image data.\nAdd the storage service 1 amplify add storage Modify the schema 1 2 3 4 5 6 7 // amplify/backend/api/notesapp/schema.graphql type Note @model @auth(rules: [{ allow: public }]) { id: ID! name: String! description: String image: String // update } Use storage in the app 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // Update imports import { API, Storage } from \u0026#39;aws-amplify\u0026#39;; import { Button, Flex, Heading, Image, Text, TextField, View, withAuthenticator, } from \u0026#39;@aws-amplify/ui-react\u0026#39;; // Update functions, e.g., createNote async function createNote(event) { event.preventDefault(); const form = new FormData(event.target); const image = form.get(\u0026#34;image\u0026#34;); const data = { name: form.get(\u0026#34;name\u0026#34;), description: form.get(\u0026#34;description\u0026#34;), image: image.name, }; // Put image into storage if (!!data.image) await Storage.put(data.name, image); await API.graphql({ query: createNoteMutation, variables: { input: data }, }); fetchNotes(); event.target.reset(); } Deploy the service 1 amplify push --y # --yes: Omit all command-line configuration options and set as default End ","permalink":"http://eimy.ink/en/posts/2023/aws-amplify/","summary":"playing with AWS","title":"Deploying an App via AWS Amplify"},{"content":"Note: The passage is originally written in Chinese and translated into English via ChatGPT.\nTranslated passage:\nAlias: Gitlet in Hindsight: Why I Suggest You Always Read the DON\u0026rsquo;Ts Part in Spec First\nAfter spending a few days catching up with the renowned project Gitlet, which has a weighty 60-page spec covering everything (lol), including informative content that provides a comprehensive understanding and training on every technical foundation, from system design to integration testing. It truly deserves the highest praise for this course project in its history.\n[Reference]: UCB CS61B-21SP-Gitlet\nProject Overview Gitlet is a version control system that mimics the functionality of the popular system Git and implements some of its basic commands, including init, add, commit, rm, checkout, branch, reset, rm-branch, merge, and more.\nAs an individual project for the course, it starts with only a few necessary .java classes and a few lines of code samples. The task requires designing and completing the system, object methods, data structures, and a few algorithms based on the requirements.\nGitlet Version-Control Mechanism In essence, version control in Git (Gitlet) revolves around the question of \u0026ldquo;how to save a certain version\u0026rdquo; and \u0026ldquo;how to switch to a specific version.\u0026rdquo; These two questions can be understood from three levels, from top to bottom: the user level, the object level, and the file read/write level.\nFrom a design perspective, there should exist an abstraction barrier between these three levels, as explained in the abstraction barrier concept. This means that when users issue commands, they don\u0026rsquo;t need to know or manipulate objects, pointers, etc., and file read/write operations should not occur between objects either.\nUser Level First, let\u0026rsquo;s discuss what happens at a higher level, which is the part that users are aware of.\nWhat does Git initialization do? It creates a hidden directory called .git in the current working directory (CWD) and some files inside it. How are file versions saved? When a commit is made, Git captures the current snapshot of the committed files and stores it in the .git directory. How to switch to a specific version? When using commands like checkout or reset to switch versions, Git looks for the corresponding snapshot based on the given branch name/commit ID in the .git directory. It then restores the specified file or the entire directory in the CWD to match that snapshot. Object Level Now let\u0026rsquo;s see how these steps are implemented at the object level. Gitlet simplifies the directory structure of Git to some extent, storing fewer metadata for each object, but the essence remains the same. The following diagram represents the structure of the .gitlet directory.\nGitlet version control utilizes two types of objects: Commit and Blob. Each Blob object corresponds to a file snapshot. Each Commit object corresponds to a commit. How are these objects used to track file versions? When a file is added to the staging area (add [file name]), a Blob object is created to store the current file content. The mapping between the file name and the corresponding Blob instance is then stored in the staging area. When committing files, a Commit object is created. It retrieves the mapping relationships from the staging area and saves them in the Commit object. In addition to the index mapping, each object also records the parent Commit, timestamp, commit message, etc. Example: In the diagram below, each blue square represents a Commit object. Inside each Commit object, there is a Map that records the file snapshots for the current commit. For instance, both Hello.txt in Commit 1 and Commit 2 point to Blob 0, indicating that the file content (snapshot) did not change in these two commits. How is switching to a specific version implemented? — By moving pointers To switch the HEAD pointer to another branch\u0026rsquo;s branchHeadCommit, at the object level, it means that the HEAD pointer, originally pointing to a Commit object on branchA, should now point to another Commit object branchHeadCommit on branchB. This can be achieved by something like updatePointerToCommit(HEAD, branchHeadCommit). File I/O Level Finally, let\u0026rsquo;s dive into the lower-level and examine file read/write operations. Since certain commands require storing Blob objects, Commit objects, and the current content of the staging area locally, two questions arise:\nHow are objects stored as data (to retrieve and use them later)?\nJava\u0026rsquo;s serialization is used to store objects. In Gitlet, all objects can be serialized and stored in files, including Blob, Commit, and StagingArea (if applicable). In the .git directory, they are stored in the /objects/ directory.\nOn the other hand, pointers are managed through file read/write operations (without serialization). Each pointer corresponds to a file that contains the ID of the object it points to. When modifying a pointer\u0026rsquo;s target, the actual change occurs in the file by updating the ID. In the .git directory, pointers are stored in the .git/refs/ directory.\n1 2 3 4 5 6 7 8 9 10 11 /* Serialize a Model object */ Model m = ....; // Assuming Model class implements Serializable File outFile = new File(saveFileName); // Create a new File try { ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(outFile)); out.writeObject(m); // Write the object to the stream out.close(); } catch (IOException excp) { ... } 1 2 3 4 5 6 7 8 9 10 11 12 /* Deserialize a Model object */ Model m; File inFile = new File(saveFileName); try { ObjectInputStream inp = new ObjectInputStream(new FileInputStream(inFile)); m = (Model) inp.readObject(); // Cast object into the expected class inp.close(); } catch (IOException | ClassNotFoundException excp) { ... m = null; } How to find and retrieve objects/modify pointer targets?\nGitlet, like Git, uses SHA-1 (Secure Hash Algorithm 1) to generate a 160-bit hash value as the unique ID (40 hexadecimal characters) for each object. When an object is created, its ID is generated based on its content. For example, identical file contents will produce the same ID after encryption. The filenames for the stored objects are their respective IDs. This means that the ID can be used to locate the serialized objects in the directory. Furthermore, this enables content-addressable lookup based on the object\u0026rsquo;s content. Regarding object retrieval, let\u0026rsquo;s take obtaining a Commit object as an example. The steps include: obtaining the commit ID (which should be a field of the object) -\u0026gt; obtaining the file path based on the ID (since they are stored in a specified directory) -\u0026gt; deserializing the file. Similarly, modifying the object involves updating its content and then serializing it back into the file. As for modifying pointer targets, at the file read/write level, the operation involves: obtaining the ID of the targetCommit -\u0026gt; writing the ID into the file corresponding to the HEAD pointer. (Reminder to self) It\u0026rsquo;s important to encapsulate these operations within the objects. The main logic should not contain statements like commitMap.put(readContentAsString(commitPath), readContentAsString(blobPath)). When reviewing others\u0026rsquo; implementations, if you come across such mixed file read/write operations at the object level, be cautious.\nIn Brief The above passages may seem repetitive, but they provide different perspectives on version control systems. Here\u0026rsquo;s a basic analogy:\nInitializing a version control system == Placing a small box in the current working directory. Saving file versions == Each time a commit is made, making a copy of the submitted files and storing them in the box. Switching the current directory or a file in the directory to a specific version == Finding the corresponding archive in the box and bringing it back to the current working directory (CWD). The other concepts, such as objects, pointers, encoding, etc., are methods used to optimize the copying process and speed up the retrieval of files from the box (at least that\u0026rsquo;s how I understand it):\nBlob object == Archive of a single file. Commit object == A note indicating which file versions to retrieve at a particular time. Commit tree == An outline of the notes (commits). SHA-1 encoding == Giving each file a name based on its content (useful for fast content comparison and addressing). Pointers == Labels indicating which version is currently in the box. Archiving files is a straightforward process that anyone can do (think: paper_final_final_final.docx). However, I believe the essence lies in SHA-1 encoding.\nReflection Notes taken while coding, might be messy.\nReading Order for the Spec The project specification for Gitlet is quite lengthy, making it impractical to read it all at once before starting. If I were to do it again, I would watch the videos first, skim through the command explanations and the \u0026ldquo;avoids\u0026rdquo; section, and then refer to the spec while coding. It\u0026rsquo;s important to pay close attention to the \u0026ldquo;Don\u0026rsquo;t\u0026rdquo; sections in the spec. The reason they are mentioned is that people tend to make those mistakes. For example, using a HashMap as the default Map implementation and encountering a Heisenbug. In reality, a TreeMap should be used to maintain order. ← Starts with \u0026ldquo;callback\u0026rdquo;. Regarding Design Initially, it\u0026rsquo;s crucial to read the entire spec comprehensively, understanding the roles of each object and their commonly used interaction methods. Once the design is clear, implementation can begin.\nPositive example: When implementing the \u0026lt;branch\u0026gt; command, a major directory overhaul was planned. However, due to a well-designed abstraction earlier, only a single line needed to be added to the File directory without any other changes.\nProtect the abstraction barrier. Interactions between higher-level objects should avoid using lower-level operations.\nNegative example: Initially, hashing and serialization were done directly in the main logic, leading to a lot of refactoring during the encapsulation process.\nNaming is crucial. After some painful lessons, the following points are summarized:\nUniformity: Just like joining database tables, if objects need to communicate, they must have some common names. A negative example would be what I did initially, using different names for the IDs obtained from sha-1 hashing, such as shaName, shaId, hashName, etc. Intuitiveness: Variable names should be as specific as possible. For example, \u0026ldquo;map\u0026rdquo; can be written as \u0026ldquo;keyToVal,\u0026rdquo; making it easier to understand. Generality: Methods should not be overly specific so that they can be easily recalled when used elsewhere. For example, instead of using \u0026ldquo;getHead\u0026rdquo; and \u0026ldquo;getMaster,\u0026rdquo; it is better to use \u0026ldquo;getCommit\u0026rdquo; and \u0026ldquo;getPointer.\u0026rdquo; Other Points It would be beneficial to read the source code of Git to find better practices, although the specification alone is generally sufficient. Stats Time and Space The code consists of approximately 1,000 lines. In terms of time, it took around 4.5 days to complete, with a recorded duration of around 40 hours according to Wakatime. Although I spent more than 10 hours debugging during that time (oops!). I remember Josh sharing some data in class, and most students took around 30-40 hours to complete the project.\nFrom a statistical standpoint, Gitlet is not a large-scale project. However, considering that it requires independent completion and involves design, unit and integration testing, makefile, Java file I/O, algorithms, encoding, and even training on Git itself, it is still a highly rewarding experience.\nAutograder Results All functional tests passed successfully. The Extra-Credit tests failed, as well as the style check (mainly due to naming, which I\u0026rsquo;ll improve next time). However, I believe those failures don\u0026rsquo;t significantly impact the overall outcome, so I didn\u0026rsquo;t continue the autograder-oriented programming.\nBTW, reasons for not implementing Extra-Credit features:\nTowards the end, many commands were combinations of previous commands, resulting in diminishing returns. The \u0026ldquo;remote\u0026rdquo; command in Gitlet differs greatly from Git and may not contribute much to understanding the underlying logic of Git. After encountering a Heisenbug, my energy was depleted. Despite not pursuing the Extra-Credit tasks, I still found the Gitlet project rewarding and a valuable learning experience.\nReflection Gitlet is an impressive project in the world of renowned universities. As I mentioned at the beginning, I firmly believe that most individuals with a similar level of proficiency can gain a lot from this project. Just take a glance at the spec, and you\u0026rsquo;ll understand.\nSpeaking from a technical standpoint, I\u0026rsquo;m not qualified to say much as I consider myself a novice. So, let me conclude with a few remarks. In one of Josh\u0026rsquo;s lectures, he shared the results of a Gitlet survey, and one particular detail stuck with me. Some students spent over 50 hours on this project (which, in my personal experience, far exceeds the workload of a typical course assignment in the freshman year). However, only a few individuals gave negative feedback in the end, and I recall Josh expressing his apologies for that. This indirectly reflects the worthwhileness of \u0026ldquo;The Gitlet Grind.\u0026rdquo;\nAn official end of CS61B \u0026ndash; so grateful for the open-source materials! Time to move on and continue working on something else.\nAppendix The following is an excerpt from the README I wrote, explaining the design aspects of my Gitlet implementation.\nDesign Abstraction Principle An issue with version control systems:\nRequires cumbersome operations like hashing, serialization, map operations, directory concatenation, file I/O, etc.\nSolution:\nOn a higher level, involve only communications between objects (between Blob and Commit, there should only be Blob b = commit1.get(filename)) Eliminate the need to dive into low-level operations through encapsulation. i.e. Outside the class of that object, never try to hash things, or modify maps inside Commit/Blob objects. E.g. The StagingArea supports common map operations. Upon put (fileName, Commit), it completes: read commit into commit id -\u0026gt; put into its map -\u0026gt; serialize itself and write into the file for staging. Persistence The directory structure looks like this:\n1 2 3 4 5 6 7 8 9 10 CWD └──.gitlet └── --commits/ # all commits ├──blobs/ # file content ├──branchHeads/ # branch heads | └──--master # master branch | ├──..\t# other branches ├──HEAD\t# HEAD commit ├──add # staging area for addition └──rm # staging area for removal The Main class is the entry class of the project. It is responsible for calling different functions according to given commands.\nThe Repository class will set up all persistance. It will\nCreate and initialize files and directories in the .gitlet folder if the directory does not exist; Handle all updates of HEAD , master, branchHeads and the serialization of two StagingAreas add and rm. Execute the commands / function calls from Main. The Commit class handles the serialization of Commit objects. It also deals with conversion between commit ids and commit objects. Each Commit records mappings of held file names and their corresponding file content. Specifically, it fulfil the following purposes:\nConstructs Commit objects; Serializes and saves Commit objects to the .gitlet/commits directory; Given a commit id, retrieves the corresponding Commit object. The Blob class handles the serialization of Blob objects. A blob is a snapshot of a file\u0026rsquo;s content at the moment of addition. For instance, a file named \u0026ldquo;hello.txt\u0026rdquo; can refer to different Blobs in different Commits.\nIts functions are similar to Commit, namely object construction, serialization and retrieval.\nThe StagingArea class stores files for addition and removal. A StagingArea works like a Java Map, stores mappings of file plain names to their blob ids, and supports basic map operations (remove, get, put). add and rm are StagingAreas for staged addition and removal respectively.\n","permalink":"http://eimy.ink/en/posts/2023/gitlet-fin/","summary":"♪(´ε｀ )","title":"Notes and Thoughts on CS61B Gitlet"},{"content":"Note: The passage is originally written in Chinese and translated into English via ChatGPT.\nB-Tree, LLRB Hug usually smoothly transitions and introduces new concepts, but the transitions written in the notes can be a bit verbose, so I will provide a concise version here.\nLimitations of BST First, let\u0026rsquo;s introduce two properties of BST: height and average depth. Height: Determines the worst-case runtime to find a node. Average depth: Determines the average-case runtime to find a node. Now let\u0026rsquo;s look at various properties of BSTs. Worst case: $\\Theta(N)$ height Best case: $\\Theta(\\log N)$ height Random trees have $\\Theta(\\log N)$ average depth and height (bushy). Random trees perform well, but the problem arises when we keep inserting data from the right side, leading to imbalance, such as: add(\u0026ldquo;01-Jan-2019, 10:31:00\u0026rdquo;) add(\u0026ldquo;01-Jan-2019, 18:51:00\u0026rdquo;) B-Trees / 2-3 trees / 2-3-4 trees To address the issue of imbalance, we keep inserting new keys into existing nodes and perform node splitting. This gives rise to a new type of tree called B-trees.\nB-trees should be called juicy trees.\nDefinition B-trees are self-balancing trees and can be classified into different types: B-trees of order L=3 (like the ones used today) are also called a 2-3-4 tree or a 2-4 tree (as shown in the figure). B-trees of order L=2 are also called a 2-3 tree (as shown in the figure). B-trees of larger L are used in practice for databases, etc. Construction Mechanism (node-split)\nInsert into a leaf until the number of keys exceeds L. In case of excessive keys, send the second (1st) node up and split the node. Examples:\n【No cascading reaction】 【Involves cascading reaction】 【Involves root split】 Properties (or Invariants)\nBased on the construction mechanism mentioned above, we can derive some properties of B-trees. B-trees are balanced in that:\nAll leaves must be the same distance from the source. Consider: When a root split occurs, the height increases by 1, and all nodes descend one level. If there is no root split, the height remains the same. A non-leaf node with k items must have exactly k+1 children. Runtime Analysis Height: $\\Theta(\\log N)$ for both worst-case and best-case scenarios. In the best case, each node has L items (full), so the height grows with $\\Theta(\\log_{L+1}N)$. In the worst case, each node has only 1 item, so the height grows with $\\Theta(\\log_2N)$, the same as a BST. Operation runtime: Both contains() and add() have a complexity of $O(\\log N)$. Worst case for contains(): $C = (\\text{number of layers}) \\log_{L+1}{N} \\cdot (\\text{nodes per layer}) 1 \\cdot (\\text{work per node}) L$ Worst case for add(): It involves some split operations, but the simplified complexity remains the same. Limitations of B-Trees Can you guess why the code implementation is not included above?\nLeft Leaning Red-Black Trees Definition A BST with left glue links that represents a 2-3 tree is often called a \u0026ldquo;Left Leaning Red Black Binary Search Tree\u0026rdquo; or LLRB.\nIn other words, LLRB is a BST that corresponds to a specific B-Tree. Some remarks about LLRB trees:\nLLRBs are normal BSTs! There is a one-to-one correspondence between an LLRB and an equivalent 2-3 tree. The red color is just a convenient representation. Red links don\u0026rsquo;t have any special functionality. Properties Similar to BSTs, LLRB trees have the following properties:\nAll leaves must be the same distance from the source (counting only black links). No node has two red links. Construction Mechanism In principle, LLRB trees are based on 2-3 trees, where the smaller item in a node is moved down. For example: However, it is not practical to implement a 2-3 tree and then convert it to an LLRB tree. In the code , LLRB trees are implemented directly using red links, rotation, and color flipping:\nAlways use a red link when inserting (analogous to adding items to a node in a 2-3 tree).\nWhen inserting items on the right, use rotateLeft().\nWhen inserting items on the left twice, use rotateRight().\nA new rule allows representing temporary 4-nodes as BST nodes with two red links.\nIn case of temporary 4-nodes, use flipColors().\nIf a rotation or color flip operation causes an additional violation, fix it.\nCode Implementation The following code includes the implementation of these methods, including the modified Node class, put(), the newly added rotate methods, flipColors(), and isRed().\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 // LLRB insertion (p.439) public class RedBlackBST\u0026lt;Key extends Comparable\u0026lt;Key\u0026gt;, Value\u0026gt; { private Node root; private class Node // BST node with color bit (see page 433) private boolean isRed(Node h) // See page 433. private Node rotateLeft(Node h) // See page 434. private Node rotateRight(Node h) // See page 434. private void flipColors(Node h) // See page 436. private int size() // See page 398. public void put(Key key, Value val) { // Search for key. Update value if found; grow table if new. root = put(root, key, val); root.color = BLACK; } private Node put(Node h, Key key, Value val) { if (h == null) { // Do standard insert, with red link to parent. return new Node(key, val, 1, RED); } int cmp = key.compareTo(h.key); if (cmp \u0026lt; 0) { h.left = put(h.left, key, val); } else if (cmp \u0026gt; 0) { h.right = put(h.right, key, val); } else { h.val = val; } if (isRed(h.right) \u0026amp;\u0026amp; !isRed(h.left)) { // 基于BST只需要修改这里三个clause h = rotateLeft(h); } if (isRed(h.left) \u0026amp;\u0026amp; isRed(h.left.left)) { h = rotateRight(h); } if (isRed(h.left) \u0026amp;\u0026amp; isRed(h.right)) { flipColors(h); h.N = size(h.left) + size(h.right) + 1; return h; } } // some omitted methods within RedBlackBST Class private boolean isRed(Node x) { if (x == null) return false; return x.color == RED; } private Node rotateLeft(Node h) { // rotateRight() is similar Node x = h.right; h.right = x.left; x.left = h; x.color = h.color; h.color = RED; x.N = h.N; h.N = 1 + size(h.left) + size(h.right); return x; } private void flipColors(Node h) { h.color = RED; h.left.color = BLACK; h.right.color = BLACK; } } // delete比较麻烦，详细见p.441. Runtime Analysis Height: $O(logN)$ contains(): $O(logN)$ insert(): $O(logN)$ $O(logN)$ to add the new node $O(logN)$ for rotation and color flip operations per insert （After simplification and ignoring constant terms, the time complexity remains O(log N).） Summary of search trees 逻辑梳理 Cited from the slides [lec 18, 19sp]\nBinary search trees** are simple, but they are subject to imbalance.\n2-3 Trees (B Trees) are balanced, but painful to implement and relatively slow.\nLLRBs insertion is simple to implement (but delete is hard).\nWorks by maintaining mathematical bijection with a 2-3 trees. Java’s TreeMap is a red-black tree (not left leaning).\nMaintains correspondence with 2-3-4 tree (is not a 1-1 correspondence).\nAllows glue links on either side (see Red-Black Tree).\nMore complex implementation, but significantly (?) faster.\nComplexity/runtime对比 WC = worst case\nBST B-Trees LLRB Height $O(logN)$ $\\Theta(logN)$ $O(logN)$ WC：$O(N)$ WC：$O(log N)$ WC：$O(log N)$ contains() $O(logN)$ $O(log N)$ $O(logN)$ WC：$O(N)$ WC：$O(log N)$ WC：$O(log N)$ insert() $O(logN)$ $O(log N)$ $O(logN)$ WC：$O(N)$ WC：$O(log N)$ WC：$O(log N)$ Explanation: B-trees and LLRB trees are self-balanced, which prevents the extreme case of a BST degenerating into a linked list. This property makes them faster compared to regular BSTs. In summary:\nB-trees achieve self-balancing to avoid the worst-case complexity of regular BSTs. LLRB trees not only inherit the self-balancing property of B-trees but also retain the ease of implementation characteristic of regular BSTs. ","permalink":"http://eimy.ink/en/posts/2023/b-tree-llrb/","summary":"B-tree, rotation and red-black trees","title":"61B Notes - B-Trees \u0026 LLRB"},{"content":"Note: The passage is originally written in Chinese and translated into English via ChatGPT.\nReference: Lecture slides from 19sp.\nTrees First, the concept of abstract data type (ADT) is introduced, followed by a progressive/step-by-step optimization-based introduction to three types of trees (BST, B-Tree, LLRB).\nThe notes are divided into two parts, and this article only covers ADT and BST.\nAbstract Data Types (ADT) An abstract data type is defined by its operations, not implementations. Hierarchy Examples ADT Deque; DisjointSets Implementations of ADT ArrayDeque, LinkedListDeque;\nQuickFindDS, WeightedQuickUnionDS Operations of ADT size(), get(), addFirst(Item x), etc. Among the most important interfaces in the java.util library are those that extend the Collection interface. The relationship is shown in the figure. List Set Map The focus this time is on two tree-related data types, TreeSet and TreeMap. Binary Search Tree Origins of BST Question: How can we improve a linked list to perform searches more efficiently?\nThe answer is: 1) Set the entry point in the middle instead of one end. 2) Traverse from the middle to both ends. 3) Traverse in a skipping manner (as shown in the figure).\nDefinition and Properties of BST A binary search tree is a rooted binary tree with the BST property. Tree properties: A set of nodes One path between any two nodes Rooted tree properties: Each node, except the root, has only one parent node. The root is typically drawn at the top. For binary trees, each node can have 0/1/2 child nodes. BST properties: Ordering: Every key in the left subtree is less than X\u0026rsquo;s key. Every key in the right subtree is greater than X\u0026rsquo;s key. No duplicate keys are allowed. (Encountering a BST)\nBST Operations Three operations of BST are introduced.\nSearch / Find Code Implementation (It\u0026rsquo;s easier to understand through the code.) Compare searchKey with T.key \u0026ndash;\u0026gt; Found! / searchKey is smaller, search T.left / searchKey is larger, search T.right.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // reference: Algorithms, p.399 /** Return value associated with key in the subtree rooted at x; * return null if key not present in subtree rooted at x. */ public Value get(Key key) { return get(root, key); } private Value get(Node x, Key key) { // helper if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp \u0026lt; 0) { return get(x.left, key); } else if (cmp \u0026gt; 0) { return get(x.right, key); } else { return x.val; } } Runtime Analysis Worst-case runtime: $\\Theta(\\log{N})$ for a dense binary tree. Tree height: ~$\\log_2{(N)}$ Consider the fact that each additional level requires twice the number of nodes. Insert Code Implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** Search for key. Update value if found; grow table if new. */ public void put(Key key, Value val) { root = put(root, key, val); } /** Change key\u0026#39;s value to val if key in subtree rooted at x. * Otherwise, add a new node to the subtree associating key with val. */ private Node put(Node x, Key key, Value val) { if (x == null) return new Node(key, val, 1); int cmp = key.compareTo(x.key); // compare searchKey to curKey if (cmp \u0026lt; 0) { x.left = put(x.left, key, val); } else if (cmp \u0026gt; 0) { x.right = put(x.right, key, val); } else { x.val = val; } x.N = size(x.left) + size(x.right) + 1; return x; } Runtime Analysis for Insertion It should be the same as the search operation.\nDelete There are three cases for deletion:\nThe key to be deleted has no child nodes (\u0026ndash;\u0026gt; see \u0026ldquo;glut,\u0026rdquo; simply disconnect). The key to be deleted has one child node (\u0026ndash;\u0026gt; see \u0026ldquo;flat,\u0026rdquo; update the parent node\u0026rsquo;s pointer to the child node). The key to be deleted has two child nodes (as shown in the figure, find the predecessor or successor to replace its position). Code Implementation (p.411) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 private Node min(Node x) { // Find the smallest node and its child nodes under x if (x.left == null) return x; return min(x.left); } public void deleteMin() { // Return the root after deleting the smallest node root = deleteMin(root); } private Node deleteMin(Node x) { // DeleteMin helper if (x.left == null) return x.right; x.left = deleteMin(x.left); x.N = size(x.left) + size(x.right) + 1; return x; } public void delete(Key key) { root = delete(root, key); } private Node delete(Node x, Key key) { if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp \u0026lt; 0) { x.left = delete(x.left, key); } else if (cmp \u0026gt; 0) { x.right = delete(x.right, key); } else { // Assume the node P to be deleted has been found if (x.right == null) return x.left; // Check if P has sub-nodes, A) if it has 0/1 sub-nodes, return it if (x.left == null) return x.right; Node t = x; // B) if it has 2 nodes, the tree needs to be adjusted x = min(t.right); // 1. Find the new substitute for the deleted node P x.right = deleteMin(t.right); // 2. Connect the updated right nodes to the new P x.left = t.left; // 3. Connect the original left sub-nodes to the new P // Note the order matters here! } x .N = size(x.left) + size(x.right) + 1; return x; } Runtime Analysis It should be of the same order as the previous operations since it only involves additional modification steps.\nBSTSet v.s. BSTMap This part introduces Lab9 BSTmap.\nBSTSet and BSTMap have the same structure (a tree), but the difference is that each node is represented using a map (as shown in the figure).\n","permalink":"http://eimy.ink/en/posts/2023/bst/","summary":"ヽ(´o｀；","title":"61B Notes - ADT and BST"},{"content":"Useful techniques to get $\\Theta (f(N))$ Relevant pages in 61B Textbook\nThis is just a condensed(?) version of the textbook.\nEx 1: A For Loop 1 2 3 4 5 6 int N = A.length; for (int i = 0; i \u0026lt; N; i += 1) for (int j = i + 1; j \u0026lt; N; j += 1) if (A[i] == A[j]) return true; return false; Method 1: Count Number of Operations (exact count) The total cost/operations of \u0026ldquo;==\u0026rdquo; amounts to: $$ C(N)=1+2+3+\\dots+(N-2)+(N-1) = N(N-1)/2 $$ Therefore, the runtime would be $\\Theta (N^2)$.\nMethod 2: Geometric Visualization (Imagine the colored blocks - since it\u0026rsquo;s a triangular area - the runtime is $\\Theta (N^2)$.)\nEx 2: Another For Loop 1 2 3 4 5 6 7 8 public static void printParty(int N) { for (int i = 1; i \u0026lt;= N; i = i * 2) { for (int j = 0; j \u0026lt; i; j += 1) { System.out.println(\u0026#34;hello\u0026#34;); int ZUG = 1 + 1; } } } Method 1: Finding the Bound Visually Graph the trajectory of 0.5 N (lower dashed line), and 4N (upper dashed line)\nAnd the C(N) would be between these two lines\nTherefore, the runtime is $\\Theta (N)$.\n(Personally I think it\u0026rsquo;s not as straighforward as the mathematical method)\nMethod 2: Finding the Bound Mathematically Imagine the boxes:\nApproach2-simpler geometric argument So C(N) would be: $$ C(N)=1+2+4+\\dots+N= 2N-1 $$ Therefore, the runtime is $\\Theta (N)$.\nEx 3: Tree Recursion 1 2 3 4 5 public static int f3(int n) { if (n \u0026lt;= 1) return 1; return f3(n-1) + f3(n-1); } Method 1: Intuition Every time we add one to n we double the amount of work that has to be done\n\u0026hellip; which results in the intuitive answer for runtime to be $2^N$.\ntree recursion Method 2: Algebra $C(N)$ amounts to: $$ C(N) = 1+2+4+\\dots+2^\\left(N-1\\right)=2^N-1 $$ So the runtime is $\\Theta (2^N)$.\nMethod 3: Recurrence Relation (Out of Scope) Starting from this: $$ C(N)=2C(N-1)+1 $$\nEx 4: Binary Search binary search Method 1: intuition We start with N options, then N/2, then N/4 \u0026hellip; until we have just 1.\nEach time, we cut the array in half, so in the end we must perform a total of $\\log_{2}(N)$operations\u0026hellip;\nSo the overall runtime then is order\nMethod 2: exact count binary search So $C(N)=floor(log_{2}(N))+1$ (based on observation).\nAnd the runtime is $\\Theta(log(N))$.\nEx 5: Mergesort arbitrary units of time: relative sense of the time needed e.g. If we run an N=6 selection sort, and the runtime is of order $N^2$, it will take ~36 AU to run.\nAbout Mergesort \u0026ndash; a simple case (merge two lists into one) mergesort Its runtime is $\\Theta (N)$.\nMergesort \u0026ndash; applying mergesort to sort a long list mergesort The key idea is to split the original array into smallest pieces and apply mergesort (whose runtime is $\\Theta (N)$).\nSo Mergesort has worst case runtime $\\Theta (N * log(N))$, where\nThe top level takes ~N AU.\nNext level takes ~N/2 + ~N/2 = ~N.\nOne more level down: ~N/4 + ~N/4 + ~N/4 + ~N/4 = ~N.\nSummary There is no magic. Just count. A more standardized method is shown in andwelcome() in disc07: Step 1: Calculate the tree height (number of layers), e.g., for a binary tree, it is $logN$. Step 2: Calculate the branching factor (nodes per layer), e.g., for a binary tree, it is $2^N$. Step 3: Calculate the operations per node, e.g., for a binary tree, it is $N/2^i$. Finally, multiply the results together: $\\sum_{i=0}^{logN} \\cdot 2^i \\cdot (\\frac{N}{2^i}) = N\\log{N}$. ","permalink":"http://eimy.ink/en/posts/2023/asymptotics2-notes/","summary":"copied from the textbook","title":"61B Notes - Asymptotics II"},{"content":"Note: The passage is originally written in Chinese and translated into English via ChatGPT.\nAsymptotics This is a mixed Chinese-English lecture notes for the algorithms section of CS61B. It outlines the main topics covered in the lecture.\nGeneral Goal This section introduces the core question of \u0026ldquo;how to measure algorithm efficiency.\u0026rdquo;\nEfficiency comes in two ways:\nProgramming cost \u0026lt;\u0026ndash; The focus in the first half of 61B Execution cost \u0026lt;\u0026ndash; The current focus Time cost Memory cost The question is raised: How to measure code efficiency?\nTherefore, the goal of this lecture is to introduce formal standards for measuring algorithm efficiency.\nIntuitive Runtime Characterizations This section provides several intuitive methods to measure program efficiency.\nComparing execution time The advantage is its intuitiveness, but it is unreliable due to multiple influencing factors. Counting the total number of operations (using real numbers/abstract N) The advantage is that it reveals the growth scale (how it scales), but it can be cumbersome to calculate. Screenshot Asymptotic Analysis This section first introduces the extent to which algorithm efficiency is influenced by the order of growth, and then presents methods to simplify asymptotic analysis.\nThe influence of Order of Growth\nThe basic principle is to focus only on the asymptotic behavior when analyzing efficiency (i.e., how it behaves as N tends to infinity).\nBased on this principle, one can observe the function shape when comparing functions at N tends to infinity.\nThis function shape is temporarily referred to as the order of growth, such as line, cubic, quadratic, etc.\nIn other words, we can measure algorithm efficiency based on the order of growth.\nHowever, the current method of analyzing growth (symbolic count) is not simple enough and lacks mathematical rigor. Therefore, it needs to be simplified:\nOnly consider the worst-case count. Choose a representative operation for counting. Consider only the term that has the greatest impact on the order, e.g.: n^3~~+n^2+1~~. Ignore coefficients. Simplification/1 At this point, the analysis involves 1) computing a complete table, 2) selecting a representative count, and 3) simplification. These steps can be further simplified:\nOne way is to directly analyze the code and choose a specific operator for counting. Approach 1 - Based on exact count A simpler approach is geometric analysis (assuming the side length is $N-1$, resulting in $N^2$). Approach 2 - Simpler geometric argument Asymptotic Notation Finally, the commonly used notations for asymptotic analysis, Big Theta (i.e., Order of Growth) and Big O, are introduced.\nBig Theta Big Theta is used to describe the rate of growth in the running time of a program.\nNotation Assume there is a runtime function $R(n)$, and if the order of growth (function shape) of $R(n)$ is $f(N)$,\nit is denoted as: $$ R(n) \\in \\Theta (f(N)) $$\nDefinition $$ R(n) \\in \\Theta (f(N)) $$\nmeans that there exist positive constants $k_1$ and $k_2$ such that $$ k_1 · f(n) \\leq R(N) \\leq k_2 · f(N) $$ for all $N\u0026gt;N_0$ (i.e., very large N).\nExample Big Theta Demo - Big O Big Theta describes an \u0026ldquo;equal\u0026rdquo; relationship (the growth rate of a function is equal to xx), while Big O describes a \u0026ldquo;less than or equal to\u0026rdquo; relationship.\nDefinition (Note: it can be observed that it removes the lower bound compared to $\\Theta$) $$ R(n) \\in \\Theta (f(N)) $$\nmeans that there exists a positive constant $k_2$ such that $$ R(N) \\leq k_2 · f(N) $$ for all $N\u0026gt;N_0$ (i.e., very large N).\nExample: $$ N^3+3N^4 \\in \\Theta(N^4) $$\n$$ N^3+3N^4 \\in O(N^6) $$\nBig O vs Big Theta Informal Meaning Family Family Members Big Theta $$\\Theta(f(N))$$ Order of Growth is $f(N)$ $\\Theta(f(N^2))$ $N^2/2$\n$2N^2$\n$N^2+38N$ Big O$$O(f(N))$$ Order of Growth is less than or equal to $f(N)$ $O(f(N^2))$ $N^2/2$\n$2N^2$\n$lg(N)$ ","permalink":"http://eimy.ink/en/posts/2023/asymptotics-notes/","summary":"halfway through 61b!","title":"61B Notes - Asymptotics"},{"content":"For certain reasons i decided to move my blogs from hexo-matery to hugo-papermod.\n","permalink":"http://eimy.ink/en/posts/move/","summary":"moving from hexo-matery to hugo-papermod","title":"Move"},{"content":" Since there\u0026rsquo;s already a brief self-intro on the homepage, I\u0026rsquo;m assuming that anyone who clicks here wants to know more.\nAbout the Site My personal blog, inspired by friends who believe I’m too mysterious.\nContains my notes about technologies or courses (50%) and my thoughts (50%). I’d like it to be more than a mere professional portfolio.\nAbout Me (in life) Background Currently a Computer Science grad student | Former Linguistics major\nThis is what I\u0026rsquo;ve been longing to do after high school, and there have been a few twists and turns. I do have a great passion for what I’m onto right now and feel really fortunate about my choices.\nLanguages Mandarin (native) \u0026gt; English (enough for getting fries on the pier) \u0026gt; Japanese (JLPT N1) \u0026gt; Shanghainese \u0026gt; French (kindergarten level)\nIt was partly my interest in learning natural languages that led me to pursue a language major and to specialize in computational linguistics.\nIt only occurred to me later that 1) language majors do not simply learn languages, 2) what attracts me more are things beyond the symbols, and 3) the coding part is so much fun\nBooks/Music i read mostly nonfictions in recent years (psychology, philosophy, sociology, economics) jpop, jrock, math rock, midwest emo Misc. An amateur illustrator good at (installing) sai2, procreate and photoshop An amateur vocaloid engineer/acoustic\u0026amp;electric guitar beginner A keen reader of personality psychology/psycho-analysis Watch anime everyday, literally Aspire to be a lifelong learner Last updated: 2024\n","permalink":"http://eimy.ink/en/about/","summary":"about","title":"About"}]