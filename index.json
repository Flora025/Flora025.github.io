[{"content":"A summary of what i learned in CS61C (fa20).\nMy course repo on GitHub: github/cs61c\nSummary of the Course Centered on several great ideas in computer architecture. Specifically,\nThe first half of the course teaches what\u0026rsquo;s called \u0026ldquo;the old school machine structures\u0026rdquo;.\nHigh level language program - C [lec3-6]\nAssembly language program - RISC-V [lec7-13]\nMachine Language - still RISC-V, but without pseudo instructions [lec7-13]\nHardware architecture description - block diagrams, datapaths, cache, pipelining, virtual mem, etc. [lec17-27]\nLogic circuit description [lec14-16]\nBasically, that\u0026rsquo;s everything from the top \u0026ndash; the programmer-friendly high level language C\u0026ndash;, to the bottom arch \u0026ndash; circuits, logic gates, and transistors\u0026ndash;.\nIn terms of actual sequence, it\u0026rsquo;s like top -\u0026gt; middle, then bottom -\u0026gt; middle, and finally the two lines meet at around project3 (DIY a CPU datapath).\nThe second half teaches the new-school structures, which include more recent ideas of parallelism / high performance programming that companies hardware improvements.\ndata-level parallelism - SIMD [lec32], MapReduce, Spark, etc. [lec36]\nthread-level parallelism - threads, cache coherency, OpenMP, etc. [lec33-35]\ndependability [lec38]\nSummary of the Labs Not including ones I didn\u0026rsquo;t manage to set up.\nLab1 Number Rep, C and CGDB: familiarize you with c and debugging tools Lab2 Advanced C: bit manipulations, memory allocation, and pointers in C Lab3 RISCV Assembly: ask u to figure out how simple C programs work on a lower level and write RISC-V assembly code Lab4 RISCV Functions, Pointers: still RISC-V practices, asking you to modify code to make the program work Lab5 Logisim: ~ build logic gates and practise with combinational logic Lab7 Caches: back to RISC-V, implement and optimize matrix-related functions to understand how cache works. This lab is valuable as it touches on one way to squeeze out performance. Lab8 OS, I/O, DMA, Disks, Networking \u0026amp; Virtual Memory: ~ play with a virtual memory simulator to understand how it works Lab9 SIMD Instructions: ~ work on single instruction multiple data (SIMD) \u0026ndash; write C functions and improve their performance with x86 intrinsics. It\u0026rsquo;s like inserting assembly code into C code. (Note that ARM users unfortunately would have to use ARM NEON intrin to be able to compile the programs.) Lab10 Thread Level Parallelism: have you experience parallel programing with C + OpenMP. Ask you to apply parallelism to the implementation of sum vector and dot product C funcs. Progress Planned to complete the course within 30 study days, and achieved the goal!\n【0611】setup, lab00 【0615】lec1\u0026amp;2 【0616】lec3 【0617】lec4 【0625】lec5, lab01 【0626】lec6 【0627】proj1A 【0702/03】proj1 Fin 【0704】K\u0026amp;Rch1-2 【0705】lec7+8.1, lab2 【0706】disc2 【0715】lec8-10 【0716】lab3 【0719】disc3, disc4 【0724】proj2 partA 50% 【0725】proj2 partA fin 【0801】lec11-13 【0802】disc5, lab4, lec14-15 【0803】lecs16+SDS State Logic handouts, lec17 【0804】lab5, lec 18-19 【0805】lec20-27 (fin CPU Pipelining Caches), disc6-8 【0806】disc9, lab7, lec28-2931 (fin OS VMi) 【0807】lec30-31(VMii I/O), disc10, lab8, disc11 【0808】lec32-35 (SIMD/MIMD, Parallelism), lec36-38 (MapReduce, WSC, RAID) 【0809】disc12, lab9, lab10, disc13-14 【skipped due to compatibility probs】proj4, proj3, lab6, lab11 Postscript should\u0026rsquo;ve been preparing for the incoming semester, projects and stuff but couldn\u0026rsquo;t resist the temptation of learning how computer works :\u0026gt;\n","permalink":"http://eimy.ink/posts/2023/cs61c/","summary":"Interesting","title":"CS61C Completed"},{"content":"Note: This passage is written in Chinese and translated into English via ChatGPT.\nI found a project tutorial for AWS Amplify on the AWS official website. It seems that it has not been translated into Chinese yet, so I took some notes while exploring it.\nIntroduction to AWS Amplify Amplify is a comprehensive platform that provides static resource hosting for:\nCreating AWS backends with features like authentication, data storage, and more for web, iOS, or Android applications in minutes. Building frontend UI intuitively from design to code with Figma integration and connecting it to the backend with just a few clicks. In summary, apart from a few distinctive features, it is quite similar to services like Netlify and also offers a certain amount of free usage:\nAWS Amplify Features: Supports visual development of full-stack websites or applications. Supports deploying mobile applications, which Netlify does not. Comprehensive ecosystem, making it convenient to use other AWS services. Getting Started with Amplify The main goal is to host a web page and deploy a backend, and additionally, there are examples of adding AWS authentication and storage services as supplementary features.\nNote: The following steps only show the configuration and deployment process related to Amplify. The complete code of the app is not provided here. Please refer to the original article for the specific app code.\nPrerequisites Create a frontend application or use an existing one. Push it to a GitHub repository. Deploying the Frontend Register for an AWS account (requires a credit card that can be charged $1). Log in and find the AWS Management Console. Go to the \u0026ldquo;Get started\u0026rdquo; page and click \u0026ldquo;Get started\u0026rdquo; under the \u0026ldquo;Host your web app\u0026rdquo; section. Choose GitHub as the deployment option, confirm the repository and branch information, and click \u0026ldquo;Next\u0026rdquo; multiple times. Click \u0026ldquo;Save and deploy\u0026rdquo; to complete the process. Afterward, any modifications and pushes to the repository will automatically update the website. Completion Page Installing Amplify CLI - Adding/Managing AWS Services Installing the CLI Amplify CLI allows you to add AWS services to your project.\n1 2 # Install CLI npm install -g @aws-amplify/cli Note: Compatibility issue on ARM Macs\nIf you encounter issues on M1/M2 Macs, where the CLI installs successfully but commands don\u0026rsquo;t respond, you can try one of the following solutions. Refer to issue #10193 for more information:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Solution 1: Install Rosetta (may or may not work) softwareupdate --install-rosetta # Solution 2: Clone an older version of the CLI (@danrivett) (may or may not work) # Environment: amplify-cli@v10.4.1 node@16 git clone https://github.com/aws-amplify/amplify-cli.git cd amplify-cli git checkout v10.4.1 # Avoids building the dev branch but builds a release tag; update as necessary yarn \u0026amp;\u0026amp; yarn build rm ~/.amplify/bin/amplify ln -s $(pwd)/packages/amplify-cli/bin/amplify ~/.amplify/bin/amplify # Solution 3: Manually download and install an older version from the releases page (@kzetxa) # Environment: node@16.12.0, Amplify 10.3.1, macOS Monterey 12.6 # 1. Delete the binary at /usr/local/bin/amplify # 2. Rename the binary inside the downloaded package # 3. Move it to the location where the old deleted binary was sudo chown -R $(whoami) ~/.amplify I have successfully used the third solution, with the same environment as mentioned. It seems that it involves a translation from x86.\nConfiguring the CLI 1 2 3 4 5 6 7 8 # Configure the CLI amplify configure # 1. You will be redirected to the web console for login. # 2. Select your region. # 3. Return to the web console to create a new user. # The user needs programmatic access. # Record the access key ID and secret access key. You will need the CLI for adding various services. Additionally, you can now use the following command to directly access the console:\n1 2 # In the local terminal amplify console Deploying the Backend Launching Amplify Studio Go back to the application page - backend environments - get started - launch studio - and run the local setup command in the terminal (copy from the web page).\nThen choose the configuration options:\n1 2 3 4 5 6 7 8 ? Choose your default editor: Visual Studio Code ? Choose the type of app that you\u0026#39;re building: JavaScript ? What javascript framework are you using: React ? Source Directory Path: src ? Distribution Directory Path: build ? Build Command: npm run-script build ? Start Command: npm run-script start ? Do you plan on modifying this backend? Y Adding Backend Build Configuration 1 2 3 4 5 6 7 8 9 10 11 # App settings \u0026gt; Build settings # Add backend configuration ... backend: phases: build: commands: - \u0026#39;# Execute Amplify CLI with the helper script\u0026#39; - amplifyPush --simple frontend: ... Example: Adding AWS Authentication This example demonstrates how to add AWS authentication to a note-taking application.\nAdding Authentication via the Command Line 1 2 3 4 5 # In the local terminal # Create the authentication service locally amplify add auth # Deploy it amplify push --y Using the Auth Service in src/index.js Import the configuration and add the following code to your src/index.js file:\n1 2 3 4 // in `src/index.js` import { Amplify } from \u0026#39;aws-amplify\u0026#39;; import config from \u0026#39;./aws-exports\u0026#39;; Amplify.configure(config); Importing Authentication into src/App.js Import similar to the following (a sample with only authentication):\n1 2 3 4 5 6 7 8 9 10 import \u0026#34;@aws-amplify/ui-react/styles.css\u0026#34;; import { withAuthenticator } from \u0026#34;@aws-amplify/ui-react\u0026#34;; function App({ signOut }) { return ( /* Middle part omitted */ ); } export default withAuthenticator(App); Finally, push the changes to the remote repository.\nAdding a Backend Database Add a GraphQL API 1 2 amplify add api # Choose GraphQL Local configuration Create a schema in /amplify/backend/api/\u0026lt;api_name\u0026gt;/schema.graphql. For example:\n1 2 3 4 5 type Note @model @auth(rules: [{ allow: public }]) { id: ID! name: String! description: String } Deploy the service 1 amplify push --y # --yes: Omit all command-line configuration options and set as default This will do three things:\nCreate the AWS AppSync API Create a DynamoDB table Create the local GraphQL operations in a folder located at src/graphql that you can use to query the API Send a query in the frontend Example:\n1 2 3 4 5 6 7 8 9 async function deleteNote({ id }) { const newNotes = notes.filter((note) =\u0026gt; note.id !== id); setNotes(newNotes); // query await API.graphql({ query: deleteNoteMutation, variables: { input: { id } }, }); } Example: Using AWS Storage Services This example shows how to use Amazon S3 (AWS Simple Storage Service) to store image data.\nAdd the storage service 1 amplify add storage Modify the schema 1 2 3 4 5 6 7 // amplify/backend/api/notesapp/schema.graphql type Note @model @auth(rules: [{ allow: public }]) { id: ID! name: String! description: String image: String // update } Use storage in the app 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // Update imports import { API, Storage } from \u0026#39;aws-amplify\u0026#39;; import { Button, Flex, Heading, Image, Text, TextField, View, withAuthenticator, } from \u0026#39;@aws-amplify/ui-react\u0026#39;; // Update functions, e.g., createNote async function createNote(event) { event.preventDefault(); const form = new FormData(event.target); const image = form.get(\u0026#34;image\u0026#34;); const data = { name: form.get(\u0026#34;name\u0026#34;), description: form.get(\u0026#34;description\u0026#34;), image: image.name, }; // Put image into storage if (!!data.image) await Storage.put(data.name, image); await API.graphql({ query: createNoteMutation, variables: { input: data }, }); fetchNotes(); event.target.reset(); } Deploy the service 1 amplify push --y # --yes: Omit all command-line configuration options and set as default End ","permalink":"http://eimy.ink/posts/2023/aws-amplify/","summary":"playing with AWS","title":"Deploying an App via AWS Amplify"},{"content":"Note: The passage is originally written in Chinese and translated into English via ChatGPT.\nTranslated passage:\nAlias: Gitlet in Hindsight: Why I Suggest You Always Read the DON\u0026rsquo;Ts Part in Spec First\nAfter spending a few days catching up with the renowned project Gitlet, which has a weighty 60-page spec covering everything (lol), including informative content that provides a comprehensive understanding and training on every technical foundation, from system design to integration testing. It truly deserves the highest praise for this course project in its history.\n[Reference]: UCB CS61B-21SP-Gitlet\nProject Overview Gitlet is a version control system that mimics the functionality of the popular system Git and implements some of its basic commands, including init, add, commit, rm, checkout, branch, reset, rm-branch, merge, and more.\nAs an individual project for the course, it starts with only a few necessary .java classes and a few lines of code samples. The task requires designing and completing the system, object methods, data structures, and a few algorithms based on the requirements.\nGitlet Version-Control Mechanism In essence, version control in Git (Gitlet) revolves around the question of \u0026ldquo;how to save a certain version\u0026rdquo; and \u0026ldquo;how to switch to a specific version.\u0026rdquo; These two questions can be understood from three levels, from top to bottom: the user level, the object level, and the file read/write level.\nFrom a design perspective, there should exist an abstraction barrier between these three levels, as explained in the abstraction barrier concept. This means that when users issue commands, they don\u0026rsquo;t need to know or manipulate objects, pointers, etc., and file read/write operations should not occur between objects either.\nUser Level First, let\u0026rsquo;s discuss what happens at a higher level, which is the part that users are aware of.\nWhat does Git initialization do? It creates a hidden directory called .git in the current working directory (CWD) and some files inside it. How are file versions saved? When a commit is made, Git captures the current snapshot of the committed files and stores it in the .git directory. How to switch to a specific version? When using commands like checkout or reset to switch versions, Git looks for the corresponding snapshot based on the given branch name/commit ID in the .git directory. It then restores the specified file or the entire directory in the CWD to match that snapshot. Object Level Now let\u0026rsquo;s see how these steps are implemented at the object level. Gitlet simplifies the directory structure of Git to some extent, storing fewer metadata for each object, but the essence remains the same. The following diagram represents the structure of the .gitlet directory.\nGitlet version control utilizes two types of objects: Commit and Blob. Each Blob object corresponds to a file snapshot. Each Commit object corresponds to a commit. How are these objects used to track file versions? When a file is added to the staging area (add [file name]), a Blob object is created to store the current file content. The mapping between the file name and the corresponding Blob instance is then stored in the staging area. When committing files, a Commit object is created. It retrieves the mapping relationships from the staging area and saves them in the Commit object. In addition to the index mapping, each object also records the parent Commit, timestamp, commit message, etc. Example: In the diagram below, each blue square represents a Commit object. Inside each Commit object, there is a Map that records the file snapshots for the current commit. For instance, both Hello.txt in Commit 1 and Commit 2 point to Blob 0, indicating that the file content (snapshot) did not change in these two commits. How is switching to a specific version implemented? — By moving pointers To switch the HEAD pointer to another branch\u0026rsquo;s branchHeadCommit, at the object level, it means that the HEAD pointer, originally pointing to a Commit object on branchA, should now point to another Commit object branchHeadCommit on branchB. This can be achieved by something like updatePointerToCommit(HEAD, branchHeadCommit). File I/O Level Finally, let\u0026rsquo;s dive into the lower-level and examine file read/write operations. Since certain commands require storing Blob objects, Commit objects, and the current content of the staging area locally, two questions arise:\nHow are objects stored as data (to retrieve and use them later)?\nJava\u0026rsquo;s serialization is used to store objects. In Gitlet, all objects can be serialized and stored in files, including Blob, Commit, and StagingArea (if applicable). In the .git directory, they are stored in the /objects/ directory.\nOn the other hand, pointers are managed through file read/write operations (without serialization). Each pointer corresponds to a file that contains the ID of the object it points to. When modifying a pointer\u0026rsquo;s target, the actual change occurs in the file by updating the ID. In the .git directory, pointers are stored in the .git/refs/ directory.\n1 2 3 4 5 6 7 8 9 10 11 /* Serialize a Model object */ Model m = ....; // Assuming Model class implements Serializable File outFile = new File(saveFileName); // Create a new File try { ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(outFile)); out.writeObject(m); // Write the object to the stream out.close(); } catch (IOException excp) { ... } 1 2 3 4 5 6 7 8 9 10 11 12 /* Deserialize a Model object */ Model m; File inFile = new File(saveFileName); try { ObjectInputStream inp = new ObjectInputStream(new FileInputStream(inFile)); m = (Model) inp.readObject(); // Cast object into the expected class inp.close(); } catch (IOException | ClassNotFoundException excp) { ... m = null; } How to find and retrieve objects/modify pointer targets?\nGitlet, like Git, uses SHA-1 (Secure Hash Algorithm 1) to generate a 160-bit hash value as the unique ID (40 hexadecimal characters) for each object. When an object is created, its ID is generated based on its content. For example, identical file contents will produce the same ID after encryption. The filenames for the stored objects are their respective IDs. This means that the ID can be used to locate the serialized objects in the directory. Furthermore, this enables content-addressable lookup based on the object\u0026rsquo;s content. Regarding object retrieval, let\u0026rsquo;s take obtaining a Commit object as an example. The steps include: obtaining the commit ID (which should be a field of the object) -\u0026gt; obtaining the file path based on the ID (since they are stored in a specified directory) -\u0026gt; deserializing the file. Similarly, modifying the object involves updating its content and then serializing it back into the file. As for modifying pointer targets, at the file read/write level, the operation involves: obtaining the ID of the targetCommit -\u0026gt; writing the ID into the file corresponding to the HEAD pointer. (Reminder to self) It\u0026rsquo;s important to encapsulate these operations within the objects. The main logic should not contain statements like commitMap.put(readContentAsString(commitPath), readContentAsString(blobPath)). When reviewing others\u0026rsquo; implementations, if you come across such mixed file read/write operations at the object level, be cautious.\nIn Brief The above passages may seem repetitive, but they provide different perspectives on version control systems. Here\u0026rsquo;s a basic analogy:\nInitializing a version control system == Placing a small box in the current working directory. Saving file versions == Each time a commit is made, making a copy of the submitted files and storing them in the box. Switching the current directory or a file in the directory to a specific version == Finding the corresponding archive in the box and bringing it back to the current working directory (CWD). The other concepts, such as objects, pointers, encoding, etc., are methods used to optimize the copying process and speed up the retrieval of files from the box (at least that\u0026rsquo;s how I understand it):\nBlob object == Archive of a single file. Commit object == A note indicating which file versions to retrieve at a particular time. Commit tree == An outline of the notes (commits). SHA-1 encoding == Giving each file a name based on its content (useful for fast content comparison and addressing). Pointers == Labels indicating which version is currently in the box. Archiving files is a straightforward process that anyone can do (think: paper_final_final_final.docx). However, I believe the essence lies in SHA-1 encoding.\nReflection Notes taken while coding, might be messy.\nReading Order for the Spec The project specification for Gitlet is quite lengthy, making it impractical to read it all at once before starting. If I were to do it again, I would watch the videos first, skim through the command explanations and the \u0026ldquo;avoids\u0026rdquo; section, and then refer to the spec while coding. It\u0026rsquo;s important to pay close attention to the \u0026ldquo;Don\u0026rsquo;t\u0026rdquo; sections in the spec. The reason they are mentioned is that people tend to make those mistakes. For example, using a HashMap as the default Map implementation and encountering a Heisenbug. In reality, a TreeMap should be used to maintain order. ← Starts with \u0026ldquo;callback\u0026rdquo;. Regarding Design Initially, it\u0026rsquo;s crucial to read the entire spec comprehensively, understanding the roles of each object and their commonly used interaction methods. Once the design is clear, implementation can begin.\nPositive example: When implementing the \u0026lt;branch\u0026gt; command, a major directory overhaul was planned. However, due to a well-designed abstraction earlier, only a single line needed to be added to the File directory without any other changes.\nProtect the abstraction barrier. Interactions between higher-level objects should avoid using lower-level operations.\nNegative example: Initially, hashing and serialization were done directly in the main logic, leading to a lot of refactoring during the encapsulation process.\nNaming is crucial. After some painful lessons, the following points are summarized:\nUniformity: Just like joining database tables, if objects need to communicate, they must have some common names. A negative example would be what I did initially, using different names for the IDs obtained from sha-1 hashing, such as shaName, shaId, hashName, etc. Intuitiveness: Variable names should be as specific as possible. For example, \u0026ldquo;map\u0026rdquo; can be written as \u0026ldquo;keyToVal,\u0026rdquo; making it easier to understand. Generality: Methods should not be overly specific so that they can be easily recalled when used elsewhere. For example, instead of using \u0026ldquo;getHead\u0026rdquo; and \u0026ldquo;getMaster,\u0026rdquo; it is better to use \u0026ldquo;getCommit\u0026rdquo; and \u0026ldquo;getPointer.\u0026rdquo; Other Points It would be beneficial to read the source code of Git to find better practices, although the specification alone is generally sufficient. Stats Time and Space The code consists of approximately 1,000 lines. In terms of time, it took around 4.5 days to complete, with a recorded duration of around 40 hours according to Wakatime. Although I spent more than 10 hours debugging during that time (oops!). I remember Josh sharing some data in class, and most students took around 30-40 hours to complete the project.\nFrom a statistical standpoint, Gitlet is not a large-scale project. However, considering that it requires independent completion and involves design, unit and integration testing, makefile, Java file I/O, algorithms, encoding, and even training on Git itself, it is still a highly rewarding experience.\nAutograder Results All functional tests passed successfully. The Extra-Credit tests failed, as well as the style check (mainly due to naming, which I\u0026rsquo;ll improve next time). However, I believe those failures don\u0026rsquo;t significantly impact the overall outcome, so I didn\u0026rsquo;t continue the autograder-oriented programming.\nBTW, reasons for not implementing Extra-Credit features:\nTowards the end, many commands were combinations of previous commands, resulting in diminishing returns. The \u0026ldquo;remote\u0026rdquo; command in Gitlet differs greatly from Git and may not contribute much to understanding the underlying logic of Git. After encountering a Heisenbug, my energy was depleted. Despite not pursuing the Extra-Credit tasks, I still found the Gitlet project rewarding and a valuable learning experience.\nReflection Gitlet is an impressive project in the world of renowned universities. As I mentioned at the beginning, I firmly believe that most individuals with a similar level of proficiency can gain a lot from this project. Just take a glance at the spec, and you\u0026rsquo;ll understand.\nSpeaking from a technical standpoint, I\u0026rsquo;m not qualified to say much as I consider myself a novice. So, let me conclude with a few remarks. In one of Josh\u0026rsquo;s lectures, he shared the results of a Gitlet survey, and one particular detail stuck with me. Some students spent over 50 hours on this project (which, in my personal experience, far exceeds the workload of a typical course assignment in the freshman year). However, only a few individuals gave negative feedback in the end, and I recall Josh expressing his apologies for that. This indirectly reflects the worthwhileness of \u0026ldquo;The Gitlet Grind.\u0026rdquo;\nAn official end of CS61B \u0026ndash; so grateful for the open-source materials! Time to move on and continue working on something else.\nAppendix The following is an excerpt from the README I wrote, explaining the design aspects of my Gitlet implementation.\nDesign Abstraction Principle An issue with version control systems:\nRequires cumbersome operations like hashing, serialization, map operations, directory concatenation, file I/O, etc.\nSolution:\nOn a higher level, involve only communications between objects (between Blob and Commit, there should only be Blob b = commit1.get(filename)) Eliminate the need to dive into low-level operations through encapsulation. i.e. Outside the class of that object, never try to hash things, or modify maps inside Commit/Blob objects. E.g. The StagingArea supports common map operations. Upon put (fileName, Commit), it completes: read commit into commit id -\u0026gt; put into its map -\u0026gt; serialize itself and write into the file for staging. Persistence The directory structure looks like this:\n1 2 3 4 5 6 7 8 9 10 CWD └──.gitlet └── --commits/ # all commits ├──blobs/ # file content ├──branchHeads/ # branch heads | └──--master # master branch | ├──..\t# other branches ├──HEAD\t# HEAD commit ├──add # staging area for addition └──rm # staging area for removal The Main class is the entry class of the project. It is responsible for calling different functions according to given commands.\nThe Repository class will set up all persistance. It will\nCreate and initialize files and directories in the .gitlet folder if the directory does not exist; Handle all updates of HEAD , master, branchHeads and the serialization of two StagingAreas add and rm. Execute the commands / function calls from Main. The Commit class handles the serialization of Commit objects. It also deals with conversion between commit ids and commit objects. Each Commit records mappings of held file names and their corresponding file content. Specifically, it fulfil the following purposes:\nConstructs Commit objects; Serializes and saves Commit objects to the .gitlet/commits directory; Given a commit id, retrieves the corresponding Commit object. The Blob class handles the serialization of Blob objects. A blob is a snapshot of a file\u0026rsquo;s content at the moment of addition. For instance, a file named \u0026ldquo;hello.txt\u0026rdquo; can refer to different Blobs in different Commits.\nIts functions are similar to Commit, namely object construction, serialization and retrieval.\nThe StagingArea class stores files for addition and removal. A StagingArea works like a Java Map, stores mappings of file plain names to their blob ids, and supports basic map operations (remove, get, put). add and rm are StagingAreas for staged addition and removal respectively.\n","permalink":"http://eimy.ink/posts/2023/gitlet-fin/","summary":"♪(´ε｀ )","title":"Notes and Thoughts on CS61B Gitlet"},{"content":"Note: The passage is originally written in Chinese and translated into English via ChatGPT.\nB-Tree, LLRB Hug usually smoothly transitions and introduces new concepts, but the transitions written in the notes can be a bit verbose, so I will provide a concise version here.\nLimitations of BST First, let\u0026rsquo;s introduce two properties of BST: height and average depth. Height: Determines the worst-case runtime to find a node. Average depth: Determines the average-case runtime to find a node. Now let\u0026rsquo;s look at various properties of BSTs. Worst case: $\\Theta(N)$ height Best case: $\\Theta(\\log N)$ height Random trees have $\\Theta(\\log N)$ average depth and height (bushy). Random trees perform well, but the problem arises when we keep inserting data from the right side, leading to imbalance, such as: add(\u0026ldquo;01-Jan-2019, 10:31:00\u0026rdquo;) add(\u0026ldquo;01-Jan-2019, 18:51:00\u0026rdquo;) B-Trees / 2-3 trees / 2-3-4 trees To address the issue of imbalance, we keep inserting new keys into existing nodes and perform node splitting. This gives rise to a new type of tree called B-trees.\nB-trees should be called juicy trees.\nDefinition B-trees are self-balancing trees and can be classified into different types: B-trees of order L=3 (like the ones used today) are also called a 2-3-4 tree or a 2-4 tree (as shown in the figure). B-trees of order L=2 are also called a 2-3 tree (as shown in the figure). B-trees of larger L are used in practice for databases, etc. Construction Mechanism (node-split)\nInsert into a leaf until the number of keys exceeds L. In case of excessive keys, send the second (1st) node up and split the node. Examples:\n【No cascading reaction】 【Involves cascading reaction】 【Involves root split】 Properties (or Invariants)\nBased on the construction mechanism mentioned above, we can derive some properties of B-trees. B-trees are balanced in that:\nAll leaves must be the same distance from the source. Consider: When a root split occurs, the height increases by 1, and all nodes descend one level. If there is no root split, the height remains the same. A non-leaf node with k items must have exactly k+1 children. Runtime Analysis Height: $\\Theta(\\log N)$ for both worst-case and best-case scenarios. In the best case, each node has L items (full), so the height grows with $\\Theta(\\log_{L+1}N)$. In the worst case, each node has only 1 item, so the height grows with $\\Theta(\\log_2N)$, the same as a BST. Operation runtime: Both contains() and add() have a complexity of $O(\\log N)$. Worst case for contains(): $C = (\\text{number of layers}) \\log_{L+1}{N} \\cdot (\\text{nodes per layer}) 1 \\cdot (\\text{work per node}) L$ Worst case for add(): It involves some split operations, but the simplified complexity remains the same. Limitations of B-Trees Can you guess why the code implementation is not included above?\nLeft Leaning Red-Black Trees Definition A BST with left glue links that represents a 2-3 tree is often called a \u0026ldquo;Left Leaning Red Black Binary Search Tree\u0026rdquo; or LLRB.\nIn other words, LLRB is a BST that corresponds to a specific B-Tree. Some remarks about LLRB trees:\nLLRBs are normal BSTs! There is a one-to-one correspondence between an LLRB and an equivalent 2-3 tree. The red color is just a convenient representation. Red links don\u0026rsquo;t have any special functionality. Properties Similar to BSTs, LLRB trees have the following properties:\nAll leaves must be the same distance from the source (counting only black links). No node has two red links. Construction Mechanism In principle, LLRB trees are based on 2-3 trees, where the smaller item in a node is moved down. For example: However, it is not practical to implement a 2-3 tree and then convert it to an LLRB tree. In the code , LLRB trees are implemented directly using red links, rotation, and color flipping:\nAlways use a red link when inserting (analogous to adding items to a node in a 2-3 tree).\nWhen inserting items on the right, use rotateLeft().\nWhen inserting items on the left twice, use rotateRight().\nA new rule allows representing temporary 4-nodes as BST nodes with two red links.\nIn case of temporary 4-nodes, use flipColors().\nIf a rotation or color flip operation causes an additional violation, fix it.\nCode Implementation The following code includes the implementation of these methods, including the modified Node class, put(), the newly added rotate methods, flipColors(), and isRed().\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 // LLRB insertion (p.439) public class RedBlackBST\u0026lt;Key extends Comparable\u0026lt;Key\u0026gt;, Value\u0026gt; { private Node root; private class Node // BST node with color bit (see page 433) private boolean isRed(Node h) // See page 433. private Node rotateLeft(Node h) // See page 434. private Node rotateRight(Node h) // See page 434. private void flipColors(Node h) // See page 436. private int size() // See page 398. public void put(Key key, Value val) { // Search for key. Update value if found; grow table if new. root = put(root, key, val); root.color = BLACK; } private Node put(Node h, Key key, Value val) { if (h == null) { // Do standard insert, with red link to parent. return new Node(key, val, 1, RED); } int cmp = key.compareTo(h.key); if (cmp \u0026lt; 0) { h.left = put(h.left, key, val); } else if (cmp \u0026gt; 0) { h.right = put(h.right, key, val); } else { h.val = val; } if (isRed(h.right) \u0026amp;\u0026amp; !isRed(h.left)) { // 基于BST只需要修改这里三个clause h = rotateLeft(h); } if (isRed(h.left) \u0026amp;\u0026amp; isRed(h.left.left)) { h = rotateRight(h); } if (isRed(h.left) \u0026amp;\u0026amp; isRed(h.right)) { flipColors(h); h.N = size(h.left) + size(h.right) + 1; return h; } } // some omitted methods within RedBlackBST Class private boolean isRed(Node x) { if (x == null) return false; return x.color == RED; } private Node rotateLeft(Node h) { // rotateRight() is similar Node x = h.right; h.right = x.left; x.left = h; x.color = h.color; h.color = RED; x.N = h.N; h.N = 1 + size(h.left) + size(h.right); return x; } private void flipColors(Node h) { h.color = RED; h.left.color = BLACK; h.right.color = BLACK; } } // delete比较麻烦，详细见p.441. Runtime Analysis Height: $O(logN)$ contains(): $O(logN)$ insert(): $O(logN)$ $O(logN)$ to add the new node $O(logN)$ for rotation and color flip operations per insert （After simplification and ignoring constant terms, the time complexity remains O(log N).） Summary of search trees 逻辑梳理 Cited from the slides [lec 18, 19sp]\nBinary search trees** are simple, but they are subject to imbalance.\n2-3 Trees (B Trees) are balanced, but painful to implement and relatively slow.\nLLRBs insertion is simple to implement (but delete is hard).\nWorks by maintaining mathematical bijection with a 2-3 trees. Java’s TreeMap is a red-black tree (not left leaning).\nMaintains correspondence with 2-3-4 tree (is not a 1-1 correspondence).\nAllows glue links on either side (see Red-Black Tree).\nMore complex implementation, but significantly (?) faster.\nComplexity/runtime对比 WC = worst case\nBST B-Trees LLRB Height $O(logN)$ $\\Theta(logN)$ $O(logN)$ WC：$O(N)$ WC：$O(log N)$ WC：$O(log N)$ contains() $O(logN)$ $O(log N)$ $O(logN)$ WC：$O(N)$ WC：$O(log N)$ WC：$O(log N)$ insert() $O(logN)$ $O(log N)$ $O(logN)$ WC：$O(N)$ WC：$O(log N)$ WC：$O(log N)$ Explanation: B-trees and LLRB trees are self-balanced, which prevents the extreme case of a BST degenerating into a linked list. This property makes them faster compared to regular BSTs. In summary:\nB-trees achieve self-balancing to avoid the worst-case complexity of regular BSTs. LLRB trees not only inherit the self-balancing property of B-trees but also retain the ease of implementation characteristic of regular BSTs. ","permalink":"http://eimy.ink/posts/2023/b-tree-llrb/","summary":"B-tree, rotation and red-black trees","title":"61B Notes - B-Trees \u0026 LLRB"},{"content":"Note: The passage is originally written in Chinese and translated into English via ChatGPT.\nReference: Lecture slides from 19sp.\nTrees First, the concept of abstract data type (ADT) is introduced, followed by a progressive/step-by-step optimization-based introduction to three types of trees (BST, B-Tree, LLRB).\nThe notes are divided into two parts, and this article only covers ADT and BST.\nAbstract Data Types (ADT) An abstract data type is defined by its operations, not implementations. Hierarchy Examples ADT Deque; DisjointSets Implementations of ADT ArrayDeque, LinkedListDeque;\nQuickFindDS, WeightedQuickUnionDS Operations of ADT size(), get(), addFirst(Item x), etc. Among the most important interfaces in the java.util library are those that extend the Collection interface. The relationship is shown in the figure. List Set Map The focus this time is on two tree-related data types, TreeSet and TreeMap. Binary Search Tree Origins of BST Question: How can we improve a linked list to perform searches more efficiently?\nThe answer is: 1) Set the entry point in the middle instead of one end. 2) Traverse from the middle to both ends. 3) Traverse in a skipping manner (as shown in the figure).\nDefinition and Properties of BST A binary search tree is a rooted binary tree with the BST property. Tree properties: A set of nodes One path between any two nodes Rooted tree properties: Each node, except the root, has only one parent node. The root is typically drawn at the top. For binary trees, each node can have 0/1/2 child nodes. BST properties: Ordering: Every key in the left subtree is less than X\u0026rsquo;s key. Every key in the right subtree is greater than X\u0026rsquo;s key. No duplicate keys are allowed. (Encountering a BST)\nBST Operations Three operations of BST are introduced.\nSearch / Find Code Implementation (It\u0026rsquo;s easier to understand through the code.) Compare searchKey with T.key \u0026ndash;\u0026gt; Found! / searchKey is smaller, search T.left / searchKey is larger, search T.right.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // reference: Algorithms, p.399 /** Return value associated with key in the subtree rooted at x; * return null if key not present in subtree rooted at x. */ public Value get(Key key) { return get(root, key); } private Value get(Node x, Key key) { // helper if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp \u0026lt; 0) { return get(x.left, key); } else if (cmp \u0026gt; 0) { return get(x.right, key); } else { return x.val; } } Runtime Analysis Worst-case runtime: $\\Theta(\\log{N})$ for a dense binary tree. Tree height: ~$\\log_2{(N)}$ Consider the fact that each additional level requires twice the number of nodes. Insert Code Implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** Search for key. Update value if found; grow table if new. */ public void put(Key key, Value val) { root = put(root, key, val); } /** Change key\u0026#39;s value to val if key in subtree rooted at x. * Otherwise, add a new node to the subtree associating key with val. */ private Node put(Node x, Key key, Value val) { if (x == null) return new Node(key, val, 1); int cmp = key.compareTo(x.key); // compare searchKey to curKey if (cmp \u0026lt; 0) { x.left = put(x.left, key, val); } else if (cmp \u0026gt; 0) { x.right = put(x.right, key, val); } else { x.val = val; } x.N = size(x.left) + size(x.right) + 1; return x; } Runtime Analysis for Insertion It should be the same as the search operation.\nDelete There are three cases for deletion:\nThe key to be deleted has no child nodes (\u0026ndash;\u0026gt; see \u0026ldquo;glut,\u0026rdquo; simply disconnect). The key to be deleted has one child node (\u0026ndash;\u0026gt; see \u0026ldquo;flat,\u0026rdquo; update the parent node\u0026rsquo;s pointer to the child node). The key to be deleted has two child nodes (as shown in the figure, find the predecessor or successor to replace its position). Code Implementation (p.411) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 private Node min(Node x) { // Find the smallest node and its child nodes under x if (x.left == null) return x; return min(x.left); } public void deleteMin() { // Return the root after deleting the smallest node root = deleteMin(root); } private Node deleteMin(Node x) { // DeleteMin helper if (x.left == null) return x.right; x.left = deleteMin(x.left); x.N = size(x.left) + size(x.right) + 1; return x; } public void delete(Key key) { root = delete(root, key); } private Node delete(Node x, Key key) { if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp \u0026lt; 0) { x.left = delete(x.left, key); } else if (cmp \u0026gt; 0) { x.right = delete(x.right, key); } else { // Assume the node P to be deleted has been found if (x.right == null) return x.left; // Check if P has sub-nodes, A) if it has 0/1 sub-nodes, return it if (x.left == null) return x.right; Node t = x; // B) if it has 2 nodes, the tree needs to be adjusted x = min(t.right); // 1. Find the new substitute for the deleted node P x.right = deleteMin(t.right); // 2. Connect the updated right nodes to the new P x.left = t.left; // 3. Connect the original left sub-nodes to the new P // Note the order matters here! } x .N = size(x.left) + size(x.right) + 1; return x; } Runtime Analysis It should be of the same order as the previous operations since it only involves additional modification steps.\nBSTSet v.s. BSTMap This part introduces Lab9 BSTmap.\nBSTSet and BSTMap have the same structure (a tree), but the difference is that each node is represented using a map (as shown in the figure).\n","permalink":"http://eimy.ink/posts/2023/bst/","summary":"ヽ(´o｀；","title":"61B Notes - ADT and BST"},{"content":"Useful techniques to get $\\Theta (f(N))$ Relevant pages in 61B Textbook\nThis is just a condensed(?) version of the textbook.\nEx 1: A For Loop 1 2 3 4 5 6 int N = A.length; for (int i = 0; i \u0026lt; N; i += 1) for (int j = i + 1; j \u0026lt; N; j += 1) if (A[i] == A[j]) return true; return false; Method 1: Count Number of Operations (exact count) The total cost/operations of \u0026ldquo;==\u0026rdquo; amounts to: $$ C(N)=1+2+3+\\dots+(N-2)+(N-1) = N(N-1)/2 $$ Therefore, the runtime would be $\\Theta (N^2)$.\nMethod 2: Geometric Visualization (Imagine the colored blocks - since it\u0026rsquo;s a triangular area - the runtime is $\\Theta (N^2)$.)\nEx 2: Another For Loop 1 2 3 4 5 6 7 8 public static void printParty(int N) { for (int i = 1; i \u0026lt;= N; i = i * 2) { for (int j = 0; j \u0026lt; i; j += 1) { System.out.println(\u0026#34;hello\u0026#34;); int ZUG = 1 + 1; } } } Method 1: Finding the Bound Visually Graph the trajectory of 0.5 N (lower dashed line), and 4N (upper dashed line)\nAnd the C(N) would be between these two lines\nTherefore, the runtime is $\\Theta (N)$.\n(Personally I think it\u0026rsquo;s not as straighforward as the mathematical method)\nMethod 2: Finding the Bound Mathematically Imagine the boxes:\nApproach2-simpler geometric argument So C(N) would be: $$ C(N)=1+2+4+\\dots+N= 2N-1 $$ Therefore, the runtime is $\\Theta (N)$.\nEx 3: Tree Recursion 1 2 3 4 5 public static int f3(int n) { if (n \u0026lt;= 1) return 1; return f3(n-1) + f3(n-1); } Method 1: Intuition Every time we add one to n we double the amount of work that has to be done\n\u0026hellip; which results in the intuitive answer for runtime to be $2^N$.\ntree recursion Method 2: Algebra $C(N)$ amounts to: $$ C(N) = 1+2+4+\\dots+2^\\left(N-1\\right)=2^N-1 $$ So the runtime is $\\Theta (2^N)$.\nMethod 3: Recurrence Relation (Out of Scope) Starting from this: $$ C(N)=2C(N-1)+1 $$\nEx 4: Binary Search binary search Method 1: intuition We start with N options, then N/2, then N/4 \u0026hellip; until we have just 1.\nEach time, we cut the array in half, so in the end we must perform a total of $\\log_{2}(N)$operations\u0026hellip;\nSo the overall runtime then is order\nMethod 2: exact count binary search So $C(N)=floor(log_{2}(N))+1$ (based on observation).\nAnd the runtime is $\\Theta(log(N))$.\nEx 5: Mergesort arbitrary units of time: relative sense of the time needed e.g. If we run an N=6 selection sort, and the runtime is of order $N^2$, it will take ~36 AU to run.\nAbout Mergesort \u0026ndash; a simple case (merge two lists into one) mergesort Its runtime is $\\Theta (N)$.\nMergesort \u0026ndash; applying mergesort to sort a long list mergesort The key idea is to split the original array into smallest pieces and apply mergesort (whose runtime is $\\Theta (N)$).\nSo Mergesort has worst case runtime $\\Theta (N * log(N))$, where\nThe top level takes ~N AU.\nNext level takes ~N/2 + ~N/2 = ~N.\nOne more level down: ~N/4 + ~N/4 + ~N/4 + ~N/4 = ~N.\nSummary There is no magic. Just count. A more standardized method is shown in andwelcome() in disc07: Step 1: Calculate the tree height (number of layers), e.g., for a binary tree, it is $logN$. Step 2: Calculate the branching factor (nodes per layer), e.g., for a binary tree, it is $2^N$. Step 3: Calculate the operations per node, e.g., for a binary tree, it is $N/2^i$. Finally, multiply the results together: $\\sum_{i=0}^{logN} \\cdot 2^i \\cdot (\\frac{N}{2^i}) = N\\log{N}$. ","permalink":"http://eimy.ink/posts/2023/asymptotics2-notes/","summary":"copied from the textbook","title":"61B Notes - Asymptotics II"},{"content":"Note: The passage is originally written in Chinese and translated into English via ChatGPT.\nAsymptotics This is a mixed Chinese-English lecture notes for the algorithms section of CS61B. It outlines the main topics covered in the lecture.\nGeneral Goal This section introduces the core question of \u0026ldquo;how to measure algorithm efficiency.\u0026rdquo;\nEfficiency comes in two ways:\nProgramming cost \u0026lt;\u0026ndash; The focus in the first half of 61B Execution cost \u0026lt;\u0026ndash; The current focus Time cost Memory cost The question is raised: How to measure code efficiency?\nTherefore, the goal of this lecture is to introduce formal standards for measuring algorithm efficiency.\nIntuitive Runtime Characterizations This section provides several intuitive methods to measure program efficiency.\nComparing execution time The advantage is its intuitiveness, but it is unreliable due to multiple influencing factors. Counting the total number of operations (using real numbers/abstract N) The advantage is that it reveals the growth scale (how it scales), but it can be cumbersome to calculate. Screenshot Asymptotic Analysis This section first introduces the extent to which algorithm efficiency is influenced by the order of growth, and then presents methods to simplify asymptotic analysis.\nThe influence of Order of Growth\nThe basic principle is to focus only on the asymptotic behavior when analyzing efficiency (i.e., how it behaves as N tends to infinity).\nBased on this principle, one can observe the function shape when comparing functions at N tends to infinity.\nThis function shape is temporarily referred to as the order of growth, such as line, cubic, quadratic, etc.\nIn other words, we can measure algorithm efficiency based on the order of growth.\nHowever, the current method of analyzing growth (symbolic count) is not simple enough and lacks mathematical rigor. Therefore, it needs to be simplified:\nOnly consider the worst-case count. Choose a representative operation for counting. Consider only the term that has the greatest impact on the order, e.g.: n^3~~+n^2+1~~. Ignore coefficients. Simplification/1 At this point, the analysis involves 1) computing a complete table, 2) selecting a representative count, and 3) simplification. These steps can be further simplified:\nOne way is to directly analyze the code and choose a specific operator for counting. Approach 1 - Based on exact count A simpler approach is geometric analysis (assuming the side length is $N-1$, resulting in $N^2$). Approach 2 - Simpler geometric argument Asymptotic Notation Finally, the commonly used notations for asymptotic analysis, Big Theta (i.e., Order of Growth) and Big O, are introduced.\nBig Theta Big Theta is used to describe the rate of growth in the running time of a program.\nNotation Assume there is a runtime function $R(n)$, and if the order of growth (function shape) of $R(n)$ is $f(N)$,\nit is denoted as: $$ R(n) \\in \\Theta (f(N)) $$\nDefinition $$ R(n) \\in \\Theta (f(N)) $$\nmeans that there exist positive constants $k_1$ and $k_2$ such that $$ k_1 · f(n) \\leq R(N) \\leq k_2 · f(N) $$ for all $N\u0026gt;N_0$ (i.e., very large N).\nExample Big Theta Demo - Big O Big Theta describes an \u0026ldquo;equal\u0026rdquo; relationship (the growth rate of a function is equal to xx), while Big O describes a \u0026ldquo;less than or equal to\u0026rdquo; relationship.\nDefinition (Note: it can be observed that it removes the lower bound compared to $\\Theta$) $$ R(n) \\in \\Theta (f(N)) $$\nmeans that there exists a positive constant $k_2$ such that $$ R(N) \\leq k_2 · f(N) $$ for all $N\u0026gt;N_0$ (i.e., very large N).\nExample: $$ N^3+3N^4 \\in \\Theta(N^4) $$\n$$ N^3+3N^4 \\in O(N^6) $$\nBig O vs Big Theta Informal Meaning Family Family Members Big Theta $$\\Theta(f(N))$$ Order of Growth is $f(N)$ $\\Theta(f(N^2))$ $N^2/2$\n$2N^2$\n$N^2+38N$ Big O$$O(f(N))$$ Order of Growth is less than or equal to $f(N)$ $O(f(N^2))$ $N^2/2$\n$2N^2$\n$lg(N)$ ","permalink":"http://eimy.ink/posts/2023/asymptotics-notes/","summary":"halfway through 61b!","title":"61B Notes - Asymptotics"},{"content":"For certain reasons i decided to move my blogs from hexo-matery to hugo-papermod.\n","permalink":"http://eimy.ink/posts/move/","summary":"moving from hexo-matery to hugo-papermod","title":"Move"},{"content":" Since there\u0026rsquo;s already a brief self-intro on the homepage, I\u0026rsquo;m assuming that anyone who clicks here wants to know more.\nAbout the Site My personal blog, inspired by friends who believe I’m too mysterious.\nI’d like it to be more of a record of my life rather than a professional portfolio.\nAbout Me (in life) Background Currently a Computer Science grad student | Former Linguistics major\nThis is what I\u0026rsquo;ve been longing to do after high school, and there have been a few twists and turns. I do have a great passion for what I’m onto right now and feel really fortunate about my choices.\nLanguages Mandarin (native); English (advanced); Japanese (JLPT N1); French (kindergarten level)\nFYI, it was partly my interest in learning natural languages that led me to pursue a language major and to specialize in computational linguistics.\nIt occurs to me later that 1) language majors do not simply learn languages, 2) what attracts me more are things beyond the symbols, and 3) the coding part is so much fun !\nFavorite band Yorushika, oshi-ed for 6 years since its debut!\nAbout the bio You can\u0026rsquo;t connect the dots looking forward; you can only connect them looking backwards. So you have to trust that the dots will somehow connect in your future.\nIt was said by Steve Jobs (I guess everyone knows). I heard it for the first time only when I was learning about Dijkstra\u0026rsquo;s. Before that, I somehow pictured life as reinforcement learning. See how knowledge changes my view of life haha\nMisc. An amateur illustrator good at sai2, procreate and photoshop An amateur vocaloid engineer/acoustic guitar beginner A keen reader of personality psychology/psycho-analysis Aspire to be a lifelong learner! Last updated: 2023-08\n","permalink":"http://eimy.ink/about/","summary":"about","title":"About"}]